{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "cf1fd448-49ea-45fd-9089-ff87b9109343",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  \n",
                "os.environ[\"HF_TOKEN\"]=\"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\"\n",
                "os.environ[\"MTEB_CACHE\"]=\"/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/results_full\"\n",
                "# os.environ[\"MTEB_CACHE\"]=\"/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/results\"\n",
                "# os.environ[\"MTEB_CACHE\"]=\"/mnt/shared/aamita/project/image_retrieval/notebooks/mteb-results/results\"\n",
                "import traceback\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "cabf0af2-9b1f-44f7-80e0-31a95a1b7c87",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ[\"MTEB_CACHE\"]=\"/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/\"\n",
                "import mteb\n",
                "from mteb.task_selection import results_to_dataframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "766b07fb-7303-4066-a1a8-b3fb48de4d49",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'/Users/aamita/Oracle/oracle/devops/mteb/mteb/__init__.py'"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mteb.__file__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "bbf266f3-d03e-46cb-a869-821f5dc962ee",
            "metadata": {},
            "outputs": [],
            "source": [
                "# model_name = 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct'\n",
                "# model_name = \"TIGER-Lab/VLM2Vec-Full\"\n",
                "model_name = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
                "\n",
                "meta = mteb.get_model_meta(model_name)\n",
                "# model = mteb.get_model(model_name) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "7376201c-74c3-4f67-a3cf-88c6e3922c71",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "ModelMeta(name='Alibaba-NLP/gme-Qwen2-VL-7B-Instruct', revision='477027a6480f8630363be77751f169cc3434b673', release_date='2024-12-24', languages=['eng_Latn', 'cmn-Hans'], loader=functools.partial(<class 'mteb.models.gme_v_models.GmeQwen2VL'>, model_name='Alibaba-NLP/gme-Qwen2-VL-7B-Instruct'), n_parameters=8290000000, memory_usage_mb=31629.0, max_tokens=32768.0, embed_dim=3584, license='apache-2.0', open_weights=True, public_training_code=None, public_training_data=None, framework=['PyTorch'], reference='https://huggingface.co/Alibaba-NLP/gme-Qwen2-VL-2B-Instruct', similarity_fn_name='cosine', use_instructions=True, training_datasets={'MSMARCO': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'FEVER': ['train']}, adapted_from=None, superseded_by=None, is_cross_encoder=None, modalities=['image', 'text'])"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "meta"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "78947957-830f-432f-8ed6-9614edd2bb45",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "ModelMeta(name='Qwen/Qwen2.5-VL-3B-Instruct', revision='c747f21f03e7d0792c30766310bd7d8de17eeeb3', release_date='2024-12-24', languages=['eng_Latn', 'cmn-Hans'], loader=functools.partial(<class 'mteb.models.qwen_25_vl_models.Qwen25VL'>, model_name='Qwen/Qwen2.5-VL-3B-Instruct'), n_parameters=2210000000, memory_usage_mb=8427.0, max_tokens=32768.0, embed_dim=1536, license='apache-2.0', open_weights=True, public_training_code=None, public_training_data=None, framework=['PyTorch'], reference='https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct', similarity_fn_name='cosine', use_instructions=True, training_datasets={'MSMARCO': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'FEVER': ['train']}, adapted_from=None, superseded_by=None, is_cross_encoder=None, modalities=['image', 'text'])"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "meta"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "ef70b008-2eba-46df-b684-66617fcc3a6c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:06<00:00,  3.49s/it]\n",
                        "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
                    ]
                }
            ],
            "source": [
                "model = mteb.get_model(model_name) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96f08422-f878-49c2-baa4-70019b292e71",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[38;5;235m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Any2AnyRetrieval</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mAny2AnyRetrieval\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - ROxfordEasyI2IRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">i2i</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "    - ROxfordEasyI2IRetrieval, \u001b[3;38;5;241mi2i\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
                            "\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\n",
                            "\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Overwrite dataset info from restored data version if exists.\n",
                        "INFO:datasets.builder:Overwrite dataset info from restored data version if exists.\n",
                        "Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/corpus/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "INFO:datasets.info:Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/corpus/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Found cached dataset r-oxford-easy-multi (/Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/corpus/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7)\n",
                        "INFO:datasets.builder:Found cached dataset r-oxford-easy-multi (/Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/corpus/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7)\n",
                        "Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/corpus/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "INFO:datasets.info:Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/corpus/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Constructing Dataset for split corpus, from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/corpus/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "DEBUG:datasets.builder:Constructing Dataset for split corpus, from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/corpus/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Overwrite dataset info from restored data version if exists.\n",
                        "INFO:datasets.builder:Overwrite dataset info from restored data version if exists.\n",
                        "Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "INFO:datasets.info:Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Found cached dataset r-oxford-easy-multi (/Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7)\n",
                        "INFO:datasets.builder:Found cached dataset r-oxford-easy-multi (/Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7)\n",
                        "Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "INFO:datasets.info:Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Constructing Dataset for split test, from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "DEBUG:datasets.builder:Constructing Dataset for split test, from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Overwrite dataset info from restored data version if exists.\n",
                        "INFO:datasets.builder:Overwrite dataset info from restored data version if exists.\n",
                        "Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "INFO:datasets.info:Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Found cached dataset r-oxford-easy-multi (/Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7)\n",
                        "INFO:datasets.builder:Found cached dataset r-oxford-easy-multi (/Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7)\n",
                        "Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "INFO:datasets.info:Loading Dataset info from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Constructing Dataset for split test, from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "DEBUG:datasets.builder:Constructing Dataset for split test, from /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7\n",
                        "Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
                        "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
                        "Loading cached processed dataset at /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7/cache-04561d8c8dc87e91.arrow\n",
                        "INFO:datasets.arrow_dataset:Loading cached processed dataset at /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/qrels/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7/cache-04561d8c8dc87e91.arrow\n",
                        "Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
                        "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
                        "Set __getitem__(key) output type to python objects for ['query-id', 'corpus-id', 'score'] columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
                        "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to python objects for ['query-id', 'corpus-id', 'score'] columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
                        "Loading cached processed dataset at /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7/cache-7dd0a438b53c95a4.arrow\n",
                        "INFO:datasets.arrow_dataset:Loading cached processed dataset at /Users/aamita/.cache/huggingface/datasets/JamieSJS___r-oxford-easy-multi/query/0.0.0/4c167c3ce529f19457c9b8e694258cc6cf8e7cc7/cache-7dd0a438b53c95a4.arrow\n",
                        "encode:   0%|                                                                                                                                                                | 0/18 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "> \u001b[32m/Users/aamita/Oracle/oracle/devops/mteb/mteb/models/qwen_25_vl_models.py\u001b[39m(\u001b[92m61\u001b[39m)\u001b[36mforward\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[32m     59\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m pixel_values \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "\u001b[32m     60\u001b[39m                 pdb.set_trace()\n",
                        "\u001b[32m---> 61\u001b[39m                 pixel_values = pixel_values.type(self.base.visual.get_dtype())\n",
                        "\u001b[32m     62\u001b[39m                 image_embeds = self.base.visual(\n",
                        "\u001b[32m     63\u001b[39m                     pixel_values, grid_thw=image_grid_thw\n",
                        "\n"
                    ]
                },
                {
                    "name": "stdin",
                    "output_type": "stream",
                    "text": [
                        "ipdb>  pixel_values\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([[ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
                        "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
                        "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1175,  2.1175,  2.1175],\n",
                        "        ...,\n",
                        "        [ 0.6019,  0.6895,  0.7187,  ...,  0.6812,  0.7097,  0.6244],\n",
                        "        [-0.0405,  0.0179,  0.1201,  ..., -0.1720,  0.3968,  0.5248],\n",
                        "        [-0.1718, -0.1426, -0.2156,  ...,  0.3542,  0.0555, -0.9399]])\n"
                    ]
                },
                {
                    "name": "stdin",
                    "output_type": "stream",
                    "text": [
                        "ipdb>  type(pixel_values)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'torch.Tensor'>\n"
                    ]
                },
                {
                    "name": "stdin",
                    "output_type": "stream",
                    "text": [
                        "ipdb>  self.base\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Qwen2_5_VLForConditionalGeneration(\n",
                        "  (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
                        "    (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
                        "      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
                        "    )\n",
                        "    (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
                        "    (blocks): ModuleList(\n",
                        "      (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
                        "        (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
                        "        (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
                        "        (attn): Qwen2_5_VLVisionSdpaAttention(\n",
                        "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
                        "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
                        "        )\n",
                        "        (mlp): Qwen2_5_VLMLP(\n",
                        "          (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
                        "          (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
                        "          (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
                        "          (act_fn): SiLU()\n",
                        "        )\n",
                        "      )\n",
                        "    )\n",
                        "    (merger): Qwen2_5_VLPatchMerger(\n",
                        "      (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
                        "      (mlp): Sequential(\n",
                        "        (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
                        "        (1): GELU(approximate='none')\n",
                        "        (2): Linear(in_features=5120, out_features=2048, bias=True)\n",
                        "      )\n",
                        "    )\n",
                        "  )\n",
                        "  (model): Qwen2_5_VLModel(\n",
                        "    (embed_tokens): Embedding(151936, 2048)\n",
                        "    (layers): ModuleList(\n",
                        "      (0-35): 36 x Qwen2_5_VLDecoderLayer(\n",
                        "        (self_attn): Qwen2_5_VLSdpaAttention(\n",
                        "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
                        "          (k_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
                        "          (v_proj): Linear(in_features=2048, out_features=256, bias=True)\n",
                        "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
                        "          (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
                        "        )\n",
                        "        (mlp): Qwen2MLP(\n",
                        "          (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)\n",
                        "          (up_proj): Linear(in_features=2048, out_features=11008, bias=False)\n",
                        "          (down_proj): Linear(in_features=11008, out_features=2048, bias=False)\n",
                        "          (act_fn): SiLU()\n",
                        "        )\n",
                        "        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
                        "        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
                        "      )\n",
                        "    )\n",
                        "    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
                        "    (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
                        "  )\n",
                        "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
                        ")\n"
                    ]
                },
                {
                    "name": "stdin",
                    "output_type": "stream",
                    "text": [
                        "ipdb>  self.base.visual\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Qwen2_5_VisionTransformerPretrainedModel(\n",
                        "  (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
                        "    (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
                        "  )\n",
                        "  (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
                        "  (blocks): ModuleList(\n",
                        "    (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
                        "      (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
                        "      (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
                        "      (attn): Qwen2_5_VLVisionSdpaAttention(\n",
                        "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
                        "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
                        "      )\n",
                        "      (mlp): Qwen2_5_VLMLP(\n",
                        "        (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
                        "        (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
                        "        (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
                        "        (act_fn): SiLU()\n",
                        "      )\n",
                        "    )\n",
                        "  )\n",
                        "  (merger): Qwen2_5_VLPatchMerger(\n",
                        "    (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
                        "    (mlp): Sequential(\n",
                        "      (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
                        "      (1): GELU(approximate='none')\n",
                        "      (2): Linear(in_features=5120, out_features=2048, bias=True)\n",
                        "    )\n",
                        "  )\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "tasks = mteb.get_tasks(tasks=[\"ROxfordEasyI2IRetrieval\"])\n",
                "# run the evaluation\n",
                "evaluation = mteb.MTEB(tasks=tasks)\n",
                "\n",
                "results = evaluation.run(model,save_corpus_embeddings=True,device=\"auto\",\n",
                "                         save_predictions=True, export_errors=True, verbosity= 3,\n",
                "                         encode_kwargs={\"batch_size\": 4})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "1b2495d4-bd7a-484b-b2d8-ffe872486e2e",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/mteb_github/mteb/__init__.py'"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mteb.__file__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "1c361923-8b94-409a-8970-03198caf0f1a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<mteb.models.sentence_transformer_wrapper.SentenceTransformerWrapper at 0x30e75b050>"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7be7aaf0-60a4-420a-90b6-b54cfb39940c",
            "metadata": {},
            "outputs": [],
            "source": [
                "/Users/aamita/Oracle/oracle/devops/mteb/mteb/models/qwen_25_vl_models.py"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ir",
            "language": "python",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
