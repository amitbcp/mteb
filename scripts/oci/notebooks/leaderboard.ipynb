{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcaec111-35c8-4848-aa5b-b9493785f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  \n",
    "os.environ[\"HF_TOKEN\"]=\"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\"\n",
    "# os.environ[\"MTEB_CACHE\"]=\"/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/results_full\"\n",
    "os.environ[\"MTEB_CACHE\"]=\"/Users/aamita/Oracle/oracle/devops/mteb/scripts/oci/\"\n",
    "# os.environ[\"MTEB_CACHE\"]=\"/mnt/shared/aamita/project/image_retrieval/notebooks/mteb-results/results\"\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3d82a2-78f1-4e96-8f06-fa4496bffc8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aamita/miniconda3/envs/image_retrieval/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mteb\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d1101-ac4f-453c-a165-15d74bb37556",
   "metadata": {},
   "source": [
    "# 1.36.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2813fb6e-29a0-4415-b306-cf7a4233b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b560ea-b078-4f04-bb5f-73d6c53c7a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aamita/miniconda3/envs/ir/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aamita/Oracle/oracle/devops/mteb/mteb/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# os.environ[\"MTEB_CACHE\"]=\"/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/\"\n",
    "# sys.path.append(\"/mnt/shared/aamita/project/image_retrieval/VLM2Vec/\")\n",
    "# os.environ[\"MTEB_CACHE\"]=\"/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/amit\"\n",
    "os.environ[\"HF_TOKEN\"]=\"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\"\n",
    "sys.path.append(\"/Users/aamita/Oracle/oracle/devops/VLM2Vec/\")\n",
    "os.environ[\"MTEB_CACHE\"]=\"/Users/aamita/Oracle/oracle/devops/mteb/scripts/oci/\"\n",
    "import mteb\n",
    "from mteb.task_selection import results_to_dataframe\n",
    "print(mteb.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a914f54-72f7-4c65-b343-6c29eeecc763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "\"google/siglip-so400m-patch14-384\",\n",
    "\"google/siglip-large-patch16-384\",\n",
    "\"laion/CLIP-ViT-bigG-14-laion2B-39B-b160k\",\n",
    "\"facebook/dinov2-giant\",\n",
    "\"facebook/dinov2-large\",\n",
    "\"TIGER-Lab/VLM2Vec-Full\",\n",
    "\"TIGER-Lab/VLM2Vec-Qwen2VL-2B\",\n",
    "\"TIGER-Lab/VLM2Vec-Qwen2VL-7B\",\n",
    "\n",
    "\"Alibaba-NLP/gme-Qwen2-VL-7B-Instruct\",\n",
    "\"Alibaba-NLP/gme-Qwen2-VL-2B-Instruct\",\n",
    "\"royokong/e5-v\",\n",
    "# \"jinaai/jina-clip-v1\",\n",
    "# \"nomic-ai/nomic-embed-vision-v1.5\",\n",
    "# internal\n",
    "\"OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full\",\n",
    "\"OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora\",\n",
    "\"OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode\"\n",
    "    \n",
    "]\n",
    "\n",
    "models = [mteb.get_model_meta(name) for name in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0ce066-9f60-42b4-8518-4d963d999b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks = mteb.get_tasks(languages=[\"eng\"],modalities=[\"text\", \"image\"],\n",
    "#                        task_types=[\"Compositionality\"])\n",
    "\n",
    "# print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d305cafb-dde2-4c67-a495-d292ceed2e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2025 09:14:48 - INFO - mteb.load_results.load_results -   Results repository already exists in /Users/aamita/Oracle/oracle/devops/mteb/scripts/oci/results, updating it using git pull\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "tasks = mteb.get_tasks(languages=[\"eng\"],modalities=[\"text\", \"image\"],\n",
    "                       task_types=[ \"Any2AnyRetrieval\", #\"Compositionality\",\n",
    "                                   \"DocumentUnderstanding\",\"VisionCentricQA\"])\n",
    "task_names = [ task.metadata.name for task in tasks]\n",
    "results = mteb.load_results(models=models, tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefa38cb-a958-4891-95ea-2f298c49d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_res in results:\n",
    "#     if not model_res.model_name ==\"TIGER-Lab/VLM2Vec-Full\" :\n",
    "#         continue\n",
    "#     for task_result in model_res.task_results:\n",
    "#         if task_result.task_name==\"ImageCoDe\" :\n",
    "#             print(task_result.scores)\n",
    "        \n",
    "\n",
    "#     break\n",
    "# results[0]#.model_name=\"TIGER-Lab/VLM2Vec-Full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb58f75-2c37-471e-9c9a-3f0ae88d9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "mteb_results = results\n",
    "for model_res in mteb_results:\n",
    "    for task_result in model_res.task_results:\n",
    "        if not task_result.task_name in task_names :\n",
    "            continue\n",
    "        tasks = mteb.get_tasks(tasks=[task_result.task_name])\n",
    "        \n",
    "        # print(task_result)\n",
    "        data.append(\n",
    "                {\n",
    "                    \"Model\": model_res.model_name,\n",
    "                    \"Revision\": model_res.model_revision,\n",
    "                    \"task\": task_result.task_name,\n",
    "                    \"task_type\": tasks[0].metadata.type,\n",
    "                    \"ndcg_at_5\": task_result.scores.get('test','default')[0].get(\"ndcg_at_5\",np.nan),\n",
    "                    \"main_score\":float(task_result.get_score()),\n",
    "                }\n",
    "        )\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca33a69-57fb-4bc0-8669-85c3dc506dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Results before NAN Removal : (755, 6)\n",
      "Size of Results before NAN Removal : (755, 6)\n"
     ]
    }
   ],
   "source": [
    "bench_df  = pd.DataFrame(data)\n",
    "print(f\"Size of Results before NAN Removal : {bench_df.shape}\")\n",
    "bench_df.dropna(subset=['ndcg_at_5'],inplace=True)\n",
    "print(f\"Size of Results before NAN Removal : {bench_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e759d7-fe57-489f-9d16-803f43d1ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_df = bench_df.groupby(['Model','task_type'])['ndcg_at_5'].mean().reset_index()\n",
    "bench_df_pivoted = bench_df.pivot(index='Model', columns='task_type', values='ndcg_at_5')\n",
    "bench_df_pivoted['Avg'] = bench_df_pivoted.mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c2888e8-b99e-4858-8683-c0fc30084402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>task_type</th>\n",
       "      <th>Any2AnyRetrieval</th>\n",
       "      <th>DocumentUnderstanding</th>\n",
       "      <th>VisionCentricQA</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP/gme-Qwen2-VL-2B-Instruct</th>\n",
       "      <td>0.507</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP/gme-Qwen2-VL-7B-Instruct</th>\n",
       "      <td>0.510</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full</th>\n",
       "      <td>0.323</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</th>\n",
       "      <td>0.373</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode</th>\n",
       "      <td>0.343</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Full</th>\n",
       "      <td>0.338</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-2B</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-7B</th>\n",
       "      <td>0.344</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/dinov2-giant</th>\n",
       "      <td>0.613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/dinov2-large</th>\n",
       "      <td>0.601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/siglip-large-patch16-384</th>\n",
       "      <td>0.447</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/siglip-so400m-patch14-384</th>\n",
       "      <td>0.456</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laion/CLIP-ViT-bigG-14-laion2B-39B-b160k</th>\n",
       "      <td>0.471</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royokong/e5-v</th>\n",
       "      <td>0.419</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task_type                                          Any2AnyRetrieval  \\\n",
       "Model                                                                 \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                          0.507   \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                          0.510   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                       0.323   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora                       0.373   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode             0.343   \n",
       "TIGER-Lab/VLM2Vec-Full                                        0.338   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                  0.375   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                  0.344   \n",
       "facebook/dinov2-giant                                         0.613   \n",
       "facebook/dinov2-large                                         0.601   \n",
       "google/siglip-large-patch16-384                               0.447   \n",
       "google/siglip-so400m-patch14-384                              0.456   \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                      0.471   \n",
       "royokong/e5-v                                                 0.419   \n",
       "\n",
       "task_type                                          DocumentUnderstanding  \\\n",
       "Model                                                                      \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                               0.883   \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                               0.900   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                            0.530   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora                            0.544   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode                  0.500   \n",
       "TIGER-Lab/VLM2Vec-Full                                             0.501   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                       0.405   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                       0.513   \n",
       "facebook/dinov2-giant                                                NaN   \n",
       "facebook/dinov2-large                                                NaN   \n",
       "google/siglip-large-patch16-384                                    0.538   \n",
       "google/siglip-so400m-patch14-384                                   0.567   \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                           0.435   \n",
       "royokong/e5-v                                                      0.630   \n",
       "\n",
       "task_type                                          VisionCentricQA    Avg  \n",
       "Model                                                                      \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                         0.886  0.759  \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                         0.896  0.769  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                      0.766  0.540  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora                      0.824  0.580  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode            0.826  0.556  \n",
       "TIGER-Lab/VLM2Vec-Full                                       0.851  0.563  \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                 0.767  0.516  \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                 0.827  0.561  \n",
       "facebook/dinov2-giant                                          NaN  0.613  \n",
       "facebook/dinov2-large                                          NaN  0.601  \n",
       "google/siglip-large-patch16-384                              0.775  0.587  \n",
       "google/siglip-so400m-patch14-384                             0.777  0.600  \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                     0.762  0.556  \n",
       "royokong/e5-v                                                0.806  0.618  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_df_pivoted.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a087ee0-92ce-4641-a91e-1194a0ceb3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>task_type</th>\n",
       "      <th>Any2AnyRetrieval</th>\n",
       "      <th>DocumentUnderstanding</th>\n",
       "      <th>VisionCentricQA</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP/gme-Qwen2-VL-2B-Instruct</th>\n",
       "      <td>0.507</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP/gme-Qwen2-VL-7B-Instruct</th>\n",
       "      <td>0.510</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full</th>\n",
       "      <td>0.323</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</th>\n",
       "      <td>0.373</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode</th>\n",
       "      <td>0.343</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Full</th>\n",
       "      <td>0.338</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-2B</th>\n",
       "      <td>0.406</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-7B</th>\n",
       "      <td>0.344</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/dinov2-giant</th>\n",
       "      <td>0.613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/dinov2-large</th>\n",
       "      <td>0.601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/siglip-large-patch16-384</th>\n",
       "      <td>0.447</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/siglip-so400m-patch14-384</th>\n",
       "      <td>0.456</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laion/CLIP-ViT-bigG-14-laion2B-39B-b160k</th>\n",
       "      <td>0.471</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royokong/e5-v</th>\n",
       "      <td>0.419</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task_type                                          Any2AnyRetrieval  \\\n",
       "Model                                                                 \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                          0.507   \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                          0.510   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                       0.323   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora                       0.373   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode             0.343   \n",
       "TIGER-Lab/VLM2Vec-Full                                        0.338   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                  0.406   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                  0.344   \n",
       "facebook/dinov2-giant                                         0.613   \n",
       "facebook/dinov2-large                                         0.601   \n",
       "google/siglip-large-patch16-384                               0.447   \n",
       "google/siglip-so400m-patch14-384                              0.456   \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                      0.471   \n",
       "royokong/e5-v                                                 0.419   \n",
       "\n",
       "task_type                                          DocumentUnderstanding  \\\n",
       "Model                                                                      \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                               0.883   \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                               0.900   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                            0.530   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora                            0.544   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode                  0.500   \n",
       "TIGER-Lab/VLM2Vec-Full                                             0.501   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                       0.405   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                       0.513   \n",
       "facebook/dinov2-giant                                                NaN   \n",
       "facebook/dinov2-large                                                NaN   \n",
       "google/siglip-large-patch16-384                                    0.538   \n",
       "google/siglip-so400m-patch14-384                                   0.567   \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                           0.435   \n",
       "royokong/e5-v                                                      0.630   \n",
       "\n",
       "task_type                                          VisionCentricQA    Avg  \n",
       "Model                                                                      \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                         0.886  0.759  \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                         0.896  0.769  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                      0.766  0.540  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora                      0.824  0.580  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode            0.826  0.556  \n",
       "TIGER-Lab/VLM2Vec-Full                                       0.851  0.563  \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                 0.767  0.526  \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                 0.827  0.561  \n",
       "facebook/dinov2-giant                                          NaN  0.613  \n",
       "facebook/dinov2-large                                          NaN  0.601  \n",
       "google/siglip-large-patch16-384                              0.775  0.587  \n",
       "google/siglip-so400m-patch14-384                             0.777  0.600  \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                     0.762  0.556  \n",
       "royokong/e5-v                                                0.806  0.618  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_df_pivoted.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f077a2c6-ac90-401f-b05d-ac13e8d1d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c30c3-e23f-4f70-a5fc-e6872002f016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7277a-7629-4d47-830f-0f6edf1a3911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff549b19-8ea6-4440-87b6-b07f8878c3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c595d8e-8d6d-47a0-8b83-a8d2353a605f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd2c3207-f9d6-490f-8d93-698fa3b375e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>task_type</th>\n",
       "      <th>Any2AnyRetrieval</th>\n",
       "      <th>DocumentUnderstanding</th>\n",
       "      <th>VisionCentricQA</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP/gme-Qwen2-VL-2B-Instruct</th>\n",
       "      <td>0.485237</td>\n",
       "      <td>0.882746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP/gme-Qwen2-VL-7B-Instruct</th>\n",
       "      <td>0.501005</td>\n",
       "      <td>0.900885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full</th>\n",
       "      <td>0.322528</td>\n",
       "      <td>0.530320</td>\n",
       "      <td>0.766247</td>\n",
       "      <td>0.539698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode</th>\n",
       "      <td>0.343180</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.825972</td>\n",
       "      <td>0.556349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Full</th>\n",
       "      <td>0.337562</td>\n",
       "      <td>0.500935</td>\n",
       "      <td>0.851088</td>\n",
       "      <td>0.563195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-2B</th>\n",
       "      <td>0.406391</td>\n",
       "      <td>0.405385</td>\n",
       "      <td>0.766605</td>\n",
       "      <td>0.526127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-7B</th>\n",
       "      <td>0.343899</td>\n",
       "      <td>0.512966</td>\n",
       "      <td>0.827268</td>\n",
       "      <td>0.561378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/dinov2-giant</th>\n",
       "      <td>0.612623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/dinov2-large</th>\n",
       "      <td>0.601182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.601182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/siglip-large-patch16-384</th>\n",
       "      <td>0.446545</td>\n",
       "      <td>0.537811</td>\n",
       "      <td>0.775260</td>\n",
       "      <td>0.586539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/siglip-so400m-patch14-384</th>\n",
       "      <td>0.455603</td>\n",
       "      <td>0.566942</td>\n",
       "      <td>0.777010</td>\n",
       "      <td>0.599852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jinaai/jina-clip-v1</th>\n",
       "      <td>0.396766</td>\n",
       "      <td>0.177522</td>\n",
       "      <td>0.772032</td>\n",
       "      <td>0.448773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laion/CLIP-ViT-bigG-14-laion2B-39B-b160k</th>\n",
       "      <td>0.471481</td>\n",
       "      <td>0.434555</td>\n",
       "      <td>0.761653</td>\n",
       "      <td>0.555896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomic-ai/nomic-embed-vision-v1.5</th>\n",
       "      <td>0.383563</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>0.427733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royokong/e5-v</th>\n",
       "      <td>0.418538</td>\n",
       "      <td>0.630217</td>\n",
       "      <td>0.806312</td>\n",
       "      <td>0.618355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task_type                                          Any2AnyRetrieval  \\\n",
       "Model                                                                 \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                       0.485237   \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                       0.501005   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                    0.322528   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode          0.343180   \n",
       "TIGER-Lab/VLM2Vec-Full                                     0.337562   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                               0.406391   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                               0.343899   \n",
       "facebook/dinov2-giant                                      0.612623   \n",
       "facebook/dinov2-large                                      0.601182   \n",
       "google/siglip-large-patch16-384                            0.446545   \n",
       "google/siglip-so400m-patch14-384                           0.455603   \n",
       "jinaai/jina-clip-v1                                        0.396766   \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                   0.471481   \n",
       "nomic-ai/nomic-embed-vision-v1.5                           0.383563   \n",
       "royokong/e5-v                                              0.418538   \n",
       "\n",
       "task_type                                          DocumentUnderstanding  \\\n",
       "Model                                                                      \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                            0.882746   \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                            0.900885   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                         0.530320   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode               0.499895   \n",
       "TIGER-Lab/VLM2Vec-Full                                          0.500935   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                    0.405385   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                    0.512966   \n",
       "facebook/dinov2-giant                                                NaN   \n",
       "facebook/dinov2-large                                                NaN   \n",
       "google/siglip-large-patch16-384                                 0.537811   \n",
       "google/siglip-so400m-patch14-384                                0.566942   \n",
       "jinaai/jina-clip-v1                                             0.177522   \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                        0.434555   \n",
       "nomic-ai/nomic-embed-vision-v1.5                                0.119700   \n",
       "royokong/e5-v                                                   0.630217   \n",
       "\n",
       "task_type                                          VisionCentricQA       Avg  \n",
       "Model                                                                         \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                           NaN  0.683991  \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                           NaN  0.700945  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                   0.766247  0.539698  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode         0.825972  0.556349  \n",
       "TIGER-Lab/VLM2Vec-Full                                    0.851088  0.563195  \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                              0.766605  0.526127  \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                              0.827268  0.561378  \n",
       "facebook/dinov2-giant                                          NaN  0.612623  \n",
       "facebook/dinov2-large                                          NaN  0.601182  \n",
       "google/siglip-large-patch16-384                           0.775260  0.586539  \n",
       "google/siglip-so400m-patch14-384                          0.777010  0.599852  \n",
       "jinaai/jina-clip-v1                                       0.772032  0.448773  \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                  0.761653  0.555896  \n",
       "nomic-ai/nomic-embed-vision-v1.5                          0.779935  0.427733  \n",
       "royokong/e5-v                                             0.806312  0.618355  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_df_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509323d9-5245-40b0-8957-9e21957a19d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050e1dfd-2807-4562-b3eb-1155ae590d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df  = pd.DataFrame(data)\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6317ae27-4b76-4395-81f2-80d8e0b6753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: ndcg_at_5, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_counts = df.groupby(['task_type','task'])['ndcg_at_5'].apply(lambda x: x.isna().sum())\n",
    "na_counts = na_counts[na_counts > 0]\n",
    "na_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9e8e3b1-c28f-43b6-a09d-7f8ad0a34f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Revision</th>\n",
       "      <th>task</th>\n",
       "      <th>task_type</th>\n",
       "      <th>ndcg_at_5</th>\n",
       "      <th>main_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Revision, task, task_type, ndcg_at_5, main_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_df[bench_df.task_type==\"Compositionality\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba28af2-4134-417b-bafb-b786878d5919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dfbbf-104d-403e-b84d-5900c240ce68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d944bd1-1d64-4e95-93eb-8d0710b0bcb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtask_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.float64' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "task_result.get_score().value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "275182fa-df16-4625-bb41-fac5cd3786ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Split m not found in scores",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m task_result\u001b[38;5;241m.\u001b[39mget_score(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrr_at_10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Oracle/oracle/devops/multimodal_retrieval/image/mteb_github/mteb/load_results/task_results.py:456\u001b[0m, in \u001b[0;36mTaskResult.get_score\u001b[0;34m(self, splits, languages, scripts, getter, aggregation)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m splits:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores:\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplit \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in scores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m scores \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores[split]:\n\u001b[1;32m    459\u001b[0m         eval_langs \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Split m not found in scores"
     ]
    }
   ],
   "source": [
    "task_result.get_score(\"mrr_at_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfdee56-aaca-4d09-840f-b630044be491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_dataframe(\n",
    "    mteb_results: BenchmarkResults,\n",
    "    drop_na: bool = True,\n",
    "    **kwargs: Any,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Convert the results of the MTEB evaluation to a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        mteb_results: The results of the MTEB evaluation.\n",
    "        drop_na: Whether to drop missing values from the DataFrame.\n",
    "        **kwargs: Additional keyword arguments to be passed to the `get_score` method of the `MTEBResults` class.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for model_res in mteb_results:\n",
    "        for task_result in model_res.task_results:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"Model\": model_res.model_name,\n",
    "                    \"Revision\": model_res.model_revision,\n",
    "                    \"task\": task_result.task_name,\n",
    "                    \"main_score\": task_result.get_score(**kwargs),\n",
    "                }\n",
    "            )\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if drop_na:\n",
    "        df = df.dropna(axis=1)\n",
    "    return df.pivot_table(\n",
    "        index=[\"Model\", \"Revision\"],\n",
    "        columns=[\"task\"],\n",
    "        values=\"main_score\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c6cf2-ae41-4e65-85ae-02692bd4b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c07758-3cc1-49db-a7db-ad6fd614b093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad08ccf8-2d14-4099-8d21-b6865b60fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(\n",
    "    task_types=[\"Retrieval\"], languages=[\"eng\", \"fra\"], domains=[\"Legal\"]\n",
    ")\n",
    "\n",
    "model_names = [\n",
    "    \"GritLM/GritLM-7B\",\n",
    "    # \"intfloat/multilingual-e5-small\",\n",
    "    # \"intfloat/multilingual-e5-base\",\n",
    "    # \"intfloat/multilingual-e5-large\",\n",
    "]\n",
    "models = [mteb.get_model_meta(name) for name in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf5bfa59-dae2-477a-aa3f-4f2081e30d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mteb.load_results(models=models, tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92ecb31e-b090-4347-b60b-44ca90e077ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkResults(model_results=[...](#1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeeef62f-42e7-4494-8604-7f8c03614db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='GritLM/GritLM-7B' model_revision='13f00a0e36500c80ce12870ea513846a066004af' task_results=[TaskResult(task_name=SyntecRetrieval, scores=...), TaskResult(task_name=BSARDRetrieval, scores=...), TaskResult(task_name=AILACasedocs, scores=...), TaskResult(task_name=LegalBenchConsumerContractsQA, scores=...), TaskResult(task_name=LegalBenchCorporateLobbying, scores=...), TaskResult(task_name=LegalSummarization, scores=...), TaskResult(task_name=AILAStatutes, scores=...)] default_modalities=['text']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "mteb_results = results\n",
    "for model_res in mteb_results:\n",
    "    print(model_res)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80a923fd-f4e9-421e-aa03-9e7fd100b903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name='GritLM/GritLM-7B' model_revision='13f00a0e36500c80ce12870ea513846a066004af' task_results=[TaskResult(task_name=SyntecRetrieval, scores=...), TaskResult(task_name=BSARDRetrieval, scores=...), TaskResult(task_name=AILACasedocs, scores=...), TaskResult(task_name=LegalBenchConsumerContractsQA, scores=...), TaskResult(task_name=LegalBenchCorporateLobbying, scores=...), TaskResult(task_name=LegalSummarization, scores=...), TaskResult(task_name=AILAStatutes, scores=...)] default_modalities=['text']\n"
     ]
    }
   ],
   "source": [
    "print(model_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "148cbfbc-d93e-4292-bb75-1b09dcd32c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': [{'hf_subset': 'default',\n",
       "   'languages': ['fra-Latn'],\n",
       "   'main_score': 0.89477,\n",
       "   'map_at_1': 0.77,\n",
       "   'map_at_10': 0.86278,\n",
       "   'map_at_100': 0.86369,\n",
       "   'map_at_1000': 0.86369,\n",
       "   'map_at_20': 0.86369,\n",
       "   'map_at_3': 0.85833,\n",
       "   'map_at_5': 0.85833,\n",
       "   'mrr_at_1': 0.77,\n",
       "   'mrr_at_10': 0.8627777777777778,\n",
       "   'mrr_at_100': 0.8636868686868686,\n",
       "   'mrr_at_1000': 0.8636868686868686,\n",
       "   'mrr_at_20': 0.8636868686868686,\n",
       "   'mrr_at_3': 0.8583333333333333,\n",
       "   'mrr_at_5': 0.8583333333333333,\n",
       "   'nauc_map_at_1000_diff1': 0.6353223361063849,\n",
       "   'nauc_map_at_1000_max': 0.2035104553996245,\n",
       "   'nauc_map_at_1000_std': 0.02782906976329559,\n",
       "   'nauc_map_at_100_diff1': 0.6353223361063849,\n",
       "   'nauc_map_at_100_max': 0.2035104553996245,\n",
       "   'nauc_map_at_100_std': 0.02782906976329559,\n",
       "   'nauc_map_at_10_diff1': 0.6370034173211229,\n",
       "   'nauc_map_at_10_max': 0.19377256262184606,\n",
       "   'nauc_map_at_10_std': 0.01512682217835213,\n",
       "   'nauc_map_at_1_diff1': 0.6110874868512343,\n",
       "   'nauc_map_at_1_max': 0.19104317271323365,\n",
       "   'nauc_map_at_1_std': 0.03034847026700385,\n",
       "   'nauc_map_at_20_diff1': 0.6353223361063849,\n",
       "   'nauc_map_at_20_max': 0.2035104553996245,\n",
       "   'nauc_map_at_20_std': 0.02782906976329559,\n",
       "   'nauc_map_at_3_diff1': 0.6438760657101258,\n",
       "   'nauc_map_at_3_max': 0.2140629177435173,\n",
       "   'nauc_map_at_3_std': 0.036360395686659185,\n",
       "   'nauc_map_at_5_diff1': 0.6438760657101258,\n",
       "   'nauc_map_at_5_max': 0.2140629177435173,\n",
       "   'nauc_map_at_5_std': 0.036360395686659185,\n",
       "   'nauc_mrr_at_1000_diff1': 0.6353223361063849,\n",
       "   'nauc_mrr_at_1000_max': 0.2035104553996245,\n",
       "   'nauc_mrr_at_1000_std': 0.02782906976329559,\n",
       "   'nauc_mrr_at_100_diff1': 0.6353223361063849,\n",
       "   'nauc_mrr_at_100_max': 0.2035104553996245,\n",
       "   'nauc_mrr_at_100_std': 0.02782906976329559,\n",
       "   'nauc_mrr_at_10_diff1': 0.6370034173211229,\n",
       "   'nauc_mrr_at_10_max': 0.19377256262184606,\n",
       "   'nauc_mrr_at_10_std': 0.01512682217835213,\n",
       "   'nauc_mrr_at_1_diff1': 0.6110874868512343,\n",
       "   'nauc_mrr_at_1_max': 0.19104317271323365,\n",
       "   'nauc_mrr_at_1_std': 0.03034847026700385,\n",
       "   'nauc_mrr_at_20_diff1': 0.6353223361063849,\n",
       "   'nauc_mrr_at_20_max': 0.2035104553996245,\n",
       "   'nauc_mrr_at_20_std': 0.02782906976329559,\n",
       "   'nauc_mrr_at_3_diff1': 0.6438760657101258,\n",
       "   'nauc_mrr_at_3_max': 0.2140629177435173,\n",
       "   'nauc_mrr_at_3_std': 0.036360395686659185,\n",
       "   'nauc_mrr_at_5_diff1': 0.6438760657101258,\n",
       "   'nauc_mrr_at_5_max': 0.2140629177435173,\n",
       "   'nauc_mrr_at_5_std': 0.036360395686659185,\n",
       "   'nauc_ndcg_at_1000_diff1': 0.6376252234064418,\n",
       "   'nauc_ndcg_at_1000_max': 0.20324133629400792,\n",
       "   'nauc_ndcg_at_1000_std': 0.025358858437553897,\n",
       "   'nauc_ndcg_at_100_diff1': 0.6376252234064418,\n",
       "   'nauc_ndcg_at_100_max': 0.20324133629400792,\n",
       "   'nauc_ndcg_at_100_std': 0.025358858437553897,\n",
       "   'nauc_ndcg_at_10_diff1': 0.6442646329665219,\n",
       "   'nauc_ndcg_at_10_max': 0.16440703457502417,\n",
       "   'nauc_ndcg_at_10_std': -0.025236427243361635,\n",
       "   'nauc_ndcg_at_1_diff1': 0.6110874868512343,\n",
       "   'nauc_ndcg_at_1_max': 0.19104317271323365,\n",
       "   'nauc_ndcg_at_1_std': 0.03034847026700385,\n",
       "   'nauc_ndcg_at_20_diff1': 0.6376252234064418,\n",
       "   'nauc_ndcg_at_20_max': 0.20324133629400792,\n",
       "   'nauc_ndcg_at_20_std': 0.025358858437553897,\n",
       "   'nauc_ndcg_at_3_diff1': 0.6598312634614598,\n",
       "   'nauc_ndcg_at_3_max': 0.22479518473000445,\n",
       "   'nauc_ndcg_at_3_std': 0.038059373958123276,\n",
       "   'nauc_ndcg_at_5_diff1': 0.6598312634614598,\n",
       "   'nauc_ndcg_at_5_max': 0.22479518473000445,\n",
       "   'nauc_ndcg_at_5_std': 0.038059373958123276,\n",
       "   'nauc_precision_at_1000_diff1': nan,\n",
       "   'nauc_precision_at_1000_max': nan,\n",
       "   'nauc_precision_at_1000_std': nan,\n",
       "   'nauc_precision_at_100_diff1': nan,\n",
       "   'nauc_precision_at_100_max': nan,\n",
       "   'nauc_precision_at_100_std': nan,\n",
       "   'nauc_precision_at_10_diff1': 0.8692810457516413,\n",
       "   'nauc_precision_at_10_max': -1.1517273576097316,\n",
       "   'nauc_precision_at_10_std': -1.7399626517273863,\n",
       "   'nauc_precision_at_1_diff1': 0.6110874868512343,\n",
       "   'nauc_precision_at_1_max': 0.19104317271323365,\n",
       "   'nauc_precision_at_1_std': 0.03034847026700385,\n",
       "   'nauc_precision_at_20_diff1': 1.0,\n",
       "   'nauc_precision_at_20_max': 1.0,\n",
       "   'nauc_precision_at_20_std': 1.0,\n",
       "   'nauc_precision_at_3_diff1': 0.8068394024276336,\n",
       "   'nauc_precision_at_3_max': 0.32317927170868604,\n",
       "   'nauc_precision_at_3_std': 0.052404295051353494,\n",
       "   'nauc_precision_at_5_diff1': 0.8068394024276381,\n",
       "   'nauc_precision_at_5_max': 0.3231792717086866,\n",
       "   'nauc_precision_at_5_std': 0.05240429505135564,\n",
       "   'nauc_recall_at_1000_diff1': nan,\n",
       "   'nauc_recall_at_1000_max': nan,\n",
       "   'nauc_recall_at_1000_std': nan,\n",
       "   'nauc_recall_at_100_diff1': nan,\n",
       "   'nauc_recall_at_100_max': nan,\n",
       "   'nauc_recall_at_100_std': nan,\n",
       "   'nauc_recall_at_10_diff1': 0.8692810457516276,\n",
       "   'nauc_recall_at_10_max': -1.151727357609709,\n",
       "   'nauc_recall_at_10_std': -1.739962651727339,\n",
       "   'nauc_recall_at_1_diff1': 0.6110874868512343,\n",
       "   'nauc_recall_at_1_max': 0.19104317271323365,\n",
       "   'nauc_recall_at_1_std': 0.03034847026700385,\n",
       "   'nauc_recall_at_20_diff1': nan,\n",
       "   'nauc_recall_at_20_max': nan,\n",
       "   'nauc_recall_at_20_std': nan,\n",
       "   'nauc_recall_at_3_diff1': 0.8068394024276366,\n",
       "   'nauc_recall_at_3_max': 0.32317927170868493,\n",
       "   'nauc_recall_at_3_std': 0.05240429505135521,\n",
       "   'nauc_recall_at_5_diff1': 0.8068394024276366,\n",
       "   'nauc_recall_at_5_max': 0.32317927170868493,\n",
       "   'nauc_recall_at_5_std': 0.05240429505135521,\n",
       "   'ndcg_at_1': 0.77,\n",
       "   'ndcg_at_10': 0.89477,\n",
       "   'ndcg_at_100': 0.89756,\n",
       "   'ndcg_at_1000': 0.89756,\n",
       "   'ndcg_at_20': 0.89756,\n",
       "   'ndcg_at_3': 0.88464,\n",
       "   'ndcg_at_5': 0.88464,\n",
       "   'precision_at_1': 0.77,\n",
       "   'precision_at_10': 0.099,\n",
       "   'precision_at_100': 0.01,\n",
       "   'precision_at_1000': 0.001,\n",
       "   'precision_at_20': 0.05,\n",
       "   'precision_at_3': 0.32,\n",
       "   'precision_at_5': 0.192,\n",
       "   'recall_at_1': 0.77,\n",
       "   'recall_at_10': 0.99,\n",
       "   'recall_at_100': 1.0,\n",
       "   'recall_at_1000': 1.0,\n",
       "   'recall_at_20': 1.0,\n",
       "   'recall_at_3': 0.96,\n",
       "   'recall_at_5': 0.96}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res.task_results[0].scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5060132-4f1e-4b30-abf2-71aa9567662b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d35c4d5-a831-4446-8911-7e034494d6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'main_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m results_to_dataframe(results)\n",
      "File \u001b[0;32m~/Oracle/oracle/devops/multimodal_retrieval/image/mteb_github/mteb/task_selection.py:64\u001b[0m, in \u001b[0;36mresults_to_dataframe\u001b[0;34m(mteb_results, drop_na, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m drop_na:\n\u001b[1;32m     63\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mpivot_table(\n\u001b[1;32m     65\u001b[0m     index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     66\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     67\u001b[0m     values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/image_retrieval/lib/python3.12/site-packages/pandas/core/frame.py:9509\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m   9492\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9493\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   9494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot_table\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9505\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   9506\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9507\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot_table\n\u001b[0;32m-> 9509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pivot_table(\n\u001b[1;32m   9510\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9511\u001b[0m         values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m   9512\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   9513\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   9514\u001b[0m         aggfunc\u001b[38;5;241m=\u001b[39maggfunc,\n\u001b[1;32m   9515\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   9516\u001b[0m         margins\u001b[38;5;241m=\u001b[39mmargins,\n\u001b[1;32m   9517\u001b[0m         dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   9518\u001b[0m         margins_name\u001b[38;5;241m=\u001b[39mmargins_name,\n\u001b[1;32m   9519\u001b[0m         observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   9520\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   9521\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/image_retrieval/lib/python3.12/site-packages/pandas/core/reshape/pivot.py:102\u001b[0m, in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m     99\u001b[0m     table \u001b[38;5;241m=\u001b[39m concat(pieces, keys\u001b[38;5;241m=\u001b[39mkeys, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m table \u001b[38;5;241m=\u001b[39m __internal_pivot_table(\n\u001b[1;32m    103\u001b[0m     data,\n\u001b[1;32m    104\u001b[0m     values,\n\u001b[1;32m    105\u001b[0m     index,\n\u001b[1;32m    106\u001b[0m     columns,\n\u001b[1;32m    107\u001b[0m     aggfunc,\n\u001b[1;32m    108\u001b[0m     fill_value,\n\u001b[1;32m    109\u001b[0m     margins,\n\u001b[1;32m    110\u001b[0m     dropna,\n\u001b[1;32m    111\u001b[0m     margins_name,\n\u001b[1;32m    112\u001b[0m     observed,\n\u001b[1;32m    113\u001b[0m     sort,\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/image_retrieval/lib/python3.12/site-packages/pandas/core/reshape/pivot.py:148\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m--> 148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(i)\n\u001b[1;32m    150\u001b[0m to_filter \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;241m+\u001b[39m values:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'main_score'"
     ]
    }
   ],
   "source": [
    "df = results_to_dataframe(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7df6cb-e0f2-4aa0-84c7-ce057400e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mteb.load_results.benchmark_results.BenchmarkResults"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c9f3f51-48b8-4f26-9c73-d3b23b316283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results_to_dataframe(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbbbe6a1-b691-4ab4-9f2a-675e4647ec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>AILACasedocs</th>\n",
       "      <th>AILAStatutes</th>\n",
       "      <th>BSARDRetrieval</th>\n",
       "      <th>LegalBenchConsumerContractsQA</th>\n",
       "      <th>LegalBenchCorporateLobbying</th>\n",
       "      <th>LegalSummarization</th>\n",
       "      <th>SyntecRetrieval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Revision</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GritLM/GritLM-7B</th>\n",
       "      <th>13f00a0e36500c80ce12870ea513846a066004af</th>\n",
       "      <td>0.35292</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.71171</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>0.94999</td>\n",
       "      <td>0.70645</td>\n",
       "      <td>0.89477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task                                                       AILACasedocs  \\\n",
       "Model            Revision                                                 \n",
       "GritLM/GritLM-7B 13f00a0e36500c80ce12870ea513846a066004af       0.35292   \n",
       "\n",
       "task                                                       AILAStatutes  \\\n",
       "Model            Revision                                                 \n",
       "GritLM/GritLM-7B 13f00a0e36500c80ce12870ea513846a066004af         0.418   \n",
       "\n",
       "task                                                       BSARDRetrieval  \\\n",
       "Model            Revision                                                   \n",
       "GritLM/GritLM-7B 13f00a0e36500c80ce12870ea513846a066004af         0.71171   \n",
       "\n",
       "task                                                       LegalBenchConsumerContractsQA  \\\n",
       "Model            Revision                                                                  \n",
       "GritLM/GritLM-7B 13f00a0e36500c80ce12870ea513846a066004af                         0.8205   \n",
       "\n",
       "task                                                       LegalBenchCorporateLobbying  \\\n",
       "Model            Revision                                                                \n",
       "GritLM/GritLM-7B 13f00a0e36500c80ce12870ea513846a066004af                      0.94999   \n",
       "\n",
       "task                                                       LegalSummarization  \\\n",
       "Model            Revision                                                       \n",
       "GritLM/GritLM-7B 13f00a0e36500c80ce12870ea513846a066004af             0.70645   \n",
       "\n",
       "task                                                       SyntecRetrieval  \n",
       "Model            Revision                                                   \n",
       "GritLM/GritLM-7B 13f00a0e36500c80ce12870ea513846a066004af          0.89477  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5b1b8-65a5-4104-802d-3cf0055a7060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e562b152-7622-42bb-aa4b-709d91135ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9cfdf92-98f2-4d20-a6d8-3df408426d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df6a81f-0337-4367-b398-4395da88e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "from mteb.leaderboard.table import scores_to_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a654b251-7fa3-4e48-84e0-7c113c841285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb.load_results import load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2c8142-335e-4318-8608-477f3f64e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_benchmarks():\n",
    "    \"\"\"Get all available benchmark names.\"\"\"\n",
    "    return [b.name for b in mteb.get_benchmarks()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b350052-ce3a-4063-9c2b-4a61cfd2c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected benchmark\n",
    "benchmarks = mteb.get_benchmarks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "278734ed-ac5a-472b-ac9e-b8ef57218038",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_name = \"MTEB(eng, v2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b16daac9-4655-49af-86f2-bd0e872cdc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = next((b for b in benchmarks if b.name == benchmark_name), None)\n",
    "if not benchmark:\n",
    "    raise ValueError(\n",
    "        f\"Benchmark '{benchmark_name}' not found. Available: {get_available_benchmarks()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e327b0b-3836-4d58-842b-f2cfb6755a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benchmark(name='MTEB(eng, v2)', tasks=MTEBTasks(ArguAna(name='ArguAna', languages=['eng']), ArXivHierarchicalClusteringP2P(name='ArXivHierarchicalClusteringP2P', languages=['eng']), ArXivHierarchicalClusteringS2S(name='ArXivHierarchicalClusteringS2S', languages=['eng']), AskUbuntuDupQuestions(name='AskUbuntuDupQuestions', languages=['eng']), BiossesSTS(name='BIOSSES', languages=['eng']), Banking77Classification(name='Banking77Classification', languages=['eng']), BiorxivClusteringP2PFast(name='BiorxivClusteringP2P.v2', languages=['eng']), CQADupstackGamingRetrieval(name='CQADupstackGamingRetrieval', languages=['eng']), CQADupstackUnixRetrieval(name='CQADupstackUnixRetrieval', languages=['eng']), ClimateFEVERHardNegatives(name='ClimateFEVERHardNegatives', languages=['eng']), FEVERHardNegatives(name='FEVERHardNegatives', languages=['eng']), FiQA2018(name='FiQA2018', languages=['eng']), HotpotQAHardNegatives(name='HotpotQAHardNegatives', languages=['eng']), ImdbClassification(name='ImdbClassification', languages=['eng']), MTOPDomainClassification(name='MTOPDomainClassification', languages=['eng']), MassiveIntentClassification(name='MassiveIntentClassification', languages=['eng']), MassiveScenarioClassification(name='MassiveScenarioClassification', languages=['eng']), MedrxivClusteringP2PFast(name='MedrxivClusteringP2P.v2', languages=['eng']), MedrxivClusteringS2SFast(name='MedrxivClusteringS2S.v2', languages=['eng']), MindSmallReranking(name='MindSmallReranking', languages=['eng']), SCIDOCS(name='SCIDOCS', languages=['eng']), SickrSTS(name='SICK-R', languages=['eng']), STS12STS(name='STS12', languages=['eng']), STS13STS(name='STS13', languages=['eng']), STS14STS(name='STS14', languages=['eng']), STS15STS(name='STS15', languages=['eng']), STSBenchmarkSTS(name='STSBenchmark', languages=['eng']), SprintDuplicateQuestionsPC(name='SprintDuplicateQuestions', languages=['eng']), StackExchangeClusteringFast(name='StackExchangeClustering.v2', languages=['eng']), StackExchangeClusteringP2PFast(name='StackExchangeClusteringP2P.v2', languages=['eng']), TRECCOVID(name='TRECCOVID', languages=['eng']), Touche2020v3Retrieval(name='Touche2020Retrieval.v3', languages=['eng']), ToxicConversationsClassification(name='ToxicConversationsClassification', languages=['eng']), TweetSentimentExtractionClassification(name='TweetSentimentExtractionClassification', languages=['eng']), TwentyNewsgroupsClusteringFast(name='TwentyNewsgroupsClustering.v2', languages=['eng']), TwitterSemEval2015PC(name='TwitterSemEval2015', languages=['eng']), TwitterURLCorpusPC(name='TwitterURLCorpus', languages=['eng']), SummEvalSummarizationv2(name='SummEvalSummarization.v2', languages=['eng']), AmazonCounterfactualClassification(name='AmazonCounterfactualClassification', languages=['eng']), STS17Crosslingual(name='STS17', languages=['eng']), STS22CrosslingualSTSv2(name='STS22.v2', languages=['eng'])), description=\"The new English Massive Text Embedding Benchmark.\\nThis benchmark was created to account for the fact that many models have now been finetuned\\nto tasks in the original MTEB, and contains tasks that are not as frequently used for model training.\\nThis way the new benchmark and leaderboard can give our users a more realistic expectation of models' generalization performance.\\n\\nThe original MTEB leaderboard is available under the [MTEB(eng, v1)](http://mteb-leaderboard.hf.space/?benchmark_name=MTEB%28eng%2C+v1%29) tab.\\n    \", reference=None, citation='', contacts=['KennethEnevoldsen', 'Muennighoff'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f10f0ff-ccaa-4871-81c7-201dc22f16b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb.models.overview import MODEL_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b90ba792-20b4-4ad3-8796-71b935f5c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Key : BAAI/bge-m3 || Model Name : BAAI/bge-m3\n",
      "Model Key : BAAI/bge-base-en-v1.5 || Model Name : BAAI/bge-base-en-v1.5\n",
      "Model Key : Alibaba-NLP/gme-Qwen2-VL-2B-Instruct || Model Name : Alibaba-NLP/gme-Qwen2-VL-2B-Instruct\n",
      "Model Key : Alibaba-NLP/gme-Qwen2-VL-7B-Instruct || Model Name : Alibaba-NLP/gme-Qwen2-VL-7B-Instruct\n",
      "Model Key : Linq-AI-Research/Linq-Embed-Mistral || Model Name : Linq-AI-Research/Linq-Embed-Mistral\n",
      "Model Key : jinaai/jina-clip-v1 || Model Name : jinaai/jina-clip-v1\n",
      "Model Key : nyu-visionx/moco-v3-vit-b || Model Name : nyu-visionx/moco-v3-vit-b\n",
      "Model Key : nyu-visionx/moco-v3-vit-l || Model Name : nyu-visionx/moco-v3-vit-l\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    'BAAI/bge-m3',\n",
    "'BAAI/bge-base-en-v1.5',\n",
    "'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
    "'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
    "'Linq-AI-Research/Linq-Embed-Mistral',\n",
    "'jinaai/jina-clip-v1',\n",
    "'nyu-visionx/moco-v3-vit-b',\n",
    "'nyu-visionx/moco-v3-vit-l'\n",
    "]\n",
    "for model in models :\n",
    "    print(f\"Model Key : {model} || Model Name : {MODEL_REGISTRY[model].name}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "935cb936-ca1e-4813-81c5-f4aeb9c80e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelMeta(name='nyu-visionx/moco-v3-vit-l', revision='7bf75358d616f39b9716148bf4e3425f3bd35b47', release_date='2024-06-03', languages=['eng_Latn'], loader=functools.partial(<function mocov3_loader at 0x173bd37e0>, model_name='nyu-visionx/moco-v3-vit-l'), n_parameters=304000000, memory_usage_mb=1161.0, max_tokens=None, embed_dim=1024, license='cc-by-nc-4.0', open_weights=True, public_training_code='https://github.com/facebookresearch/moco-v3', public_training_data=None, framework=['PyTorch'], reference='https://github.com/facebookresearch/moco-v3', similarity_fn_name=None, use_instructions=False, training_datasets={}, adapted_from=None, superseded_by=None, is_cross_encoder=None, modalities=['image'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_REGISTRY[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95a1fdd5-fcc4-405f-8a1c-66ea90b93dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify what you want to evaluate it on\n",
    "tasks = mteb.get_tasks(languages=[\"eng\"],modalities=[\"text\", \"image\"],task_types=[\n",
    "                                                                                \"Any2AnyRetrieval\", \n",
    "                                                                                  # \"Compositionality\",\n",
    "                                                                                  # \"DocumentUnderstanding\", \n",
    "    # \"VisionCentric\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d39a618-4338-493f-816e-7e763bf0cc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b93c550-dd5e-413d-93b6-c9db3b1c1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "'BAAI/bge-m3',\n",
    "'BAAI/bge-base-en-v1.5',\n",
    "'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
    "'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
    "'Linq-AI-Research/Linq-Embed-Mistral',\n",
    "'jinaai/jina-clip-v1',\n",
    "'nyu-visionx/moco-v3-vit-b',\n",
    "'nyu-visionx/moco-v3-vit-l'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6716adc3-9ea9-4db0-8cd6-e386c1dfdd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       " 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       " 'BAAI/bge-base-en-v1.5',\n",
       " 'BAAI/bge-m3',\n",
       " 'Linq-AI-Research/Linq-Embed-Mistral',\n",
       " 'jinaai/jina-clip-v1',\n",
       " 'nyu-visionx/moco-v3-vit-b',\n",
       " 'nyu-visionx/moco-v3-vit-l'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b0836-6781-44cd-99dd-9dd43eeab0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "export MTEB_CACHE=\"/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f922537-8e92-41de-a5c6-c17b941be1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "export MTEB_CACHE=\"/Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/\"\n",
    "python scripts/make_leaderboard.py --benchmark \"MTEB(eng, v2)\" --results_repo /Users/aamita/Oracle/oracle/devops/multimodal_retrieval/image/mteb-results --models \"potion-base-8M\" --save-path \"leader_board_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9aef1595-a84b-45e1-8741-e79b51fe6344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>BLINKIT2IRetrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>BLINKIT2TRetrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>CIRRIT2IRetrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>CUB200I2IRetrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>EDIST2ITRetrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>VisionCentricQA</td>\n",
       "      <td>BLINKIT2TMultiChoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>VisionCentricQA</td>\n",
       "      <td>CVBenchCount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>VisionCentricQA</td>\n",
       "      <td>CVBenchDepth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>VisionCentricQA</td>\n",
       "      <td>CVBenchDistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>VisionCentricQA</td>\n",
       "      <td>CVBenchRelation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           task_type                  task\n",
       "0   Any2AnyRetrieval    BLINKIT2IRetrieval\n",
       "1   Any2AnyRetrieval    BLINKIT2TRetrieval\n",
       "2   Any2AnyRetrieval     CIRRIT2IRetrieval\n",
       "3   Any2AnyRetrieval    CUB200I2IRetrieval\n",
       "4   Any2AnyRetrieval     EDIST2ITRetrieval\n",
       "..               ...                   ...\n",
       "59   VisionCentricQA  BLINKIT2TMultiChoice\n",
       "60   VisionCentricQA          CVBenchCount\n",
       "61   VisionCentricQA          CVBenchDepth\n",
       "62   VisionCentricQA       CVBenchDistance\n",
       "63   VisionCentricQA       CVBenchRelation\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_all  = pd.DataFrame(data)\n",
    "# Sort by 'task_type' and then 'task'\n",
    "sorted_df = bench_all.sort_values(by=['task_type', 'task'])\n",
    "\n",
    "# Get unique combinations of 'task_type' and 'task'\n",
    "unique_tasks_df = sorted_df[['task_type', 'task']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "unique_tasks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "864e971b-fd2f-4f54-9c4f-90c653057284",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tasks_df.to_excel(\"all_tasks_benchmarked_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b33c68c3-65ae-4c01-b925-e2901565aba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Count how many unique models exist\n",
    "unique_models = bench_all['Model'].unique()\n",
    "num_models = len(unique_models)\n",
    "num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f70569f8-ba2c-49f8-8928-5358caf56246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 2: Count how many models are present per task\n",
    "task_model_counts = bench_all.groupby('task')['Model'].nunique().reset_index()\n",
    "task_model_counts = task_model_counts[task_model_counts['Model'] == num_models]\n",
    "\n",
    "task_model_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f278565-f12a-48f5-a39f-fd42e260e9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Revision</th>\n",
       "      <th>task</th>\n",
       "      <th>task_type</th>\n",
       "      <th>ndcg_at_5</th>\n",
       "      <th>main_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>SciMMIRI2TRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.20377</td>\n",
       "      <td>0.22010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>MSCOCOT2IRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.57768</td>\n",
       "      <td>0.60941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>SketchyI2IRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.78612</td>\n",
       "      <td>0.79511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>CUB200I2IRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.39635</td>\n",
       "      <td>0.65948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>SOPI2IRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.60061</td>\n",
       "      <td>0.47910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>TIGER-Lab/VLM2Vec-Qwen2VL-7B</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>VisualNewsT2IRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.13099</td>\n",
       "      <td>0.14922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>TIGER-Lab/VLM2Vec-Qwen2VL-7B</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>Flickr30kI2TRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.71262</td>\n",
       "      <td>0.78750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>TIGER-Lab/VLM2Vec-Qwen2VL-7B</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>RParisMediumI2IRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.93043</td>\n",
       "      <td>0.02507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>TIGER-Lab/VLM2Vec-Qwen2VL-7B</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>ROxfordMediumI2IRetrieval</td>\n",
       "      <td>Any2AnyRetrieval</td>\n",
       "      <td>0.40172</td>\n",
       "      <td>0.05440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>TIGER-Lab/VLM2Vec-Qwen2VL-7B</td>\n",
       "      <td>f2f1c2194823b780632c628548d85a03939d896c</td>\n",
       "      <td>VidoreTabfquadRetrieval</td>\n",
       "      <td>DocumentUnderstanding</td>\n",
       "      <td>0.62301</td>\n",
       "      <td>0.62301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Model  \\\n",
       "1    OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora   \n",
       "2    OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora   \n",
       "5    OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora   \n",
       "6    OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora   \n",
       "7    OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora   \n",
       "..                                       ...   \n",
       "712             TIGER-Lab/VLM2Vec-Qwen2VL-7B   \n",
       "713             TIGER-Lab/VLM2Vec-Qwen2VL-7B   \n",
       "714             TIGER-Lab/VLM2Vec-Qwen2VL-7B   \n",
       "715             TIGER-Lab/VLM2Vec-Qwen2VL-7B   \n",
       "718             TIGER-Lab/VLM2Vec-Qwen2VL-7B   \n",
       "\n",
       "                                     Revision                       task  \\\n",
       "1    f2f1c2194823b780632c628548d85a03939d896c        SciMMIRI2TRetrieval   \n",
       "2    f2f1c2194823b780632c628548d85a03939d896c         MSCOCOT2IRetrieval   \n",
       "5    f2f1c2194823b780632c628548d85a03939d896c        SketchyI2IRetrieval   \n",
       "6    f2f1c2194823b780632c628548d85a03939d896c         CUB200I2IRetrieval   \n",
       "7    f2f1c2194823b780632c628548d85a03939d896c            SOPI2IRetrieval   \n",
       "..                                        ...                        ...   \n",
       "712  f2f1c2194823b780632c628548d85a03939d896c     VisualNewsT2IRetrieval   \n",
       "713  f2f1c2194823b780632c628548d85a03939d896c      Flickr30kI2TRetrieval   \n",
       "714  f2f1c2194823b780632c628548d85a03939d896c   RParisMediumI2IRetrieval   \n",
       "715  f2f1c2194823b780632c628548d85a03939d896c  ROxfordMediumI2IRetrieval   \n",
       "718  f2f1c2194823b780632c628548d85a03939d896c    VidoreTabfquadRetrieval   \n",
       "\n",
       "                 task_type  ndcg_at_5  main_score  \n",
       "1         Any2AnyRetrieval    0.20377     0.22010  \n",
       "2         Any2AnyRetrieval    0.57768     0.60941  \n",
       "5         Any2AnyRetrieval    0.78612     0.79511  \n",
       "6         Any2AnyRetrieval    0.39635     0.65948  \n",
       "7         Any2AnyRetrieval    0.60061     0.47910  \n",
       "..                     ...        ...         ...  \n",
       "712       Any2AnyRetrieval    0.13099     0.14922  \n",
       "713       Any2AnyRetrieval    0.71262     0.78750  \n",
       "714       Any2AnyRetrieval    0.93043     0.02507  \n",
       "715       Any2AnyRetrieval    0.40172     0.05440  \n",
       "718  DocumentUnderstanding    0.62301     0.62301  \n",
       "\n",
       "[396 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Filter bench_all to keep only those tasks\n",
    "filtered_df = bench_all[bench_all['task'].isin(task_model_counts['task'])]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8e21f47-2286-4ce8-a6e2-35d67db864e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_df = (\n",
    "    bench_all\n",
    "    .assign(present=1)\n",
    "    .pivot_table(index='task', columns='Model', values='present', fill_value=0)\n",
    "    .astype(int)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c91f8587-b51a-4f87-9a4d-7126137bb170",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.groupby(['Model','task_type'])['ndcg_at_5'].mean().reset_index()\n",
    "filtered_df_pivoted = filtered_df.pivot(index='Model', columns='task_type', values='ndcg_at_5')\n",
    "filtered_df_pivoted['Avg'] = filtered_df_pivoted.mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "296b3530-61d7-40b7-bf19-ac3834a3a4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>task_type</th>\n",
       "      <th>Any2AnyRetrieval</th>\n",
       "      <th>DocumentUnderstanding</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP/gme-Qwen2-VL-2B-Instruct</th>\n",
       "      <td>0.549</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alibaba-NLP/gme-Qwen2-VL-7B-Instruct</th>\n",
       "      <td>0.546</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode</th>\n",
       "      <td>0.428</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Full</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-2B</th>\n",
       "      <td>0.409</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-7B</th>\n",
       "      <td>0.403</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/siglip-large-patch16-384</th>\n",
       "      <td>0.557</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/siglip-so400m-patch14-384</th>\n",
       "      <td>0.571</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laion/CLIP-ViT-bigG-14-laion2B-39B-b160k</th>\n",
       "      <td>0.559</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>royokong/e5-v</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task_type                                          Any2AnyRetrieval  \\\n",
       "Model                                                                 \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                          0.549   \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                          0.546   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                       0.392   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora                       0.445   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode             0.428   \n",
       "TIGER-Lab/VLM2Vec-Full                                        0.417   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                  0.409   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                  0.403   \n",
       "google/siglip-large-patch16-384                               0.557   \n",
       "google/siglip-so400m-patch14-384                              0.571   \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                      0.559   \n",
       "royokong/e5-v                                                 0.469   \n",
       "\n",
       "task_type                                          DocumentUnderstanding  \\\n",
       "Model                                                                      \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct                               0.946   \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct                               0.958   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full                            0.530   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora                            0.597   \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode                  0.559   \n",
       "TIGER-Lab/VLM2Vec-Full                                             0.532   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                                       0.440   \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                                       0.564   \n",
       "google/siglip-large-patch16-384                                    0.568   \n",
       "google/siglip-so400m-patch14-384                                   0.587   \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k                           0.438   \n",
       "royokong/e5-v                                                      0.673   \n",
       "\n",
       "task_type                                            Avg  \n",
       "Model                                                     \n",
       "Alibaba-NLP/gme-Qwen2-VL-2B-Instruct               0.747  \n",
       "Alibaba-NLP/gme-Qwen2-VL-7B-Instruct               0.752  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full            0.461  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora            0.521  \n",
       "OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode  0.494  \n",
       "TIGER-Lab/VLM2Vec-Full                             0.475  \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-2B                       0.425  \n",
       "TIGER-Lab/VLM2Vec-Qwen2VL-7B                       0.484  \n",
       "google/siglip-large-patch16-384                    0.563  \n",
       "google/siglip-so400m-patch14-384                   0.579  \n",
       "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k           0.498  \n",
       "royokong/e5-v                                      0.571  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_pivoted.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "def2b89e-ea6b-42a6-8994-c0eb418ab0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full</th>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora</th>\n",
       "      <th>OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode</th>\n",
       "      <th>TIGER-Lab/VLM2Vec-Full</th>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-2B</th>\n",
       "      <th>TIGER-Lab/VLM2Vec-Qwen2VL-7B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLINKIT2IMultiChoice</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLINKIT2IRetrieval</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLINKIT2TMultiChoice</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLINKIT2TRetrieval</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIRRIT2IRetrieval</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VisualNewsI2TRetrieval</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VisualNewsT2IRetrieval</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VizWizIT2TRetrieval</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebQAT2ITRetrieval</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebQAT2TRetrieval</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                   OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full  \\\n",
       "task                                                              \n",
       "BLINKIT2IMultiChoice                                          0   \n",
       "BLINKIT2IRetrieval                                            0   \n",
       "BLINKIT2TMultiChoice                                          0   \n",
       "BLINKIT2TRetrieval                                            0   \n",
       "CIRRIT2IRetrieval                                             1   \n",
       "...                                                         ...   \n",
       "VisualNewsI2TRetrieval                                        1   \n",
       "VisualNewsT2IRetrieval                                        1   \n",
       "VizWizIT2TRetrieval                                           1   \n",
       "WebQAT2ITRetrieval                                            1   \n",
       "WebQAT2TRetrieval                                             1   \n",
       "\n",
       "Model                   OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora  \\\n",
       "task                                                              \n",
       "BLINKIT2IMultiChoice                                          1   \n",
       "BLINKIT2IRetrieval                                            1   \n",
       "BLINKIT2TMultiChoice                                          1   \n",
       "BLINKIT2TRetrieval                                            1   \n",
       "CIRRIT2IRetrieval                                             1   \n",
       "...                                                         ...   \n",
       "VisualNewsI2TRetrieval                                        1   \n",
       "VisualNewsT2IRetrieval                                        1   \n",
       "VizWizIT2TRetrieval                                           1   \n",
       "WebQAT2ITRetrieval                                            1   \n",
       "WebQAT2TRetrieval                                             1   \n",
       "\n",
       "Model                   OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode  \\\n",
       "task                                                                        \n",
       "BLINKIT2IMultiChoice                                                    1   \n",
       "BLINKIT2IRetrieval                                                      1   \n",
       "BLINKIT2TMultiChoice                                                    1   \n",
       "BLINKIT2TRetrieval                                                      1   \n",
       "CIRRIT2IRetrieval                                                       1   \n",
       "...                                                                   ...   \n",
       "VisualNewsI2TRetrieval                                                  1   \n",
       "VisualNewsT2IRetrieval                                                  1   \n",
       "VizWizIT2TRetrieval                                                     1   \n",
       "WebQAT2ITRetrieval                                                      1   \n",
       "WebQAT2TRetrieval                                                       1   \n",
       "\n",
       "Model                   TIGER-Lab/VLM2Vec-Full  TIGER-Lab/VLM2Vec-Qwen2VL-2B  \\\n",
       "task                                                                           \n",
       "BLINKIT2IMultiChoice                         1                             1   \n",
       "BLINKIT2IRetrieval                           1                             0   \n",
       "BLINKIT2TMultiChoice                         1                             1   \n",
       "BLINKIT2TRetrieval                           1                             0   \n",
       "CIRRIT2IRetrieval                            1                             0   \n",
       "...                                        ...                           ...   \n",
       "VisualNewsI2TRetrieval                       1                             1   \n",
       "VisualNewsT2IRetrieval                       1                             1   \n",
       "VizWizIT2TRetrieval                          1                             0   \n",
       "WebQAT2ITRetrieval                           1                             0   \n",
       "WebQAT2TRetrieval                            1                             1   \n",
       "\n",
       "Model                   TIGER-Lab/VLM2Vec-Qwen2VL-7B  \n",
       "task                                                  \n",
       "BLINKIT2IMultiChoice                               1  \n",
       "BLINKIT2IRetrieval                                 1  \n",
       "BLINKIT2TMultiChoice                               1  \n",
       "BLINKIT2TRetrieval                                 1  \n",
       "CIRRIT2IRetrieval                                  1  \n",
       "...                                              ...  \n",
       "VisualNewsI2TRetrieval                             1  \n",
       "VisualNewsT2IRetrieval                             1  \n",
       "VizWizIT2TRetrieval                                1  \n",
       "WebQAT2ITRetrieval                                 1  \n",
       "WebQAT2TRetrieval                                  1  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c60195f-ca06-4a75-aa09-9e45ad206f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/aamita/miniconda3/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /Users/aamita/miniconda3/lib/python3.12/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e156066e-9134-4adf-95a9-0ccbf8cddb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.65373,\n",
       "  'main_score': 0.65373},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20377,\n",
       "  'main_score': 0.2201},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.57768,\n",
       "  'main_score': 0.60941},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17919,\n",
       "  'main_score': 0.21391},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.59994,\n",
       "  'main_score': 0.59994},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.78612,\n",
       "  'main_score': 0.79511},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.39635,\n",
       "  'main_score': 0.65948},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.60061,\n",
       "  'main_score': 0.4791},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20392,\n",
       "  'main_score': 0.32902},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01367,\n",
       "  'main_score': 0.01809},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.59641,\n",
       "  'main_score': 0.59641},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03959,\n",
       "  'main_score': 0.21542},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.85967,\n",
       "  'main_score': 0.04252},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.13206,\n",
       "  'main_score': 0.16745},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47134,\n",
       "  'main_score': 0.49127},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.32126,\n",
       "  'main_score': 0.35084},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.27367,\n",
       "  'main_score': 0.27367},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04651,\n",
       "  'main_score': 0.05122},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.68112,\n",
       "  'main_score': 0.68112},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.13147,\n",
       "  'main_score': 0.1153},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.08473,\n",
       "  'main_score': 0.09044},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.16347,\n",
       "  'main_score': 0.1857},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80439,\n",
       "  'main_score': 0.47},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.1877,\n",
       "  'main_score': 0.24659},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.36551,\n",
       "  'main_score': 0.45497},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.83835,\n",
       "  'main_score': 0.84964},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.54686,\n",
       "  'main_score': 0.16516},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.24481,\n",
       "  'main_score': 0.24481},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.62828,\n",
       "  'main_score': 0.75918},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.34717,\n",
       "  'main_score': 0.37919},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.90084,\n",
       "  'main_score': 0.89925},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97516,\n",
       "  'main_score': 0.11335},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.46554,\n",
       "  'main_score': 0.54108},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17821,\n",
       "  'main_score': 0.19382},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.06477,\n",
       "  'main_score': 0.07203},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80937,\n",
       "  'main_score': 0.57741},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.83023,\n",
       "  'main_score': 0.54},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.48085,\n",
       "  'main_score': 0.49548},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02376,\n",
       "  'main_score': 0.03037},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.74078,\n",
       "  'main_score': 0.74078},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3559,\n",
       "  'main_score': 0.63873},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26093,\n",
       "  'main_score': 0.05987},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.84783,\n",
       "  'main_score': 0.58769},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12506,\n",
       "  'main_score': 0.14718},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.209,\n",
       "  'main_score': 0.23148},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09097,\n",
       "  'main_score': 0.11922},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04063,\n",
       "  'main_score': 0.05048},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.89626,\n",
       "  'main_score': 0.71891},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.66548,\n",
       "  'main_score': 0.54913},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.298,\n",
       "  'main_score': 0.33576},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.48234,\n",
       "  'main_score': 0.48234},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.33373,\n",
       "  'main_score': 0.36743},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.75412,\n",
       "  'main_score': 0.42371},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.47872,\n",
       "  'main_score': 0.47872},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.16933,\n",
       "  'main_score': 0.19104},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70114,\n",
       "  'main_score': 0.77789},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.9875,\n",
       "  'main_score': 0.02727},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.57051,\n",
       "  'main_score': 0.09004},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.16403,\n",
       "  'main_score': 0.18779},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.588,\n",
       "  'main_score': 0.63574},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.68898,\n",
       "  'main_score': 0.68898},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.59948,\n",
       "  'main_score': 0.59948},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.27916,\n",
       "  'main_score': 0.29756},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.62958,\n",
       "  'main_score': 0.65603},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.108,\n",
       "  'main_score': 0.13758},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.55419,\n",
       "  'main_score': 0.55419},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.77705,\n",
       "  'main_score': 0.7889},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.511,\n",
       "  'main_score': 0.81205},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70624,\n",
       "  'main_score': 0.65432},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.27676,\n",
       "  'main_score': 0.43821},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.34359,\n",
       "  'main_score': 0.31208},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.1182,\n",
       "  'main_score': 0.14207},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.90416,\n",
       "  'main_score': 0.90757},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.62274,\n",
       "  'main_score': 0.62274},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03426,\n",
       "  'main_score': 0.16508},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.46448,\n",
       "  'main_score': 0.41429},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01565,\n",
       "  'main_score': 0.0209},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.50174,\n",
       "  'main_score': 0.52341},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.6631,\n",
       "  'main_score': 0.67437},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.61024,\n",
       "  'main_score': 0.53849},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.1621,\n",
       "  'main_score': 0.1621},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04694,\n",
       "  'main_score': 0.05738},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.61853,\n",
       "  'main_score': 0.61853},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.19162,\n",
       "  'main_score': 0.16194},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.05857,\n",
       "  'main_score': 0.06536},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.41833,\n",
       "  'main_score': 0.44503},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.78655,\n",
       "  'main_score': 0.42167},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.19341,\n",
       "  'main_score': 0.26015},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.76353,\n",
       "  'main_score': 0.8235},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.87603,\n",
       "  'main_score': 0.88406},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.88584,\n",
       "  'main_score': 0.92647},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.22189,\n",
       "  'main_score': 0.22189},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.53326,\n",
       "  'main_score': 0.60801},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.78682,\n",
       "  'main_score': 0.80053},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.92442,\n",
       "  'main_score': 0.92127},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97174,\n",
       "  'main_score': 0.98571},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.52976,\n",
       "  'main_score': 0.60177},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.27233,\n",
       "  'main_score': 0.29046},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.22793,\n",
       "  'main_score': 0.26278},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.50687,\n",
       "  'main_score': 0.04188},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80501,\n",
       "  'main_score': 0.47167},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.93413,\n",
       "  'main_score': 0.93697},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.13423,\n",
       "  'main_score': 0.1539},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.57857,\n",
       "  'main_score': 0.57857},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.59293,\n",
       "  'main_score': 0.90822},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.27688,\n",
       "  'main_score': 0.32857},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'EncyclopediaVQAIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26749,\n",
       "  'main_score': 0.38098},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80922,\n",
       "  'main_score': 0.48308},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.65436,\n",
       "  'main_score': 0.6632},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.08249,\n",
       "  'main_score': 0.09891},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10771,\n",
       "  'main_score': 0.13619},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03813,\n",
       "  'main_score': 0.0516},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.90085,\n",
       "  'main_score': 0.73134},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.75317,\n",
       "  'main_score': 0.68944},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.32812,\n",
       "  'main_score': 0.36337},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.24954,\n",
       "  'main_score': 0.24954},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4274,\n",
       "  'main_score': 0.46104},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.76142,\n",
       "  'main_score': 0.44136},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.38836,\n",
       "  'main_score': 0.38836},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.42013,\n",
       "  'main_score': 0.44646},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.81133,\n",
       "  'main_score': 0.8779},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.99208,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.87615,\n",
       "  'main_score': 0.92857},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.27275,\n",
       "  'main_score': 0.31384},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.50933,\n",
       "  'main_score': 0.56575},\n",
       " {'Model': 'laion/CLIP-ViT-bigG-14-laion2B-39B-b160k',\n",
       "  'Revision': 'bc7788f151930d91b58474715fdce5524ad9a189',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.35015,\n",
       "  'main_score': 0.35015},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.72236,\n",
       "  'main_score': 0.72198},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.55016,\n",
       "  'main_score': 0.86244},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.60266,\n",
       "  'main_score': 0.49891},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26541,\n",
       "  'main_score': 0.43455},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.44292,\n",
       "  'main_score': 0.39726},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4905,\n",
       "  'main_score': 0.41429},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47852,\n",
       "  'main_score': 0.43487},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.19132,\n",
       "  'main_score': 0.25065},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95523,\n",
       "  'main_score': 0.97059},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.94357,\n",
       "  'main_score': 0.97143},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.377,\n",
       "  'main_score': 0.68375},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.46807,\n",
       "  'main_score': 0.45714},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.73722,\n",
       "  'main_score': 0.66818},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.99604,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'facebook/dinov2-giant',\n",
       "  'Revision': '611a9d42f2335e0f921f1e313ad3c1b7178d206d',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.96837,\n",
       "  'main_score': 0.97143},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.66497,\n",
       "  'main_score': 0.66153},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.54988,\n",
       "  'main_score': 0.85899},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.59964,\n",
       "  'main_score': 0.49259},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26245,\n",
       "  'main_score': 0.42852},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.44308,\n",
       "  'main_score': 0.39566},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47204,\n",
       "  'main_score': 0.4},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.43304,\n",
       "  'main_score': 0.38423},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18594,\n",
       "  'main_score': 0.24806},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.94447,\n",
       "  'main_score': 0.95588},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95929,\n",
       "  'main_score': 0.98571},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.37861,\n",
       "  'main_score': 0.67827},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.45287,\n",
       "  'main_score': 0.47143},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.72145,\n",
       "  'main_score': 0.64291},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.99077,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'facebook/dinov2-large',\n",
       "  'Revision': '47b73eefe95e8d44ec3623f8890bd894b6ea2d6c',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95923,\n",
       "  'main_score': 0.95714},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.66272,\n",
       "  'main_score': 0.66272},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.22756,\n",
       "  'main_score': 0.2443},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.55279,\n",
       "  'main_score': 0.58596},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17724,\n",
       "  'main_score': 0.21153},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.53911,\n",
       "  'main_score': 0.53911},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.73334,\n",
       "  'main_score': 0.74957},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.37149,\n",
       "  'main_score': 0.61805},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.59375,\n",
       "  'main_score': 0.46558},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20108,\n",
       "  'main_score': 0.32171},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01278,\n",
       "  'main_score': 0.01609},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.62732,\n",
       "  'main_score': 0.62732},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02921,\n",
       "  'main_score': 0.17162},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.8299,\n",
       "  'main_score': 0.04101},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09669,\n",
       "  'main_score': 0.1254},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.32674,\n",
       "  'main_score': 0.35988},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.24995,\n",
       "  'main_score': 0.27412},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.16823,\n",
       "  'main_score': 0.16823},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03279,\n",
       "  'main_score': 0.03628},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.5923,\n",
       "  'main_score': 0.5923},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09202,\n",
       "  'main_score': 0.08193},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04969,\n",
       "  'main_score': 0.05446},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.15522,\n",
       "  'main_score': 0.17628},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.82777,\n",
       "  'main_score': 0.53333},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17591,\n",
       "  'main_score': 0.23438},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.2442,\n",
       "  'main_score': 0.31588},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.80089,\n",
       "  'main_score': 0.81542},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.5111,\n",
       "  'main_score': 0.14415},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.23945,\n",
       "  'main_score': 0.23945},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.43215,\n",
       "  'main_score': 0.55742},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.32797,\n",
       "  'main_score': 0.36176},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.88165,\n",
       "  'main_score': 0.88493},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.96993,\n",
       "  'main_score': 0.11232},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4525,\n",
       "  'main_score': 0.52771},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14786,\n",
       "  'main_score': 0.15922},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.05429,\n",
       "  'main_score': 0.0582},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.783,\n",
       "  'main_score': 0.52792},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.87882,\n",
       "  'main_score': 0.67167},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.32455,\n",
       "  'main_score': 0.34157},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02091,\n",
       "  'main_score': 0.02618},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.68508,\n",
       "  'main_score': 0.68508},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.31315,\n",
       "  'main_score': 0.58164},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.25843,\n",
       "  'main_score': 0.06253},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.82285,\n",
       "  'main_score': 0.52},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12516,\n",
       "  'main_score': 0.14188},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18812,\n",
       "  'main_score': 0.21281},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.08736,\n",
       "  'main_score': 0.1129},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03202,\n",
       "  'main_score': 0.03845},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.87055,\n",
       "  'main_score': 0.64925},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.6372,\n",
       "  'main_score': 0.51079},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26793,\n",
       "  'main_score': 0.30046},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.43082,\n",
       "  'main_score': 0.43082},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.32643,\n",
       "  'main_score': 0.3585},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.77284,\n",
       "  'main_score': 0.46154},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.42173,\n",
       "  'main_score': 0.42173},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14036,\n",
       "  'main_score': 0.15975},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.72227,\n",
       "  'main_score': 0.79445},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.98154,\n",
       "  'main_score': 0.02705},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.54404,\n",
       "  'main_score': 0.08403},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11214,\n",
       "  'main_score': 0.12888},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.63081,\n",
       "  'main_score': 0.66887},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-lora-multinode',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.63219,\n",
       "  'main_score': 0.63219},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.67343,\n",
       "  'main_score': 0.67343},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.28141,\n",
       "  'main_score': 0.29922},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.66085,\n",
       "  'main_score': 0.68465},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12778,\n",
       "  'main_score': 0.15841},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.64865,\n",
       "  'main_score': 0.64865},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.7789,\n",
       "  'main_score': 0.79498},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49124,\n",
       "  'main_score': 0.78133},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.69718,\n",
       "  'main_score': 0.63796},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26801,\n",
       "  'main_score': 0.42842},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3128,\n",
       "  'main_score': 0.27534},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17866,\n",
       "  'main_score': 0.21056},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.96053,\n",
       "  'main_score': 0.96199},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.74524,\n",
       "  'main_score': 0.74524},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02614,\n",
       "  'main_score': 0.14229},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4674,\n",
       "  'main_score': 0.44286},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00616,\n",
       "  'main_score': 0.01005},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47755,\n",
       "  'main_score': 0.4986},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.84267,\n",
       "  'main_score': 0.84696},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70242,\n",
       "  'main_score': 0.65253},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.25256,\n",
       "  'main_score': 0.25256},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00922,\n",
       "  'main_score': 0.01093},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.65264,\n",
       "  'main_score': 0.65264},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07517,\n",
       "  'main_score': 0.06516},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01269,\n",
       "  'main_score': 0.01599},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26463,\n",
       "  'main_score': 0.28689},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80009,\n",
       "  'main_score': 0.45833},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18241,\n",
       "  'main_score': 0.24858},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.55417,\n",
       "  'main_score': 0.60571},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.89509,\n",
       "  'main_score': 0.90126},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.89518,\n",
       "  'main_score': 0.91176},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.3112,\n",
       "  'main_score': 0.3112},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.32929,\n",
       "  'main_score': 0.39922},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.64837,\n",
       "  'main_score': 0.67119},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95267,\n",
       "  'main_score': 0.94852},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95277,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.5546,\n",
       "  'main_score': 0.62354},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.29959,\n",
       "  'main_score': 0.31879},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.08926,\n",
       "  'main_score': 0.09365},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.56538,\n",
       "  'main_score': 0.08756},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.83269,\n",
       "  'main_score': 0.54667},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97867,\n",
       "  'main_score': 0.97867},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.21486,\n",
       "  'main_score': 0.24062},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.74674,\n",
       "  'main_score': 0.74674},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.6099,\n",
       "  'main_score': 0.93359},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.29801,\n",
       "  'main_score': 0.35714},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'EncyclopediaVQAIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12038,\n",
       "  'main_score': 0.16912},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.81887,\n",
       "  'main_score': 0.50923},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.82295,\n",
       "  'main_score': 0.8315},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03477,\n",
       "  'main_score': 0.04697},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10823,\n",
       "  'main_score': 0.13443},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.05912,\n",
       "  'main_score': 0.07639},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.90268,\n",
       "  'main_score': 0.73632},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70539,\n",
       "  'main_score': 0.62182},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18848,\n",
       "  'main_score': 0.21475},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.26643,\n",
       "  'main_score': 0.26643},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.28273,\n",
       "  'main_score': 0.30458},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.73185,\n",
       "  'main_score': 0.38335},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.47036,\n",
       "  'main_score': 0.47036},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.25797,\n",
       "  'main_score': 0.27904},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.81656,\n",
       "  'main_score': 0.88322},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.98439,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.89335,\n",
       "  'main_score': 0.94286},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12343,\n",
       "  'main_score': 0.14146},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.38534,\n",
       "  'main_score': 0.43245},\n",
       " {'Model': 'google/siglip-large-patch16-384',\n",
       "  'Revision': 'ce005573a40965dfd21fd937fbdeeebf2439fc35',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.61086,\n",
       "  'main_score': 0.61086},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.19341,\n",
       "  'main_score': 0.19341},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09612,\n",
       "  'main_score': 0.10651},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.55175,\n",
       "  'main_score': 0.58372},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12498,\n",
       "  'main_score': 0.15856},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.15572,\n",
       "  'main_score': 0.15572},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.33044,\n",
       "  'main_score': 0.34593},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.41011,\n",
       "  'main_score': 0.66914},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.64012,\n",
       "  'main_score': 0.56596},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.2366,\n",
       "  'main_score': 0.38762},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17963,\n",
       "  'main_score': 0.15516},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03477,\n",
       "  'main_score': 0.04176},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.78191,\n",
       "  'main_score': 0.78953},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.21834,\n",
       "  'main_score': 0.21834},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03915,\n",
       "  'main_score': 0.18371},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47523,\n",
       "  'main_score': 0.44286},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01713,\n",
       "  'main_score': 0.02373},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.45574,\n",
       "  'main_score': 0.48249},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.52258,\n",
       "  'main_score': 0.5403},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4376,\n",
       "  'main_score': 0.38113},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.03342,\n",
       "  'main_score': 0.03342},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.0293,\n",
       "  'main_score': 0.03466},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.35551,\n",
       "  'main_score': 0.35551},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.08778,\n",
       "  'main_score': 0.0797},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01989,\n",
       "  'main_score': 0.02299},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11211,\n",
       "  'main_score': 0.12769},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80439,\n",
       "  'main_score': 0.47},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.1805,\n",
       "  'main_score': 0.23867},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.87126,\n",
       "  'main_score': 0.91632},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.79521,\n",
       "  'main_score': 0.80945},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.82249,\n",
       "  'main_score': 0.83824},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.11846,\n",
       "  'main_score': 0.11846},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.72554,\n",
       "  'main_score': 0.79199},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.43906,\n",
       "  'main_score': 0.47101},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.92119,\n",
       "  'main_score': 0.90812},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97649,\n",
       "  'main_score': 0.98571},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.41452,\n",
       "  'main_score': 0.48269},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10146,\n",
       "  'main_score': 0.11106},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.1283,\n",
       "  'main_score': 0.14215},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.56868,\n",
       "  'main_score': 0.14848},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.813,\n",
       "  'main_score': 0.49333},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.8284,\n",
       "  'main_score': 0.8356},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03747,\n",
       "  'main_score': 0.04783},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.20841,\n",
       "  'main_score': 0.20841},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.37937,\n",
       "  'main_score': 0.64892},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.2185,\n",
       "  'main_score': 0.2},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'EncyclopediaVQAIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.2475,\n",
       "  'main_score': 0.32941},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.8183,\n",
       "  'main_score': 0.50769},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49048,\n",
       "  'main_score': 0.50555},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07369,\n",
       "  'main_score': 0.0945},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09433,\n",
       "  'main_score': 0.11777},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03427,\n",
       "  'main_score': 0.04499},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.90727,\n",
       "  'main_score': 0.74876},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.73139,\n",
       "  'main_score': 0.66391},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.58913,\n",
       "  'main_score': 0.62405},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.03835,\n",
       "  'main_score': 0.03835},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4779,\n",
       "  'main_score': 0.51523},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.72055,\n",
       "  'main_score': 0.35435},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.25218,\n",
       "  'main_score': 0.25218},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12245,\n",
       "  'main_score': 0.13945},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.67901,\n",
       "  'main_score': 0.75647},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.98632,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.80174,\n",
       "  'main_score': 0.85714},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20128,\n",
       "  'main_score': 0.22463},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.48933,\n",
       "  'main_score': 0.53001},\n",
       " {'Model': 'jinaai/jina-clip-v1',\n",
       "  'Revision': '06150c7c382d7a4faedc7d5a0d8cdb59308968f4',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.20142,\n",
       "  'main_score': 0.20142},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.78105,\n",
       "  'main_score': 0.78105},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.28316,\n",
       "  'main_score': 0.30085},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.65498,\n",
       "  'main_score': 0.68123},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.24761,\n",
       "  'main_score': 0.28295},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.78912,\n",
       "  'main_score': 0.78912},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.68702,\n",
       "  'main_score': 0.68758},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.23665,\n",
       "  'main_score': 0.43027},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.58386,\n",
       "  'main_score': 0.46764},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.21216,\n",
       "  'main_score': 0.35145},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12602,\n",
       "  'main_score': 0.10831},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00787,\n",
       "  'main_score': 0.01004},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.79065,\n",
       "  'main_score': 0.80283},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.8203,\n",
       "  'main_score': 0.8203},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.06963,\n",
       "  'main_score': 0.27586},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.38664,\n",
       "  'main_score': 0.4},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.05609,\n",
       "  'main_score': 0.06962},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4301,\n",
       "  'main_score': 0.44763},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.67435,\n",
       "  'main_score': 0.69391},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.61109,\n",
       "  'main_score': 0.55351},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.29201,\n",
       "  'main_score': 0.29201},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.05751,\n",
       "  'main_score': 0.06424},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.69808,\n",
       "  'main_score': 0.69808},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07878,\n",
       "  'main_score': 0.07308},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.06377,\n",
       "  'main_score': 0.06897},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07214,\n",
       "  'main_score': 0.08392},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.79394,\n",
       "  'main_score': 0.44167},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.16966,\n",
       "  'main_score': 0.22375},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.88838,\n",
       "  'main_score': 0.93599},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.89074,\n",
       "  'main_score': 0.8975},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.68196,\n",
       "  'main_score': 0.72059},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.37852,\n",
       "  'main_score': 0.37852},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.88872,\n",
       "  'main_score': 0.95449},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.24908,\n",
       "  'main_score': 0.28569},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.89722,\n",
       "  'main_score': 0.88978},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95296,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47906,\n",
       "  'main_score': 0.55186},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.34573,\n",
       "  'main_score': 0.36431},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07156,\n",
       "  'main_score': 0.08036},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.71011,\n",
       "  'main_score': 0.39213},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80931,\n",
       "  'main_score': 0.48333},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.91713,\n",
       "  'main_score': 0.92122},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01518,\n",
       "  'main_score': 0.02045},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.82313,\n",
       "  'main_score': 0.82313},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.21499,\n",
       "  'main_score': 0.42582},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17088,\n",
       "  'main_score': 0.14286},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.85124,\n",
       "  'main_score': 0.59692},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.60469,\n",
       "  'main_score': 0.62796},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14239,\n",
       "  'main_score': 0.163},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11324,\n",
       "  'main_score': 0.14364},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04915,\n",
       "  'main_score': 0.05782},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.89626,\n",
       "  'main_score': 0.71891},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.68891,\n",
       "  'main_score': 0.59221},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.56413,\n",
       "  'main_score': 0.60512},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.42092,\n",
       "  'main_score': 0.42092},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.46206,\n",
       "  'main_score': 0.49684},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.77701,\n",
       "  'main_score': 0.48298},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.48464,\n",
       "  'main_score': 0.48464},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11531,\n",
       "  'main_score': 0.12977},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.76756,\n",
       "  'main_score': 0.84742},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.96083,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.65627,\n",
       "  'main_score': 0.71429},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.206,\n",
       "  'main_score': 0.23373},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.59594,\n",
       "  'main_score': 0.63905},\n",
       " {'Model': 'royokong/e5-v',\n",
       "  'Revision': '0c1f22679417b3ae925d779442221c40cd1861ab',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.8144,\n",
       "  'main_score': 0.8144},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.43661,\n",
       "  'main_score': 0.43661},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.23295,\n",
       "  'main_score': 0.24955},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.5144,\n",
       "  'main_score': 0.54989},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.45044,\n",
       "  'main_score': 0.45044},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.74209,\n",
       "  'main_score': 0.75693},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.36034,\n",
       "  'main_score': 0.60753},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.59714,\n",
       "  'main_score': 0.47147},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20116,\n",
       "  'main_score': 0.3208},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00788,\n",
       "  'main_score': 0.01071},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.5354,\n",
       "  'main_score': 0.5354},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.79407,\n",
       "  'main_score': 0.03849},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.21484,\n",
       "  'main_score': 0.23304},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.22666,\n",
       "  'main_score': 0.22666},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.48844,\n",
       "  'main_score': 0.48844},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.1503,\n",
       "  'main_score': 0.16811},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.81731,\n",
       "  'main_score': 0.505},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.1721,\n",
       "  'main_score': 0.23116},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.76389,\n",
       "  'main_score': 0.7826},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.37378,\n",
       "  'main_score': 0.07074},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.25061,\n",
       "  'main_score': 0.25061},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.32523,\n",
       "  'main_score': 0.36333},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.77033,\n",
       "  'main_score': 0.76289},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.94786,\n",
       "  'main_score': 0.10571},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.43509,\n",
       "  'main_score': 0.50609},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14211,\n",
       "  'main_score': 0.15643},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.50381,\n",
       "  'main_score': 0.07107},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.83576,\n",
       "  'main_score': 0.555},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.38238,\n",
       "  'main_score': 0.40076},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02449,\n",
       "  'main_score': 0.03046},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.41228,\n",
       "  'main_score': 0.41228},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.35664,\n",
       "  'main_score': 0.64121},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.23342,\n",
       "  'main_score': 0.05647},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.82569,\n",
       "  'main_score': 0.52769},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.0609,\n",
       "  'main_score': 0.07096},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.08642,\n",
       "  'main_score': 0.11324},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.87514,\n",
       "  'main_score': 0.66169},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.64961,\n",
       "  'main_score': 0.52742},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3589,\n",
       "  'main_score': 0.39967},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.17633,\n",
       "  'main_score': 0.17633},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.74192,\n",
       "  'main_score': 0.39975},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.42827,\n",
       "  'main_score': 0.42827},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12189,\n",
       "  'main_score': 0.13943},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.67155,\n",
       "  'main_score': 0.74694},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95566,\n",
       "  'main_score': 0.02613},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.54432,\n",
       "  'main_score': 0.07834},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
       "  'Revision': '7717deedf0631e6f520b7c83c8f82dcbc2c4c21e',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.64881,\n",
       "  'main_score': 0.64881},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.95693,\n",
       "  'main_score': 0.95693},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.61204,\n",
       "  'main_score': 0.63401},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.6306,\n",
       "  'main_score': 0.65606},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.42108,\n",
       "  'main_score': 0.45708},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.99631,\n",
       "  'main_score': 0.99631},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.81002,\n",
       "  'main_score': 0.81593},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.40597,\n",
       "  'main_score': 0.67829},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.60031,\n",
       "  'main_score': 0.48593},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.22159,\n",
       "  'main_score': 0.35792},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.24228,\n",
       "  'main_score': 0.21094},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14218,\n",
       "  'main_score': 0.16731},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70726,\n",
       "  'main_score': 0.72874},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.995,\n",
       "  'main_score': 0.995},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07383,\n",
       "  'main_score': 0.27031},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.46734,\n",
       "  'main_score': 0.44286},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03019,\n",
       "  'main_score': 0.0384},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.53065,\n",
       "  'main_score': 0.54352},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.56111,\n",
       "  'main_score': 0.58628},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.62314,\n",
       "  'main_score': 0.54672},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.75569,\n",
       "  'main_score': 0.75569},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.21863,\n",
       "  'main_score': 0.24442},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.92296,\n",
       "  'main_score': 0.92296},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.29845,\n",
       "  'main_score': 0.24789},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.30438,\n",
       "  'main_score': 0.29414},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.36293,\n",
       "  'main_score': 0.39019},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20381,\n",
       "  'main_score': 0.26733},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97528,\n",
       "  'main_score': 0.98947},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.84814,\n",
       "  'main_score': 0.85898},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.80087,\n",
       "  'main_score': 0.80882},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.58152,\n",
       "  'main_score': 0.58152},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97713,\n",
       "  'main_score': 0.99277},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.51407,\n",
       "  'main_score': 0.54172},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.9333,\n",
       "  'main_score': 0.92066},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97924,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.30452,\n",
       "  'main_score': 0.37031},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.43646,\n",
       "  'main_score': 0.46092},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.30358,\n",
       "  'main_score': 0.32275},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.77116,\n",
       "  'main_score': 0.78654},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17974,\n",
       "  'main_score': 0.20647},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 1.0,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.34799,\n",
       "  'main_score': 0.62679},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.22989,\n",
       "  'main_score': 0.27143},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'EncyclopediaVQAIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.69646,\n",
       "  'main_score': 0.81111},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.55708,\n",
       "  'main_score': 0.58751},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26257,\n",
       "  'main_score': 0.28168},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11673,\n",
       "  'main_score': 0.1494},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17848,\n",
       "  'main_score': 0.20266},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.89626,\n",
       "  'main_score': 0.71891},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70087,\n",
       "  'main_score': 0.60122},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.76625,\n",
       "  'main_score': 0.79488},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.97262,\n",
       "  'main_score': 0.97262},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.68153,\n",
       "  'main_score': 0.71508},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.87112,\n",
       "  'main_score': 0.87112},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3683,\n",
       "  'main_score': 0.39601},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.75439,\n",
       "  'main_score': 0.82977},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.99486,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.77229,\n",
       "  'main_score': 0.81429},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49227,\n",
       "  'main_score': 0.53198},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.58199,\n",
       "  'main_score': 0.62769},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-7B-Instruct',\n",
       "  'Revision': '477027a6480f8630363be77751f169cc3434b673',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.95243,\n",
       "  'main_score': 0.95243},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.73524,\n",
       "  'main_score': 0.73524},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.31474,\n",
       "  'main_score': 0.33377},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.66534,\n",
       "  'main_score': 0.68942},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.16987,\n",
       "  'main_score': 0.20275},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.6778,\n",
       "  'main_score': 0.6778},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.77226,\n",
       "  'main_score': 0.78583},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49276,\n",
       "  'main_score': 0.78512},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70014,\n",
       "  'main_score': 0.64303},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.26892,\n",
       "  'main_score': 0.42686},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.37668,\n",
       "  'main_score': 0.33817},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.16874,\n",
       "  'main_score': 0.19726},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97161,\n",
       "  'main_score': 0.97212},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.75349,\n",
       "  'main_score': 0.75349},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02166,\n",
       "  'main_score': 0.1199},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.48241,\n",
       "  'main_score': 0.45714},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00505,\n",
       "  'main_score': 0.00762},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47709,\n",
       "  'main_score': 0.50324},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.83927,\n",
       "  'main_score': 0.84392},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.71284,\n",
       "  'main_score': 0.66906},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.2749,\n",
       "  'main_score': 0.2749},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00185,\n",
       "  'main_score': 0.00242},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.70496,\n",
       "  'main_score': 0.70496},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02816,\n",
       "  'main_score': 0.02538},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00438,\n",
       "  'main_score': 0.00574},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.34085,\n",
       "  'main_score': 0.36504},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.77856,\n",
       "  'main_score': 0.4},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17737,\n",
       "  'main_score': 0.23627},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.5543,\n",
       "  'main_score': 0.60571},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.90726,\n",
       "  'main_score': 0.91312},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.87599,\n",
       "  'main_score': 0.92647},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.34113,\n",
       "  'main_score': 0.34113},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.34285,\n",
       "  'main_score': 0.41738},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.80302,\n",
       "  'main_score': 0.81792},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95451,\n",
       "  'main_score': 0.95344},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95701,\n",
       "  'main_score': 0.97143},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.56448,\n",
       "  'main_score': 0.63534},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3408,\n",
       "  'main_score': 0.36049},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04177,\n",
       "  'main_score': 0.04379},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.60566,\n",
       "  'main_score': 0.21701},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80931,\n",
       "  'main_score': 0.48333},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.98063,\n",
       "  'main_score': 0.98063},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.21138,\n",
       "  'main_score': 0.23807},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.83103,\n",
       "  'main_score': 0.83103},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.60734,\n",
       "  'main_score': 0.93222},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.29613,\n",
       "  'main_score': 0.34286},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'EncyclopediaVQAIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10699,\n",
       "  'main_score': 0.14454},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.82796,\n",
       "  'main_score': 0.53385},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.8346,\n",
       "  'main_score': 0.84066},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02454,\n",
       "  'main_score': 0.03133},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11168,\n",
       "  'main_score': 0.13548},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09323,\n",
       "  'main_score': 0.11057},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.91278,\n",
       "  'main_score': 0.76368},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70334,\n",
       "  'main_score': 0.61949},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17928,\n",
       "  'main_score': 0.2004},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.24826,\n",
       "  'main_score': 0.24826},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.23858,\n",
       "  'main_score': 0.26172},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.72779,\n",
       "  'main_score': 0.37831},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.49976,\n",
       "  'main_score': 0.49976},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.34054,\n",
       "  'main_score': 0.3646},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.83653,\n",
       "  'main_score': 0.89938},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.99077,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.87026,\n",
       "  'main_score': 0.92857},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11131,\n",
       "  'main_score': 0.12415},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.45344,\n",
       "  'main_score': 0.50082},\n",
       " {'Model': 'google/siglip-so400m-patch14-384',\n",
       "  'Revision': '9fdffc58afc957d1a03a25b10dba0329ab15c2a3',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.60285,\n",
       "  'main_score': 0.60285},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.92641,\n",
       "  'main_score': 0.92641},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.7233,\n",
       "  'main_score': 0.73787},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.60411,\n",
       "  'main_score': 0.63149},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.37099,\n",
       "  'main_score': 0.40616},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.98631,\n",
       "  'main_score': 0.98631},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.78118,\n",
       "  'main_score': 0.7887},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.38337,\n",
       "  'main_score': 0.64653},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.59475,\n",
       "  'main_score': 0.47161},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.2105,\n",
       "  'main_score': 0.33897},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.23867,\n",
       "  'main_score': 0.20703},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11161,\n",
       "  'main_score': 0.13095},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.77017,\n",
       "  'main_score': 0.7862},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.97762,\n",
       "  'main_score': 0.97762},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07857,\n",
       "  'main_score': 0.29647},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4879,\n",
       "  'main_score': 0.48571},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04258,\n",
       "  'main_score': 0.05437},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47852,\n",
       "  'main_score': 0.49666},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.61691,\n",
       "  'main_score': 0.63906},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.60668,\n",
       "  'main_score': 0.52611},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.70911,\n",
       "  'main_score': 0.70911},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.19327,\n",
       "  'main_score': 0.21395},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.91685,\n",
       "  'main_score': 0.91685},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.28377,\n",
       "  'main_score': 0.23625},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.27912,\n",
       "  'main_score': 0.27188},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.30117,\n",
       "  'main_score': 0.32652},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.19333,\n",
       "  'main_score': 0.25887},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.96811,\n",
       "  'main_score': 0.98753},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.84807,\n",
       "  'main_score': 0.85752},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.81108,\n",
       "  'main_score': 0.80882},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.55941,\n",
       "  'main_score': 0.55941},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.96746,\n",
       "  'main_score': 0.98848},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49284,\n",
       "  'main_score': 0.52133},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.91032,\n",
       "  'main_score': 0.89902},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.9721,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.35856,\n",
       "  'main_score': 0.42687},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.71987,\n",
       "  'main_score': 0.73447},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.23503,\n",
       "  'main_score': 0.26581},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.82719,\n",
       "  'main_score': 0.83669},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.13536,\n",
       "  'main_score': 0.15831},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.99262,\n",
       "  'main_score': 0.99262},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.40039,\n",
       "  'main_score': 0.69419},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.2138,\n",
       "  'main_score': 0.2},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'EncyclopediaVQAIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.65036,\n",
       "  'main_score': 0.77157},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.53021,\n",
       "  'main_score': 0.55916},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.25906,\n",
       "  'main_score': 0.2793},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11171,\n",
       "  'main_score': 0.13834},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.15308,\n",
       "  'main_score': 0.17291},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.88616,\n",
       "  'main_score': 0.69154},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.67902,\n",
       "  'main_score': 0.56327},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.73255,\n",
       "  'main_score': 0.76385},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.96693,\n",
       "  'main_score': 0.96693},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.6648,\n",
       "  'main_score': 0.70012},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.84248,\n",
       "  'main_score': 0.84248},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3052,\n",
       "  'main_score': 0.33195},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.75597,\n",
       "  'main_score': 0.82948},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.98487,\n",
       "  'main_score': 0.98571},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.78914,\n",
       "  'main_score': 0.82857},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.42862,\n",
       "  'main_score': 0.46573},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.5645,\n",
       "  'main_score': 0.61213},\n",
       " {'Model': 'Alibaba-NLP/gme-Qwen2-VL-2B-Instruct',\n",
       "  'Revision': 'ce765ae71b8cdb208203cd8fb64a170b1b84293a',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.95065,\n",
       "  'main_score': 0.95065},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.10941,\n",
       "  'main_score': 0.10941},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04046,\n",
       "  'main_score': 0.04652},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.43157,\n",
       "  'main_score': 0.46669},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07626,\n",
       "  'main_score': 0.09514},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.11103,\n",
       "  'main_score': 0.11103},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70709,\n",
       "  'main_score': 0.71606},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.47402,\n",
       "  'main_score': 0.74525},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.58047,\n",
       "  'main_score': 0.4496},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18424,\n",
       "  'main_score': 0.29975},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.27183,\n",
       "  'main_score': 0.24381},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.0516,\n",
       "  'main_score': 0.06376},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49307,\n",
       "  'main_score': 0.51223},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.08897,\n",
       "  'main_score': 0.08897},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03557,\n",
       "  'main_score': 0.17004},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.45804,\n",
       "  'main_score': 0.38571},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00782,\n",
       "  'main_score': 0.01079},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.46863,\n",
       "  'main_score': 0.48516},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.42673,\n",
       "  'main_score': 0.44653},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.28849,\n",
       "  'main_score': 0.22838},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.02609,\n",
       "  'main_score': 0.02609},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02631,\n",
       "  'main_score': 0.03019},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.29352,\n",
       "  'main_score': 0.29352},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11566,\n",
       "  'main_score': 0.09834},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00855,\n",
       "  'main_score': 0.00981},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10012,\n",
       "  'main_score': 0.11587},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.8167,\n",
       "  'main_score': 0.50333},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17151,\n",
       "  'main_score': 0.23094},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.90264,\n",
       "  'main_score': 0.93655},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.6482,\n",
       "  'main_score': 0.67624},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.88163,\n",
       "  'main_score': 0.91176},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.09786,\n",
       "  'main_score': 0.09786},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.6866,\n",
       "  'main_score': 0.73809},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.55235,\n",
       "  'main_score': 0.57136},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.92343,\n",
       "  'main_score': 0.92012},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.94853,\n",
       "  'main_score': 0.97143},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.31082,\n",
       "  'main_score': 0.37108},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.05179,\n",
       "  'main_score': 0.05775},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20656,\n",
       "  'main_score': 0.21976},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.61098,\n",
       "  'main_score': 0.21827},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.79824,\n",
       "  'main_score': 0.45333},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.74852,\n",
       "  'main_score': 0.75946},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.06531,\n",
       "  'main_score': 0.07882},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.15792,\n",
       "  'main_score': 0.15792},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.56282,\n",
       "  'main_score': 0.89006},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.25921,\n",
       "  'main_score': 0.27143},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'EncyclopediaVQAIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.33379,\n",
       "  'main_score': 0.43735},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.81035,\n",
       "  'main_score': 0.48615},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.35326,\n",
       "  'main_score': 0.37424},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02837,\n",
       "  'main_score': 0.03548},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07377,\n",
       "  'main_score': 0.09339},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01429,\n",
       "  'main_score': 0.02024},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.90911,\n",
       "  'main_score': 0.75373},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.59099,\n",
       "  'main_score': 0.44323},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.61033,\n",
       "  'main_score': 0.64919},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.0,\n",
       "  'main_score': 0.0},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49519,\n",
       "  'main_score': 0.52558},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.73423,\n",
       "  'main_score': 0.3884},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.16023,\n",
       "  'main_score': 0.16023},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10952,\n",
       "  'main_score': 0.12501},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.51498,\n",
       "  'main_score': 0.59799},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.97079,\n",
       "  'main_score': 0.98571},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.85859,\n",
       "  'main_score': 0.91429},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18724,\n",
       "  'main_score': 0.20613},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.48704,\n",
       "  'main_score': 0.51306},\n",
       " {'Model': 'nomic-ai/nomic-embed-vision-v1.5',\n",
       "  'Revision': 'af2246fffdab78d8458418480e4886a8e48b70a7',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.15197,\n",
       "  'main_score': 0.15197},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.63488,\n",
       "  'main_score': 0.63488},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.22418,\n",
       "  'main_score': 0.24379},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.56244,\n",
       "  'main_score': 0.59528},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.12515,\n",
       "  'main_score': 0.15807},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.53425,\n",
       "  'main_score': 0.53425},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.67406,\n",
       "  'main_score': 0.67045},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.24755,\n",
       "  'main_score': 0.43959},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.59585,\n",
       "  'main_score': 0.4912},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.21465,\n",
       "  'main_score': 0.35587},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'GLDv2I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10774,\n",
       "  'main_score': 0.09352},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.0055,\n",
       "  'main_score': 0.00773},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'MemotionI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17685,\n",
       "  'main_score': 0.19816},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.6403,\n",
       "  'main_score': 0.6403},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03558,\n",
       "  'main_score': 0.19798},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.36785,\n",
       "  'main_score': 0.4},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14141,\n",
       "  'main_score': 0.16985},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.46434,\n",
       "  'main_score': 0.48213},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.41682,\n",
       "  'main_score': 0.43921},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'FORBI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4345,\n",
       "  'main_score': 0.3597},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.2145,\n",
       "  'main_score': 0.2145},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02954,\n",
       "  'main_score': 0.03431},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.67674,\n",
       "  'main_score': 0.67674},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07315,\n",
       "  'main_score': 0.06739},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.08745,\n",
       "  'main_score': 0.0938},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09834,\n",
       "  'main_score': 0.11428},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.84499,\n",
       "  'main_score': 0.58},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.19637,\n",
       "  'main_score': 0.25437},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.48086,\n",
       "  'main_score': 0.60072},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.80337,\n",
       "  'main_score': 0.8184},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.71856,\n",
       "  'main_score': 0.72059},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.29024,\n",
       "  'main_score': 0.29024},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.15817,\n",
       "  'main_score': 0.18358},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.8987,\n",
       "  'main_score': 0.89121},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.9522,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.43336,\n",
       "  'main_score': 0.50596},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.19908,\n",
       "  'main_score': 0.2187},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.04674,\n",
       "  'main_score': 0.05303},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.83589,\n",
       "  'main_score': 0.62183},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.85975,\n",
       "  'main_score': 0.62},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.5705,\n",
       "  'main_score': 0.58988},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01042,\n",
       "  'main_score': 0.01339},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.70728,\n",
       "  'main_score': 0.70728},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.22084,\n",
       "  'main_score': 0.43104},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18477,\n",
       "  'main_score': 0.17143},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.89552,\n",
       "  'main_score': 0.71692},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18479,\n",
       "  'main_score': 0.2077},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.2285,\n",
       "  'main_score': 0.24997},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09938,\n",
       "  'main_score': 0.12408},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.01716,\n",
       "  'main_score': 0.02151},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.89809,\n",
       "  'main_score': 0.72388},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70232,\n",
       "  'main_score': 0.61787},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.31425,\n",
       "  'main_score': 0.35494},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.24429,\n",
       "  'main_score': 0.24429},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18405,\n",
       "  'main_score': 0.20998},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.77229,\n",
       "  'main_score': 0.4628},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.43151,\n",
       "  'main_score': 0.43151},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10484,\n",
       "  'main_score': 0.12003},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.67111,\n",
       "  'main_score': 0.74461},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.96087,\n",
       "  'main_score': 1.0},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.68838,\n",
       "  'main_score': 0.72857},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14122,\n",
       "  'main_score': 0.16364},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.61165,\n",
       "  'main_score': 0.68636},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Full',\n",
       "  'Revision': 'e9afa98002097ac2471827ba23ea1f2ddd229480',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.63536,\n",
       "  'main_score': 0.63536},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.16727,\n",
       "  'main_score': 0.18378},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.4499,\n",
       "  'main_score': 0.48514},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18463,\n",
       "  'main_score': 0.21529},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.75065,\n",
       "  'main_score': 0.75143},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.41062,\n",
       "  'main_score': 0.67087},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.55181,\n",
       "  'main_score': 0.38617},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18181,\n",
       "  'main_score': 0.29338},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.00803,\n",
       "  'main_score': 0.0105},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.64863,\n",
       "  'main_score': 0.64863},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.0278,\n",
       "  'main_score': 0.16667},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.79001,\n",
       "  'main_score': 0.04006},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.05898,\n",
       "  'main_score': 0.06829},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20015,\n",
       "  'main_score': 0.22067},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.0163,\n",
       "  'main_score': 0.01856},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.06342,\n",
       "  'main_score': 0.06989},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10081,\n",
       "  'main_score': 0.11672},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.82039,\n",
       "  'main_score': 0.51333},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.18367,\n",
       "  'main_score': 0.24001},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.19386,\n",
       "  'main_score': 0.25492},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.70803,\n",
       "  'main_score': 0.72845},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.51927,\n",
       "  'main_score': 0.14162},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.50602,\n",
       "  'main_score': 0.62813},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3102,\n",
       "  'main_score': 0.34592},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.66441,\n",
       "  'main_score': 0.66553},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.94923,\n",
       "  'main_score': 0.10478},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3849,\n",
       "  'main_score': 0.45146},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14266,\n",
       "  'main_score': 0.15428},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.62437,\n",
       "  'main_score': 0.20305},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.80931,\n",
       "  'main_score': 0.48333},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.0159,\n",
       "  'main_score': 0.02004},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.73191,\n",
       "  'main_score': 0.73191},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.24836,\n",
       "  'main_score': 0.06312},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.81092,\n",
       "  'main_score': 0.48769},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11631,\n",
       "  'main_score': 0.13513},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.13945,\n",
       "  'main_score': 0.15443},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07639,\n",
       "  'main_score': 0.09916},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03924,\n",
       "  'main_score': 0.04671},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.58223,\n",
       "  'main_score': 0.42825},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.227,\n",
       "  'main_score': 0.26223},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.32204,\n",
       "  'main_score': 0.32204},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.22161,\n",
       "  'main_score': 0.24572},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.41824,\n",
       "  'main_score': 0.41824},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.07794,\n",
       "  'main_score': 0.09153},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.64961,\n",
       "  'main_score': 0.72851},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.95798,\n",
       "  'main_score': 0.02647},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.55426,\n",
       "  'main_score': 0.08225},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14787,\n",
       "  'main_score': 0.16704},\n",
       " {'Model': 'OCI/VLM2Vec-Qwen2VL-2B-8K-all-data-full',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.53078,\n",
       "  'main_score': 0.53078},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAEnergyRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.57216,\n",
       "  'main_score': 0.57216},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SciMMIRI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.3322,\n",
       "  'main_score': 0.3503},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MSCOCOT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49352,\n",
       "  'main_score': 0.52574},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CIRRIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.14288,\n",
       "  'main_score': 0.16903},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAAIRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.54429,\n",
       "  'main_score': 0.54429},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SketchyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.20217,\n",
       "  'main_score': 0.27981},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CUB200I2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.40753,\n",
       "  'main_score': 0.66707},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SOPI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.5726,\n",
       "  'main_score': 0.43138},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'METI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.11353,\n",
       "  'main_score': 0.18891},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Fashion200kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02584,\n",
       "  'main_score': 0.03325},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAGovernmentReportsRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.64829,\n",
       "  'main_score': 0.64829},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OKVQAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03842,\n",
       "  'main_score': 0.21086},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.69472,\n",
       "  'main_score': 0.02987},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VQA2IT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.09026,\n",
       "  'main_score': 0.11144},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.38684,\n",
       "  'main_score': 0.39958},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'HatefulMemesT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.49029,\n",
       "  'main_score': 0.51237},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreTatdqaRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.20241,\n",
       "  'main_score': 0.20241},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'InfoSeekIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03818,\n",
       "  'main_score': 0.04252},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreInfoVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.69266,\n",
       "  'main_score': 0.69266},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OVENIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.06677,\n",
       "  'main_score': 0.06058},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'OVENIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10759,\n",
       "  'main_score': 0.11183},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VisualNewsI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.17291,\n",
       "  'main_score': 0.19491},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchDistance',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.84376,\n",
       "  'main_score': 0.57667},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'NIGHTSI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.13327,\n",
       "  'main_score': 0.16861},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ReMuQIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.33592,\n",
       "  'main_score': 0.43696},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Flickr30kT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.82661,\n",
       "  'main_score': 0.83779},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.37173,\n",
       "  'main_score': 0.08843},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreDocVQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.29594,\n",
       "  'main_score': 0.29594},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'LLaVAIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.6398,\n",
       "  'main_score': 0.75684},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'GLDv2I2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.44108,\n",
       "  'main_score': 0.4773},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'TUBerlinT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.76731,\n",
       "  'main_score': 0.76813},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisEasyI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.88923,\n",
       "  'main_score': 0.08694},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MSCOCOI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.44055,\n",
       "  'main_score': 0.51122},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'SciMMIRT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.30751,\n",
       "  'main_score': 0.32766},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'InfoSeekIT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03742,\n",
       "  'main_score': 0.03786},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchCount',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.7859,\n",
       "  'main_score': 0.5368},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchDepth',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.84499,\n",
       "  'main_score': 0.58},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'MemotionT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.5889,\n",
       "  'main_score': 0.60465},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Fashion200kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.03271,\n",
       "  'main_score': 0.04315},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreSyntheticDocQAHealthcareIndustryRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.71367,\n",
       "  'main_score': 0.71367},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'StanfordCarsI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.35928,\n",
       "  'main_score': 0.63549},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordHardI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.15257,\n",
       "  'main_score': 0.03062},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'CVBenchRelation',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.82001,\n",
       "  'main_score': 0.51231},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'HatefulMemesI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.21633,\n",
       "  'main_score': 0.23993},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VizWizIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.24165,\n",
       "  'main_score': 0.26199},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ImageCoDeT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.0846,\n",
       "  'main_score': 0.10317},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'FashionIQIT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.02279,\n",
       "  'main_score': 0.02758},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2IMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.88432,\n",
       "  'main_score': 0.68657},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RP2kI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.54311,\n",
       "  'main_score': 0.37087},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'WebQAT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.39581,\n",
       "  'main_score': 0.4373},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreShiftProjectRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.2527,\n",
       "  'main_score': 0.2527},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'WebQAT2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.31673,\n",
       "  'main_score': 0.34813},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2TMultiChoice',\n",
       "  'task_type': 'VisionCentricQA',\n",
       "  'ndcg_at_5': 0.78463,\n",
       "  'main_score': 0.48928},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreArxivQARetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.58453,\n",
       "  'main_score': 0.58453},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VisualNewsT2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.13099,\n",
       "  'main_score': 0.14922},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'Flickr30kI2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.71262,\n",
       "  'main_score': 0.7875},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'RParisMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.93043,\n",
       "  'main_score': 0.02507},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'ROxfordMediumI2IRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.40172,\n",
       "  'main_score': 0.0544},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'EDIST2ITRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.10993,\n",
       "  'main_score': 0.12633},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'BLINKIT2TRetrieval',\n",
       "  'task_type': 'Any2AnyRetrieval',\n",
       "  'ndcg_at_5': 0.66859,\n",
       "  'main_score': 0.70037},\n",
       " {'Model': 'TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
       "  'Revision': 'f2f1c2194823b780632c628548d85a03939d896c',\n",
       "  'task': 'VidoreTabfquadRetrieval',\n",
       "  'task_type': 'DocumentUnderstanding',\n",
       "  'ndcg_at_5': 0.62301,\n",
       "  'main_score': 0.62301}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17a426-faef-4cc1-a63b-26882cac1fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
