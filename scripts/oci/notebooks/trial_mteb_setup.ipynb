{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d69860-052d-48ed-97e4-a718a70419a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "# os.environ[\"http_proxy\"]=\"http://10.68.69.53:80\"\n",
    "# os.environ[\"https_proxy\"]=\"http://10.68.69.53:80\"\n",
    "# os.environ[\"HTTP_PROXY\"]=\"http://10.68.69.53:80\"\n",
    "# os.environ[\"HTTPS_PROXY\"]=\"http://10.68.69.53:80\"\n",
    "# !. set_proxy\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc46fe6-e9e6-4f21-8e85-394737f2a1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aamita/miniconda3/envs/image_retrieval/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/shared/aamita/project/image_retrieval/mteb/mteb/tasks/Retrieval/eng/ChemNQRetrieval.py:29: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  bibtex_citation=\"\"\"\n",
      "/mnt/shared/aamita/project/image_retrieval/mteb/mteb/tasks/Retrieval/eng/LegalBenchCorporateLobbyingRetrieval.py:30: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  bibtex_citation=\"\"\"@misc{guha2023legalbench,\n",
      "/mnt/shared/aamita/project/image_retrieval/mteb/mteb/tasks/Retrieval/multilingual/MIRACLRetrieval.py:128: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  bibtex_citation=\"\"\"@article{10.1162/tacl_a_00595,\n",
      "/mnt/shared/aamita/project/image_retrieval/mteb/mteb/tasks/Retrieval/multilingual/MIRACLRetrieval.py:322: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  bibtex_citation=\"\"\"@article{10.1162/tacl_a_00595,\n",
      "/mnt/shared/aamita/project/image_retrieval/mteb/mteb/tasks/Classification/eng/LegalBenchClassification.py:6066: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  bibtex_citation=\"\"\"\n",
      "/mnt/shared/aamita/project/image_retrieval/mteb/mteb/tasks/Classification/pol/PolishClassification.py:64: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  bibtex_citation=\"\"\"@inproceedings{kocon-etal-2019-multi,\n",
      "/mnt/shared/aamita/project/image_retrieval/mteb/mteb/tasks/PairClassification/pol/PolishPC.py:30: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  bibtex_citation=\"\"\"@inproceedings{dadas-etal-2020-evaluation,\n"
     ]
    }
   ],
   "source": [
    "import mteb\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5762499-a146-40e1-9f6c-55baa5818236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentence-transformers model name\n",
    "# model_name = \"average_word_embeddings_komninos\"\n",
    "\n",
    "# royokong/e5-v\n",
    "# BAAI/bge-m3\n",
    "# BAAI/bge-base-en-v1.5\n",
    "# Alibaba-NLP/gme-Qwen2-VL-2B-Instruct\n",
    "# Alibaba-NLP/gme-Qwen2-VL-7B-Instruct\n",
    "# nyu-visionx/moco-v3-vit-b\n",
    "# nyu-visionx/moco-v3-vit-l\n",
    "# jinaai/jina-clip-v1\n",
    "# Linq-AI-Research/Linq-Embed-Mistral\n",
    "# embed-multilingual-v3.0-v\n",
    "# embed-english-v3.0-v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b6e28f-0678-41b4-a520-1e350a68e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentence-transformers model name\n",
    "model_name = \"TIGER-Lab/VLM2Vec-Full\"  # ,\"\"BAAI/bge-base-en-v1.5\"#\"Alibaba-NLP/gme-Qwen2-VL-2B-Instruct\"\n",
    "# if the model is not implemented in MTEB it will be eq. to SentenceTransformer(model_name)\n",
    "model = mteb.get_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd25f3a-29ba-4081-a5f8-771a749e13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidore_tasks = {\n",
    "    \"VidoreArxivQARetrieval\": \"t2i\",\n",
    "    \"VidoreDocVQARetrieval\": \"t2i\",\n",
    "    \"VidoreInfoVQARetrieval\": \"t2i\",\n",
    "    \"VidoreTabfquadRetrieval\": \"t2i\",\n",
    "    \"VidoreTatdqaRetrieval\": \"t2i\",\n",
    "    \"VidoreShiftProjectRetrieval\": \"t2i\",\n",
    "    \"VidoreSyntheticDocQAAIRetrieval\": \"t2i\",\n",
    "    \"VidoreSyntheticDocQAEnergyRetrieval\": \"t2i\",\n",
    "    \"VidoreSyntheticDocQAGovernmentReportsRetrieval\": \"t2i\",\n",
    "    \"VidoreSyntheticDocQAHealthcareIndustryRetrieval\": \"t2i\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53524ea7-86d6-4447-abaa-fc4ae48abe52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreArxivQARetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreArxivQARetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreArxivQARetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "INFO:datasets.info:Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "Found cached dataset arxivqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4)\n",
      "INFO:datasets.builder:Found cached dataset arxivqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4)\n",
      "Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "INFO:datasets.info:Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "Loading cached processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4/cache-5f96447c3909584e.arrow\n",
      "INFO:datasets.arrow_dataset:Loading cached processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/queries/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4/cache-5f96447c3909584e.arrow\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "INFO:datasets.info:Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "Found cached dataset arxivqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4)\n",
      "INFO:datasets.builder:Found cached dataset arxivqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4)\n",
      "Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "INFO:datasets.info:Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "Loading cached processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4/cache-b699bc8b7ff267c7.arrow\n",
      "INFO:datasets.arrow_dataset:Loading cached processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/corpus/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4/cache-b699bc8b7ff267c7.arrow\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/qrels/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "INFO:datasets.info:Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/qrels/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "Found cached dataset arxivqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/qrels/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4)\n",
      "INFO:datasets.builder:Found cached dataset arxivqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/qrels/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4)\n",
      "Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/qrels/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "INFO:datasets.info:Loading Dataset info from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/qrels/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/qrels/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___arxivqa_test_subsampled_beir/qrels/0.0.0/7d94d570960eac2408d3baa7a33f9de4822ae3e4\n",
      "\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:06<00:00, 40.88it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/250 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|██▌                                                                                                                                                                | 4/250 [00:14<14:22,  3.51s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▎                                                                                                                                                               | 5/250 [00:16<13:36,  3.33s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   5%|███████▊                                                                                                                                                          | 12/250 [00:32<10:22,  2.62s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   7%|███████████▋                                                                                                                                                      | 18/250 [00:50<10:44,  2.78s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   9%|██████████████▉                                                                                                                                                   | 23/250 [01:05<10:57,  2.90s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  12%|██████████████████▊                                                                                                                                               | 29/250 [01:23<10:36,  2.88s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|██████████████████████▋                                                                                                                                           | 35/250 [01:40<10:20,  2.88s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  16%|██████████████████████████▌                                                                                                                                       | 41/250 [01:58<10:09,  2.92s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  18%|█████████████████████████████▊                                                                                                                                    | 46/250 [02:13<10:02,  2.95s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|█████████████████████████████████                                                                                                                                 | 51/250 [02:29<09:56,  3.00s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  22%|████████████████████████████████████▎                                                                                                                             | 56/250 [02:44<09:43,  3.01s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  25%|████████████████████████████████████████▏                                                                                                                         | 62/250 [02:59<08:59,  2.87s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  27%|███████████████████████████████████████████▍                                                                                                                      | 67/250 [03:15<08:59,  2.95s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  29%|██████████████████████████████████████████████▋                                                                                                                   | 72/250 [03:30<08:52,  2.99s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  31%|█████████████████████████████████████████████████▉                                                                                                                | 77/250 [03:46<08:42,  3.02s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  33%|█████████████████████████████████████████████████████▏                                                                                                            | 82/250 [04:01<08:31,  3.04s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  35%|█████████████████████████████████████████████████████████                                                                                                         | 88/250 [04:18<07:59,  2.96s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  38%|████████████████████████████████████████████████████████████▉                                                                                                     | 94/250 [04:36<07:38,  2.94s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|████████████████████████████████████████████████████████████████▍                                                                                                | 100/250 [04:52<07:14,  2.90s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  42%|████████████████████████████████████████████████████████████████████▎                                                                                            | 106/250 [05:10<06:59,  2.91s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  44%|███████████████████████████████████████████████████████████████████████▍                                                                                         | 111/250 [05:26<06:53,  2.97s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  46%|██████████████████████████████████████████████████████████████████████████▋                                                                                      | 116/250 [05:41<06:42,  3.01s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  49%|██████████████████████████████████████████████████████████████████████████████▌                                                                                  | 122/250 [05:59<06:23,  2.99s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  51%|█████████████████████████████████████████████████████████████████████████████████▊                                                                               | 127/250 [06:15<06:14,  3.04s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  53%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 133/250 [06:33<05:52,  3.01s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  55%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 138/250 [06:48<05:40,  3.04s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 144/250 [07:06<05:20,  3.02s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  60%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                 | 149/250 [07:21<05:06,  3.03s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 154/250 [07:37<04:52,  3.05s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 159/250 [07:52<04:39,  3.07s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 165/250 [08:08<04:06,  2.90s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 170/250 [08:23<03:55,  2.95s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 175/250 [08:38<03:42,  2.96s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 182/250 [08:56<03:12,  2.83s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 187/250 [09:11<03:01,  2.88s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 193/250 [09:29<02:44,  2.89s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                | 199/250 [09:44<02:22,  2.79s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                             | 205/250 [10:01<02:04,  2.78s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 211/250 [10:17<01:47,  2.77s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 217/250 [10:34<01:32,  2.79s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 222/250 [10:49<01:19,  2.85s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 228/250 [11:07<01:03,  2.88s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 234/250 [11:25<00:46,  2.91s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 239/250 [11:40<00:32,  2.96s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 244/250 [11:56<00:18,  3.01s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [12:12<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreDocVQARetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreDocVQARetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreDocVQARetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/9d480d4d5778f796eea86d11efc08ae4c749232aff2e356e20cec6cfd94d8721.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/9d480d4d5778f796eea86d11efc08ae4c749232aff2e356e20cec6cfd94d8721.incomplete\n",
      "\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.08k/1.08k [00:00<00:00, 12.8kB/s]\n",
      "storing hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/9d480d4d5778f796eea86d11efc08ae4c749232aff2e356e20cec6cfd94d8721\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/9d480d4d5778f796eea86d11efc08ae4c749232aff2e356e20cec6cfd94d8721\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/9d480d4d5778f796eea86d11efc08ae4c749232aff2e356e20cec6cfd94d8721\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/9d480d4d5778f796eea86d11efc08ae4c749232aff2e356e20cec6cfd94d8721\n",
      "Generating dataset docvqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092)\n",
      "INFO:datasets.builder:Generating dataset docvqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092)\n",
      "Downloading and preparing dataset docvqa_test_subsampled_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092...\n",
      "INFO:datasets.builder:Downloading and preparing dataset docvqa_test_subsampled_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092...\n",
      "hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/5855d7ce79afef8160c831751545c3c0db4389190536062ec9726f8e1400546c.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/5855d7ce79afef8160c831751545c3c0db4389190536062ec9726f8e1400546c.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/15.7k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15.7k/15.7k [00:01<00:00, 8.59kB/s]\n",
      "storing hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/5855d7ce79afef8160c831751545c3c0db4389190536062ec9726f8e1400546c\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/5855d7ce79afef8160c831751545c3c0db4389190536062ec9726f8e1400546c\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/5855d7ce79afef8160c831751545c3c0db4389190536062ec9726f8e1400546c\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/5855d7ce79afef8160c831751545c3c0db4389190536062ec9726f8e1400546c\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 451 examples in 25058 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092.incomplete/docvqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 451 examples in 25058 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092.incomplete/docvqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [00:00<00:00, 20520.61 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset docvqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset docvqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/451 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/cache-e510472bd520f562.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/cache-e510472bd520f562.arrow\n",
      "Done writing 451 examples in 33009 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/tmp6pvmtpon.\n",
      "DEBUG:datasets.arrow_writer:Done writing 451 examples in 33009 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/queries/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/tmp6pvmtpon.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [00:00<00:00, 9136.15 examples/s]\n",
      "Generating dataset docvqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092)\n",
      "INFO:datasets.builder:Generating dataset docvqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092)\n",
      "Downloading and preparing dataset docvqa_test_subsampled_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092...\n",
      "INFO:datasets.builder:Downloading and preparing dataset docvqa_test_subsampled_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092...\n",
      "hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/b786f3ed6949f64f6ae219134c3960391f0118b2d377a3a6a01b64ba343855c0.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/b786f3ed6949f64f6ae219134c3960391f0118b2d377a3a6a01b64ba343855c0.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                              | 0.00/292M [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   4%|█████▎                                                                                                                                               | 10.5M/292M [00:00<00:13, 20.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   7%|██████████▋                                                                                                                                          | 21.0M/292M [00:00<00:08, 31.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  11%|████████████████                                                                                                                                     | 31.5M/292M [00:00<00:06, 39.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  14%|█████████████████████▍                                                                                                                               | 41.9M/292M [00:01<00:05, 43.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  18%|██████████████████████████▋                                                                                                                          | 52.4M/292M [00:01<00:05, 46.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  22%|████████████████████████████████                                                                                                                     | 62.9M/292M [00:01<00:04, 49.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  25%|█████████████████████████████████████▍                                                                                                               | 73.4M/292M [00:01<00:04, 50.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  29%|██████████████████████████████████████████▊                                                                                                          | 83.9M/292M [00:01<00:04, 50.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  32%|████████████████████████████████████████████████                                                                                                     | 94.4M/292M [00:02<00:03, 52.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  36%|█████████████████████████████████████████████████████▊                                                                                                | 105M/292M [00:02<00:03, 53.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  39%|███████████████████████████████████████████████████████████▏                                                                                          | 115M/292M [00:02<00:03, 53.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  43%|████████████████████████████████████████████████████████████████▌                                                                                     | 126M/292M [00:02<00:03, 52.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  47%|█████████████████████████████████████████████████████████████████████▉                                                                                | 136M/292M [00:02<00:02, 53.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  50%|███████████████████████████████████████████████████████████████████████████▎                                                                          | 147M/292M [00:03<00:02, 52.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  54%|████████████████████████████████████████████████████████████████████████████████▋                                                                     | 157M/292M [00:03<00:02, 53.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  57%|██████████████████████████████████████████████████████████████████████████████████████                                                                | 168M/292M [00:03<00:02, 52.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  61%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 178M/292M [00:03<00:02, 52.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  65%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 189M/292M [00:03<00:02, 51.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                               | 199M/292M [00:04<00:01, 52.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 210M/292M [00:04<00:01, 51.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 220M/292M [00:04<00:01, 50.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 231M/292M [00:04<00:01, 51.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 241M/292M [00:04<00:00, 52.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 252M/292M [00:05<00:00, 52.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 262M/292M [00:05<00:00, 53.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 273M/292M [00:05<00:00, 52.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 283M/292M [00:05<00:00, 51.5MB/s]\n",
      "\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 292M/292M [00:05<00:00, 49.4MB/s]\n",
      "storing hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/b786f3ed6949f64f6ae219134c3960391f0118b2d377a3a6a01b64ba343855c0\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/b786f3ed6949f64f6ae219134c3960391f0118b2d377a3a6a01b64ba343855c0\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/b786f3ed6949f64f6ae219134c3960391f0118b2d377a3a6a01b64ba343855c0\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/b786f3ed6949f64f6ae219134c3960391f0118b2d377a3a6a01b64ba343855c0\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/500 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  20%|███████████████████████████▌                                                                                                              | 100/500 [00:00<00:01, 209.16 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  40%|███████████████████████████████████████████████████████▏                                                                                  | 200/500 [00:00<00:01, 237.23 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  60%|██████████████████████████████████████████████████████████████████████████████████▊                                                       | 300/500 [00:01<00:00, 238.58 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 400/500 [00:01<00:00, 224.76 examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 500 examples in 292604006 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092.incomplete/docvqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 500 examples in 292604006 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092.incomplete/docvqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:02<00:00, 221.48 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset docvqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset docvqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/500 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/cache-ebca1b0c858740b0.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/cache-ebca1b0c858740b0.arrow\n",
      "Done writing 500 examples in 292613829 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/tmp_ig9ec0v.\n",
      "DEBUG:datasets.arrow_writer:Done writing 500 examples in 292613829 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/corpus/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/tmp_ig9ec0v.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[AFinished processing shard number None of 1.█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:03<00:00, 141.91 examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:03<00:00, 139.57 examples/s]\n",
      "Generating dataset docvqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092)\n",
      "INFO:datasets.builder:Generating dataset docvqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092)\n",
      "Downloading and preparing dataset docvqa_test_subsampled_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092...\n",
      "INFO:datasets.builder:Downloading and preparing dataset docvqa_test_subsampled_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092...\n",
      "hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/682e3c05b4a8298f18a407dcd805f6f0eb8636f263121a088e575718b5aa32ed.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/682e3c05b4a8298f18a407dcd805f6f0eb8636f263121a088e575718b5aa32ed.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/6.54k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.54k/6.54k [00:00<00:00, 22.2kB/s]\n",
      "storing hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/682e3c05b4a8298f18a407dcd805f6f0eb8636f263121a088e575718b5aa32ed\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/docvqa_test_subsampled_beir@162ba2fc1a8437eda8b6c37b240bc1c0f0deb092/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/682e3c05b4a8298f18a407dcd805f6f0eb8636f263121a088e575718b5aa32ed\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/682e3c05b4a8298f18a407dcd805f6f0eb8636f263121a088e575718b5aa32ed\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/682e3c05b4a8298f18a407dcd805f6f0eb8636f263121a088e575718b5aa32ed\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 500 examples in 12189 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092.incomplete/docvqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 500 examples in 12189 bytes /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092.incomplete/docvqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 56045.11 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset docvqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset docvqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___docvqa_test_subsampled_beir/qrels/0.0.0/162ba2fc1a8437eda8b6c37b240bc1c0f0deb092\n",
      "\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:05<00:00, 39.78it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/250 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|██▌                                                                                                                                                                | 4/250 [00:15<16:01,  3.91s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▎                                                                                                                                                               | 5/250 [00:17<14:31,  3.56s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   4%|███████▏                                                                                                                                                          | 11/250 [00:35<12:39,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   6%|██████████▎                                                                                                                                                       | 16/250 [00:51<12:21,  3.17s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   8%|█████████████▌                                                                                                                                                    | 21/250 [01:08<12:27,  3.26s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  10%|████████████████▊                                                                                                                                                 | 26/250 [01:24<12:05,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  12%|████████████████████                                                                                                                                              | 31/250 [01:40<11:47,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|███████████████████████▎                                                                                                                                          | 36/250 [01:57<11:42,  3.28s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  16%|██████████████████████████▌                                                                                                                                       | 41/250 [02:13<11:19,  3.25s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  18%|█████████████████████████████▊                                                                                                                                    | 46/250 [02:28<10:51,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|█████████████████████████████████                                                                                                                                 | 51/250 [02:45<10:42,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  22%|████████████████████████████████████▎                                                                                                                             | 56/250 [03:02<10:37,  3.29s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  24%|███████████████████████████████████████▌                                                                                                                          | 61/250 [03:18<10:23,  3.30s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  26%|██████████████████████████████████████████▊                                                                                                                       | 66/250 [03:34<09:51,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  28%|██████████████████████████████████████████████                                                                                                                    | 71/250 [03:50<09:36,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  30%|█████████████████████████████████████████████████▏                                                                                                                | 76/250 [04:06<09:19,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  32%|████████████████████████████████████████████████████▍                                                                                                             | 81/250 [04:22<09:07,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  34%|███████████████████████████████████████████████████████▋                                                                                                          | 86/250 [04:38<08:51,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  36%|██████████████████████████████████████████████████████████▉                                                                                                       | 91/250 [04:55<08:35,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  38%|██████████████████████████████████████████████████████████████▏                                                                                                   | 96/250 [05:10<08:15,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|█████████████████████████████████████████████████████████████████                                                                                                | 101/250 [05:26<07:54,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  42%|████████████████████████████████████████████████████████████████████▎                                                                                            | 106/250 [05:42<07:38,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  44%|███████████████████████████████████████████████████████████████████████▍                                                                                         | 111/250 [05:58<07:20,  3.17s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  46%|██████████████████████████████████████████████████████████████████████████▋                                                                                      | 116/250 [06:14<07:06,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  48%|█████████████████████████████████████████████████████████████████████████████▉                                                                                   | 121/250 [06:29<06:47,  3.16s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  50%|█████████████████████████████████████████████████████████████████████████████████▏                                                                               | 126/250 [06:45<06:32,  3.17s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  52%|████████████████████████████████████████████████████████████████████████████████████▎                                                                            | 131/250 [07:01<06:20,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  54%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 136/250 [07:17<06:03,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  56%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 141/250 [07:33<05:47,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 146/250 [07:49<05:31,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  60%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 151/250 [08:05<05:14,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  62%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 156/250 [08:21<04:58,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 162/250 [08:38<04:32,  3.09s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 167/250 [08:54<04:19,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                  | 172/250 [09:10<04:04,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 178/250 [09:28<03:41,  3.08s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 183/250 [09:44<03:29,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 188/250 [10:00<03:14,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 193/250 [10:17<03:03,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 198/250 [10:33<02:47,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 203/250 [10:49<02:31,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                           | 208/250 [11:05<02:14,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 213/250 [11:21<01:57,  3.17s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 219/250 [11:37<01:33,  3.00s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 224/250 [11:52<01:18,  3.02s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 229/250 [12:08<01:04,  3.09s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 234/250 [12:24<00:49,  3.10s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 239/250 [12:40<00:34,  3.12s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [13:09<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreInfoVQARetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreInfoVQARetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreInfoVQARetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/efec01fcc3da3088a3120d13e1d26c3c649c8b2b0c5d66ed711235b4f7d47d25.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/efec01fcc3da3088a3120d13e1d26c3c649c8b2b0c5d66ed711235b4f7d47d25.incomplete\n",
      "\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.08k/1.08k [00:00<00:00, 12.4kB/s]\n",
      "storing hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/efec01fcc3da3088a3120d13e1d26c3c649c8b2b0c5d66ed711235b4f7d47d25\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/efec01fcc3da3088a3120d13e1d26c3c649c8b2b0c5d66ed711235b4f7d47d25\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/efec01fcc3da3088a3120d13e1d26c3c649c8b2b0c5d66ed711235b4f7d47d25\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/efec01fcc3da3088a3120d13e1d26c3c649c8b2b0c5d66ed711235b4f7d47d25\n",
      "Generating dataset infovqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4)\n",
      "INFO:datasets.builder:Generating dataset infovqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4)\n",
      "Downloading and preparing dataset infovqa_test_subsampled_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4...\n",
      "INFO:datasets.builder:Downloading and preparing dataset infovqa_test_subsampled_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4...\n",
      "hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/82804bf0fd6564bcd2685b1bdecb83c80505df298bace28932c93dd3cee632b4.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/82804bf0fd6564bcd2685b1bdecb83c80505df298bace28932c93dd3cee632b4.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/24.8k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24.8k/24.8k [00:02<00:00, 10.6kB/s]\n",
      "storing hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/82804bf0fd6564bcd2685b1bdecb83c80505df298bace28932c93dd3cee632b4\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/82804bf0fd6564bcd2685b1bdecb83c80505df298bace28932c93dd3cee632b4\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/82804bf0fd6564bcd2685b1bdecb83c80505df298bace28932c93dd3cee632b4\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/82804bf0fd6564bcd2685b1bdecb83c80505df298bace28932c93dd3cee632b4\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 494 examples in 38245 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4.incomplete/infovqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 494 examples in 38245 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4.incomplete/infovqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 494/494 [00:00<00:00, 47785.66 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset infovqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset infovqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/494 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4/cache-6845a7e5ee5a4f2a.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4/cache-6845a7e5ee5a4f2a.arrow\n",
      "Done writing 494 examples in 46965 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4/tmp864c6zn4.\n",
      "DEBUG:datasets.arrow_writer:Done writing 494 examples in 46965 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/queries/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4/tmp864c6zn4.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 494/494 [00:00<00:00, 10612.56 examples/s]\n",
      "Generating dataset infovqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4)\n",
      "INFO:datasets.builder:Generating dataset infovqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4)\n",
      "Downloading and preparing dataset infovqa_test_subsampled_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4...\n",
      "INFO:datasets.builder:Downloading and preparing dataset infovqa_test_subsampled_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4...\n",
      "hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/3c0655d0e1002353cbfcb8743127723283d076e6f43884bfa2cd09f7573939be.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/3c0655d0e1002353cbfcb8743127723283d076e6f43884bfa2cd09f7573939be.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                              | 0.00/176M [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   6%|████████▊                                                                                                                                            | 10.5M/176M [00:00<00:08, 18.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  12%|█████████████████▋                                                                                                                                   | 21.0M/176M [00:00<00:05, 29.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  18%|██████████████████████████▌                                                                                                                          | 31.5M/176M [00:00<00:03, 37.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  24%|███████████████████████████████████▍                                                                                                                 | 41.9M/176M [00:01<00:03, 42.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  30%|████████████████████████████████████████████▎                                                                                                        | 52.4M/176M [00:01<00:02, 45.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  36%|█████████████████████████████████████████████████████▏                                                                                               | 62.9M/176M [00:01<00:02, 47.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  42%|██████████████████████████████████████████████████████████████                                                                                       | 73.4M/176M [00:01<00:02, 49.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  48%|██████████████████████████████████████████████████████████████████████▉                                                                              | 83.9M/176M [00:01<00:01, 50.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  54%|███████████████████████████████████████████████████████████████████████████████▊                                                                     | 94.4M/176M [00:02<00:01, 51.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  60%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 105M/176M [00:02<00:01, 51.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 115M/176M [00:02<00:01, 52.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████                                           | 126M/176M [00:02<00:00, 52.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 136M/176M [00:02<00:00, 52.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 147M/176M [00:03<00:00, 50.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 157M/176M [00:03<00:00, 51.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 168M/176M [00:03<00:00, 51.9MB/s]\n",
      "\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 176M/176M [00:03<00:00, 46.7MB/s]\n",
      "storing hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/3c0655d0e1002353cbfcb8743127723283d076e6f43884bfa2cd09f7573939be\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/3c0655d0e1002353cbfcb8743127723283d076e6f43884bfa2cd09f7573939be\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/3c0655d0e1002353cbfcb8743127723283d076e6f43884bfa2cd09f7573939be\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/3c0655d0e1002353cbfcb8743127723283d076e6f43884bfa2cd09f7573939be\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/500 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  20%|███████████████████████████▌                                                                                                              | 100/500 [00:00<00:01, 362.85 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  40%|███████████████████████████████████████████████████████▏                                                                                  | 200/500 [00:00<00:00, 317.19 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  60%|██████████████████████████████████████████████████████████████████████████████████▊                                                       | 300/500 [00:00<00:00, 317.40 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 400/500 [00:01<00:00, 313.91 examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 500 examples in 185832651 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4.incomplete/infovqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 500 examples in 185832651 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4.incomplete/infovqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 318.48 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset infovqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset infovqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/500 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4/cache-11a92aa41e9b8cd5.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4/cache-11a92aa41e9b8cd5.arrow\n",
      "Done writing 500 examples in 185842474 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4/tmpdpx9dat8.\n",
      "DEBUG:datasets.arrow_writer:Done writing 500 examples in 185842474 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/corpus/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4/tmpdpx9dat8.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[AFinished processing shard number None of 1.█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:02<00:00, 223.02 examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:02<00:00, 218.89 examples/s]\n",
      "Generating dataset infovqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4)\n",
      "INFO:datasets.builder:Generating dataset infovqa_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4)\n",
      "Downloading and preparing dataset infovqa_test_subsampled_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4...\n",
      "INFO:datasets.builder:Downloading and preparing dataset infovqa_test_subsampled_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4...\n",
      "hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/89f04f447599e39f35cf61d5627d59e364aae4135be14229e76b1034287cf185.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/89f04f447599e39f35cf61d5627d59e364aae4135be14229e76b1034287cf185.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/6.72k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6.72k/6.72k [00:00<00:00, 41.7kB/s]\n",
      "storing hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/89f04f447599e39f35cf61d5627d59e364aae4135be14229e76b1034287cf185\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/infovqa_test_subsampled_beir@b802cc5fd6c605df2d673a963667d74881d2c9a4/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/89f04f447599e39f35cf61d5627d59e364aae4135be14229e76b1034287cf185\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/89f04f447599e39f35cf61d5627d59e364aae4135be14229e76b1034287cf185\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/89f04f447599e39f35cf61d5627d59e364aae4135be14229e76b1034287cf185\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 500 examples in 12189 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4.incomplete/infovqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 500 examples in 12189 bytes /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4.incomplete/infovqa_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 52099.27 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset infovqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset infovqa_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___infovqa_test_subsampled_beir/qrels/0.0.0/b802cc5fd6c605df2d673a963667d74881d2c9a4\n",
      "\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 247/247 [00:06<00:00, 40.12it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/250 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█▉                                                                                                                                                                 | 3/250 [00:11<15:46,  3.83s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▎                                                                                                                                                               | 5/250 [00:15<12:49,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   4%|██████▍                                                                                                                                                           | 10/250 [00:31<12:25,  3.10s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   6%|██████████▎                                                                                                                                                       | 16/250 [00:46<11:12,  2.88s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   8%|█████████████▌                                                                                                                                                    | 21/250 [01:02<11:24,  2.99s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  11%|█████████████████▍                                                                                                                                                | 27/250 [01:19<10:50,  2.92s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|██████████████████████                                                                                                                                            | 34/250 [01:35<09:35,  2.67s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  16%|█████████████████████████▉                                                                                                                                        | 40/250 [01:51<09:21,  2.68s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  18%|█████████████████████████████▊                                                                                                                                    | 46/250 [02:08<09:08,  2.69s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|█████████████████████████████████                                                                                                                                 | 51/250 [02:24<09:30,  2.87s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  23%|████████████████████████████████████▉                                                                                                                             | 57/250 [02:43<09:24,  2.92s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  25%|████████████████████████████████████████▏                                                                                                                         | 62/250 [02:59<09:22,  2.99s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  27%|████████████████████████████████████████████                                                                                                                      | 68/250 [03:16<08:56,  2.95s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  29%|███████████████████████████████████████████████▎                                                                                                                  | 73/250 [03:32<08:59,  3.05s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  32%|███████████████████████████████████████████████████▏                                                                                                              | 79/250 [03:48<08:20,  2.93s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  34%|██████████████████████████████████████████████████████▍                                                                                                           | 84/250 [04:03<08:09,  2.95s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  36%|█████████████████████████████████████████████████████████▋                                                                                                        | 89/250 [04:18<07:57,  2.97s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  38%|████████████████████████████████████████████████████████████▉                                                                                                     | 94/250 [04:34<07:46,  2.99s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|████████████████████████████████████████████████████████████████▏                                                                                                 | 99/250 [04:49<07:40,  3.05s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  42%|███████████████████████████████████████████████████████████████████▌                                                                                             | 105/250 [05:06<07:07,  2.95s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  44%|███████████████████████████████████████████████████████████████████████▍                                                                                         | 111/250 [05:23<06:45,  2.91s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  47%|███████████████████████████████████████████████████████████████████████████▎                                                                                     | 117/250 [05:39<06:17,  2.84s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  49%|███████████████████████████████████████████████████████████████████████████████▏                                                                                 | 123/250 [05:55<05:55,  2.80s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  51%|██████████████████████████████████████████████████████████████████████████████████▍                                                                              | 128/250 [06:11<05:53,  2.90s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  54%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 134/250 [06:29<05:38,  2.92s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  56%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                      | 140/250 [06:46<05:20,  2.92s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 146/250 [07:03<04:58,  2.87s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  61%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 152/250 [07:21<04:44,  2.90s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  63%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                            | 157/250 [07:36<04:33,  2.94s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 163/250 [07:54<04:16,  2.95s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 169/250 [08:11<03:56,  2.93s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 175/250 [08:28<03:37,  2.90s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 181/250 [08:44<03:15,  2.84s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 187/250 [09:01<02:56,  2.81s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 193/250 [09:18<02:41,  2.83s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                | 199/250 [09:35<02:23,  2.82s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                             | 204/250 [09:51<02:13,  2.91s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 209/250 [10:06<02:01,  2.96s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 215/250 [10:21<01:38,  2.83s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 220/250 [10:37<01:27,  2.92s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 226/250 [10:54<01:08,  2.87s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 232/250 [11:10<00:50,  2.81s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 237/250 [11:25<00:37,  2.90s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 243/250 [11:42<00:20,  2.87s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [12:00<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreTabfquadRetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreTabfquadRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreTabfquadRetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/eea9acb2a7268974426f0a6bd848b472329bfb3cd7af3d67f591bbec25ed9a52.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/eea9acb2a7268974426f0a6bd848b472329bfb3cd7af3d67f591bbec25ed9a52.incomplete\n",
      "\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.07k/1.07k [00:00<00:00, 12.4kB/s]\n",
      "storing hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/eea9acb2a7268974426f0a6bd848b472329bfb3cd7af3d67f591bbec25ed9a52\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/eea9acb2a7268974426f0a6bd848b472329bfb3cd7af3d67f591bbec25ed9a52\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/eea9acb2a7268974426f0a6bd848b472329bfb3cd7af3d67f591bbec25ed9a52\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/eea9acb2a7268974426f0a6bd848b472329bfb3cd7af3d67f591bbec25ed9a52\n",
      "Generating dataset tabfquad_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31)\n",
      "INFO:datasets.builder:Generating dataset tabfquad_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31)\n",
      "Downloading and preparing dataset tabfquad_test_subsampled_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31...\n",
      "INFO:datasets.builder:Downloading and preparing dataset tabfquad_test_subsampled_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31...\n",
      "hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/d07584a6a6da68daadac6cab74a57d9b273da5adab662579350ad37b2b364876.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/d07584a6a6da68daadac6cab74a57d9b273da5adab662579350ad37b2b364876.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/18.4k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18.4k/18.4k [00:03<00:00, 5.20kB/s]\n",
      "storing hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/d07584a6a6da68daadac6cab74a57d9b273da5adab662579350ad37b2b364876\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/d07584a6a6da68daadac6cab74a57d9b273da5adab662579350ad37b2b364876\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/d07584a6a6da68daadac6cab74a57d9b273da5adab662579350ad37b2b364876\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/d07584a6a6da68daadac6cab74a57d9b273da5adab662579350ad37b2b364876\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 280 examples in 32448 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31.incomplete/tabfquad_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 280 examples in 32448 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31.incomplete/tabfquad_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [00:00<00:00, 14950.67 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset tabfquad_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset tabfquad_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/280 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31/cache-69334a08222e029f.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31/cache-69334a08222e029f.arrow\n",
      "Done writing 280 examples in 37343 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31/tmpb5aowyc1.\n",
      "DEBUG:datasets.arrow_writer:Done writing 280 examples in 37343 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/queries/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31/tmpb5aowyc1.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [00:00<00:00, 5288.33 examples/s]\n",
      "Generating dataset tabfquad_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31)\n",
      "INFO:datasets.builder:Generating dataset tabfquad_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31)\n",
      "Downloading and preparing dataset tabfquad_test_subsampled_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31...\n",
      "INFO:datasets.builder:Downloading and preparing dataset tabfquad_test_subsampled_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31...\n",
      "hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/e943c13a822250bc100cc7d3d9f5eda740cc29b1baa4a5f486c2c616f7ec2b30.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/e943c13a822250bc100cc7d3d9f5eda740cc29b1baa4a5f486c2c616f7ec2b30.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/9.34M [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.34M/9.34M [00:00<00:00, 16.5MB/s]\n",
      "storing hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/e943c13a822250bc100cc7d3d9f5eda740cc29b1baa4a5f486c2c616f7ec2b30\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/e943c13a822250bc100cc7d3d9f5eda740cc29b1baa4a5f486c2c616f7ec2b30\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/e943c13a822250bc100cc7d3d9f5eda740cc29b1baa4a5f486c2c616f7ec2b30\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/e943c13a822250bc100cc7d3d9f5eda740cc29b1baa4a5f486c2c616f7ec2b30\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                      | 0/70 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 70 examples in 9364105 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31.incomplete/tabfquad_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 70 examples in 9364105 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31.incomplete/tabfquad_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 602.74 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset tabfquad_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset tabfquad_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                         | 0/70 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31/cache-a9775424d0e41410.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31/cache-a9775424d0e41410.arrow\n",
      "Done writing 70 examples in 9365416 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31/tmpkidtf9zj.\n",
      "DEBUG:datasets.arrow_writer:Done writing 70 examples in 9365416 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/corpus/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31/tmpkidtf9zj.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[AFinished processing shard number None of 1.███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 425.78 examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 384.55 examples/s]\n",
      "Generating dataset tabfquad_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31)\n",
      "INFO:datasets.builder:Generating dataset tabfquad_test_subsampled_beir (/home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31)\n",
      "Downloading and preparing dataset tabfquad_test_subsampled_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31...\n",
      "INFO:datasets.builder:Downloading and preparing dataset tabfquad_test_subsampled_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31...\n",
      "hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/670637543319f462ffe900204a6958fb9add1f9778f00146d546c056a343b4fd.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/670637543319f462ffe900204a6958fb9add1f9778f00146d546c056a343b4fd.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/3.56k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.56k/3.56k [00:00<00:00, 13.3kB/s]\n",
      "storing hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/670637543319f462ffe900204a6958fb9add1f9778f00146d546c056a343b4fd\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/tabfquad_test_subsampled_beir@61a2224bcd29b7b261a4892ff4c8bea353527a31/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/670637543319f462ffe900204a6958fb9add1f9778f00146d546c056a343b4fd\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/670637543319f462ffe900204a6958fb9add1f9778f00146d546c056a343b4fd\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/670637543319f462ffe900204a6958fb9add1f9778f00146d546c056a343b4fd\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 280 examples in 6825 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31.incomplete/tabfquad_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 280 examples in 6825 bytes /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31.incomplete/tabfquad_test_subsampled_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 280/280 [00:00<00:00, 17220.52 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset tabfquad_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset tabfquad_test_subsampled_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tabfquad_test_subsampled_beir/qrels/0.0.0/61a2224bcd29b7b261a4892ff4c8bea353527a31\n",
      "\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 140/140 [00:03<00:00, 40.46it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                            | 0/35 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:  17%|████████████████████████████                                                                                                                                        | 6/35 [00:13<01:04,  2.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|████████████████████████████████▊                                                                                                                                   | 7/35 [00:15<01:02,  2.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  43%|█████████████████████████████████████████████████████████████████████▊                                                                                             | 15/35 [00:31<00:42,  2.11s/it]\n",
      "\n",
      "encode: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [01:00<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreTatdqaRetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreTatdqaRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreTatdqaRetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/75cd5f4a0cf2d3e1e396ab8a24a1e1d2e27dbf47525584e28c258991a777e075.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/75cd5f4a0cf2d3e1e396ab8a24a1e1d2e27dbf47525584e28c258991a777e075.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading readme:   0%|                                                                                                                                                           | 0.00/1.06k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.06k/1.06k [00:00<00:00, 7.39kB/s]\n",
      "storing hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/75cd5f4a0cf2d3e1e396ab8a24a1e1d2e27dbf47525584e28c258991a777e075\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/75cd5f4a0cf2d3e1e396ab8a24a1e1d2e27dbf47525584e28c258991a777e075\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/75cd5f4a0cf2d3e1e396ab8a24a1e1d2e27dbf47525584e28c258991a777e075\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/75cd5f4a0cf2d3e1e396ab8a24a1e1d2e27dbf47525584e28c258991a777e075\n",
      "Generating dataset tatdqa_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0)\n",
      "INFO:datasets.builder:Generating dataset tatdqa_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0)\n",
      "Downloading and preparing dataset tatdqa_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0...\n",
      "INFO:datasets.builder:Downloading and preparing dataset tatdqa_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0...\n",
      "hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/29576d4be1537818b597dc616ee63dd550d1dd78fb176049b4c4ed16de8ac47d.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/29576d4be1537818b597dc616ee63dd550d1dd78fb176049b4c4ed16de8ac47d.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/59.4k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 59.4k/59.4k [00:00<00:00, 187kB/s]\n",
      "storing hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/29576d4be1537818b597dc616ee63dd550d1dd78fb176049b4c4ed16de8ac47d\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/29576d4be1537818b597dc616ee63dd550d1dd78fb176049b4c4ed16de8ac47d\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/29576d4be1537818b597dc616ee63dd550d1dd78fb176049b4c4ed16de8ac47d\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/29576d4be1537818b597dc616ee63dd550d1dd78fb176049b4c4ed16de8ac47d\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                    | 0/1646 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 1646 examples in 140251 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0.incomplete/tatdqa_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 1646 examples in 140251 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0.incomplete/tatdqa_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1646/1646 [00:00<00:00, 9314.20 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset tatdqa_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset tatdqa_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                       | 0/1646 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0/cache-3a6f8eaacb56e8eb.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0/cache-3a6f8eaacb56e8eb.arrow\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 1646 examples in 170209 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0/tmp09gdeypk.<03:39,  7.50 examples/s]\n",
      "DEBUG:datasets.arrow_writer:Done writing 1646 examples in 170209 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/queries/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0/tmp09gdeypk.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1646/1646 [00:00<00:00, 4224.39 examples/s]\n",
      "Generating dataset tatdqa_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0)\n",
      "INFO:datasets.builder:Generating dataset tatdqa_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0)\n",
      "Downloading and preparing dataset tatdqa_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0...\n",
      "INFO:datasets.builder:Downloading and preparing dataset tatdqa_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0...\n",
      "hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/762168acc84149c8ff88cae08eda9eb4a87fda4783af012e0f89d818be47e8c4.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/762168acc84149c8ff88cae08eda9eb4a87fda4783af012e0f89d818be47e8c4.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                              | 0.00/127M [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   8%|████████████▎                                                                                                                                        | 10.5M/127M [00:00<00:05, 21.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  17%|████████████████████████▋                                                                                                                            | 21.0M/127M [00:00<00:04, 21.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  25%|█████████████████████████████████████                                                                                                                | 31.5M/127M [00:01<00:03, 25.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  33%|█████████████████████████████████████████████████▎                                                                                                   | 41.9M/127M [00:01<00:03, 27.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  41%|█████████████████████████████████████████████████████████████▋                                                                                       | 52.4M/127M [00:01<00:02, 28.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  50%|██████████████████████████████████████████████████████████████████████████                                                                           | 62.9M/127M [00:02<00:02, 30.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  58%|██████████████████████████████████████████████████████████████████████████████████████▎                                                              | 73.4M/127M [00:02<00:01, 31.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 83.9M/127M [00:02<00:01, 33.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 94.4M/127M [00:03<00:00, 35.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 105M/127M [00:03<00:00, 35.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 115M/127M [00:03<00:00, 33.9MB/s]\n",
      "\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127M/127M [00:04<00:00, 29.9MB/s]\n",
      "storing hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/762168acc84149c8ff88cae08eda9eb4a87fda4783af012e0f89d818be47e8c4\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/762168acc84149c8ff88cae08eda9eb4a87fda4783af012e0f89d818be47e8c4\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/762168acc84149c8ff88cae08eda9eb4a87fda4783af012e0f89d818be47e8c4\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/762168acc84149c8ff88cae08eda9eb4a87fda4783af012e0f89d818be47e8c4\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/277 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  36%|██████████████████████████████████████████████████▏                                                                                        | 100/277 [00:01<00:02, 70.85 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 200/277 [00:02<00:01, 76.12 examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 277 examples in 128915382 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0.incomplete/tatdqa_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 277 examples in 128915382 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0.incomplete/tatdqa_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 277/277 [00:03<00:00, 73.20 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset tatdqa_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset tatdqa_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/277 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0/cache-e44fccdd80b0c5a6.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0/cache-e44fccdd80b0c5a6.arrow\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 277 examples in 128920775 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0/tmp8i1b2lm4.00:57,  4.77 examples/s]\n",
      "DEBUG:datasets.arrow_writer:Done writing 277 examples in 128920775 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/corpus/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0/tmp8i1b2lm4.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[AFinished processing shard number None of 1.██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 277/277 [00:14<00:00, 19.34 examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 277/277 [00:14<00:00, 19.00 examples/s]\n",
      "Generating dataset tatdqa_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0)\n",
      "INFO:datasets.builder:Generating dataset tatdqa_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0)\n",
      "Downloading and preparing dataset tatdqa_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0...\n",
      "INFO:datasets.builder:Downloading and preparing dataset tatdqa_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0...\n",
      "hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/d5d8f64c28386dbce52092d5f47fb3fb0f58f20b9cf783a0dab87d40a1a50a2a.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/d5d8f64c28386dbce52092d5f47fb3fb0f58f20b9cf783a0dab87d40a1a50a2a.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/13.2k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13.2k/13.2k [00:00<00:00, 67.2kB/s]\n",
      "storing hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/d5d8f64c28386dbce52092d5f47fb3fb0f58f20b9cf783a0dab87d40a1a50a2a\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/tatdqa_test_beir@5feb5630fdff4d8d189ffedb2dba56862fdd45c0/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/d5d8f64c28386dbce52092d5f47fb3fb0f58f20b9cf783a0dab87d40a1a50a2a\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/d5d8f64c28386dbce52092d5f47fb3fb0f58f20b9cf783a0dab87d40a1a50a2a\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/d5d8f64c28386dbce52092d5f47fb3fb0f58f20b9cf783a0dab87d40a1a50a2a\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                    | 0/1663 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 1663 examples in 40536 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0.incomplete/tatdqa_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 1663 examples in 40536 bytes /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0.incomplete/tatdqa_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1663/1663 [00:00<00:00, 12016.41 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset tatdqa_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset tatdqa_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___tatdqa_test_beir/qrels/0.0.0/5feb5630fdff4d8d189ffedb2dba56862fdd45c0\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/823 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                    | 557/823 [00:13<00:06, 40.98it/s]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 823/823 [00:20<00:00, 41.02it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/139 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▌                                                                                                                                                               | 3/139 [00:13<10:11,  4.49s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   4%|█████▊                                                                                                                                                             | 5/139 [00:17<08:01,  3.59s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   7%|███████████▋                                                                                                                                                      | 10/139 [00:33<07:12,  3.35s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  11%|█████████████████▍                                                                                                                                                | 15/139 [00:49<06:48,  3.29s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|███████████████████████▎                                                                                                                                          | 20/139 [01:06<06:29,  3.27s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  18%|█████████████████████████████▏                                                                                                                                    | 25/139 [01:22<06:10,  3.25s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  22%|██████████████████████████████████▉                                                                                                                               | 30/139 [01:38<05:51,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  25%|████████████████████████████████████████▊                                                                                                                         | 35/139 [01:54<05:36,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  29%|██████████████████████████████████████████████▌                                                                                                                   | 40/139 [02:10<05:20,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  32%|████████████████████████████████████████████████████▍                                                                                                             | 45/139 [02:26<05:01,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  36%|██████████████████████████████████████████████████████████▎                                                                                                       | 50/139 [02:42<04:45,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|████████████████████████████████████████████████████████████████                                                                                                  | 55/139 [02:58<04:30,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  43%|█████████████████████████████████████████████████████████████████████▉                                                                                            | 60/139 [03:14<04:14,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  47%|███████████████████████████████████████████████████████████████████████████▊                                                                                      | 65/139 [03:30<03:57,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  50%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                | 70/139 [03:46<03:42,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  54%|███████████████████████████████████████████████████████████████████████████████████████▍                                                                          | 75/139 [04:02<03:25,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 80/139 [04:18<03:09,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  61%|███████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 85/139 [04:35<02:54,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 90/139 [04:51<02:37,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 95/139 [05:07<02:20,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 100/139 [05:23<02:05,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 105/139 [05:39<01:49,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 110/139 [05:55<01:33,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 115/139 [06:11<01:17,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 120/139 [06:27<01:01,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 125/139 [06:43<00:45,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 130/139 [06:59<00:28,  3.21s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 139/139 [07:26<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreShiftProjectRetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreShiftProjectRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreShiftProjectRetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/12484a72c15925042d4d3b6efa5a006e30f72d0cf14903d3dff00698fc9c2dc9.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/12484a72c15925042d4d3b6efa5a006e30f72d0cf14903d3dff00698fc9c2dc9.incomplete\n",
      "\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.07k/1.07k [00:00<00:00, 12.1kB/s]\n",
      "storing hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/12484a72c15925042d4d3b6efa5a006e30f72d0cf14903d3dff00698fc9c2dc9\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/12484a72c15925042d4d3b6efa5a006e30f72d0cf14903d3dff00698fc9c2dc9\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/12484a72c15925042d4d3b6efa5a006e30f72d0cf14903d3dff00698fc9c2dc9\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/12484a72c15925042d4d3b6efa5a006e30f72d0cf14903d3dff00698fc9c2dc9\n",
      "Generating dataset shiftproject_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117)\n",
      "INFO:datasets.builder:Generating dataset shiftproject_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117)\n",
      "Downloading and preparing dataset shiftproject_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117...\n",
      "INFO:datasets.builder:Downloading and preparing dataset shiftproject_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117...\n",
      "hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/1b0af3cced786bf5b8d00affadd4bc9e84016f06b26ea76e908d55bfddf20d47.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/1b0af3cced786bf5b8d00affadd4bc9e84016f06b26ea76e908d55bfddf20d47.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/7.59k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.59k/7.59k [00:02<00:00, 2.76kB/s]\n",
      "storing hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/1b0af3cced786bf5b8d00affadd4bc9e84016f06b26ea76e908d55bfddf20d47\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/1b0af3cced786bf5b8d00affadd4bc9e84016f06b26ea76e908d55bfddf20d47\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/1b0af3cced786bf5b8d00affadd4bc9e84016f06b26ea76e908d55bfddf20d47\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/1b0af3cced786bf5b8d00affadd4bc9e84016f06b26ea76e908d55bfddf20d47\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 11287 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117.incomplete/shiftproject_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 11287 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117.incomplete/shiftproject_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 5120.38 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset shiftproject_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset shiftproject_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/100 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117/cache-a8134901da2b9692.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117/cache-a8134901da2b9692.arrow\n",
      "Done writing 100 examples in 12964 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117/tmpaefdylvk.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 12964 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/queries/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117/tmpaefdylvk.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3037.22 examples/s]\n",
      "Generating dataset shiftproject_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117)\n",
      "INFO:datasets.builder:Generating dataset shiftproject_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117)\n",
      "Downloading and preparing dataset shiftproject_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117...\n",
      "INFO:datasets.builder:Downloading and preparing dataset shiftproject_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117...\n",
      "hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/80dbdcadf68956760cd0345544a4b62c579f7f5210561638bdf3a9b47e43000f.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/80dbdcadf68956760cd0345544a4b62c579f7f5210561638bdf3a9b47e43000f.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                              | 0.00/396M [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   3%|███▉                                                                                                                                                 | 10.5M/396M [00:00<00:19, 20.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   5%|███████▉                                                                                                                                             | 21.0M/396M [00:00<00:12, 30.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   8%|███████████▊                                                                                                                                         | 31.5M/396M [00:00<00:09, 38.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  11%|███████████████▊                                                                                                                                     | 41.9M/396M [00:01<00:08, 42.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  13%|███████████████████▋                                                                                                                                 | 52.4M/396M [00:01<00:07, 45.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  16%|███████████████████████▋                                                                                                                             | 62.9M/396M [00:01<00:07, 47.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  19%|███████████████████████████▌                                                                                                                         | 73.4M/396M [00:01<00:06, 48.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  21%|███████████████████████████████▌                                                                                                                     | 83.9M/396M [00:01<00:06, 50.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  24%|███████████████████████████████████▌                                                                                                                 | 94.4M/396M [00:02<00:05, 50.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  26%|███████████████████████████████████████▋                                                                                                              | 105M/396M [00:02<00:05, 51.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  29%|███████████████████████████████████████████▋                                                                                                          | 115M/396M [00:02<00:05, 50.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  32%|███████████████████████████████████████████████▋                                                                                                      | 126M/396M [00:02<00:05, 52.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  34%|███████████████████████████████████████████████████▋                                                                                                  | 136M/396M [00:02<00:04, 52.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  37%|███████████████████████████████████████████████████████▌                                                                                              | 147M/396M [00:03<00:04, 51.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  40%|███████████████████████████████████████████████████████████▌                                                                                          | 157M/396M [00:03<00:04, 48.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  42%|███████████████████████████████████████████████████████████████▌                                                                                      | 168M/396M [00:03<00:04, 48.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  45%|███████████████████████████████████████████████████████████████████▌                                                                                  | 178M/396M [00:03<00:04, 48.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  48%|███████████████████████████████████████████████████████████████████████▍                                                                              | 189M/396M [00:04<00:04, 47.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  50%|███████████████████████████████████████████████████████████████████████████▍                                                                          | 199M/396M [00:04<00:04, 48.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  53%|███████████████████████████████████████████████████████████████████████████████▍                                                                      | 210M/396M [00:04<00:03, 49.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  56%|███████████████████████████████████████████████████████████████████████████████████▍                                                                  | 220M/396M [00:04<00:03, 49.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  58%|███████████████████████████████████████████████████████████████████████████████████████▎                                                              | 231M/396M [00:04<00:03, 49.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  61%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                          | 241M/396M [00:05<00:03, 49.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  64%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 252M/396M [00:05<00:02, 49.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  66%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 262M/396M [00:05<00:02, 50.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 273M/396M [00:05<00:02, 49.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 283M/396M [00:05<00:02, 49.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 294M/396M [00:06<00:02, 49.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 304M/396M [00:06<00:01, 50.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 315M/396M [00:06<00:01, 51.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 325M/396M [00:06<00:01, 50.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 336M/396M [00:06<00:01, 51.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 346M/396M [00:07<00:00, 51.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 357M/396M [00:07<00:00, 52.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 367M/396M [00:07<00:00, 53.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 377M/396M [00:07<00:00, 52.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉   | 388M/396M [00:07<00:00, 52.8MB/s]\n",
      "\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 396M/396M [00:08<00:00, 48.6MB/s]\n",
      "storing hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/80dbdcadf68956760cd0345544a4b62c579f7f5210561638bdf3a9b47e43000f\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/80dbdcadf68956760cd0345544a4b62c579f7f5210561638bdf3a9b47e43000f\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/80dbdcadf68956760cd0345544a4b62c579f7f5210561638bdf3a9b47e43000f\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/80dbdcadf68956760cd0345544a4b62c579f7f5210561638bdf3a9b47e43000f\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                    | 0/1000 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  10%|█████████████▋                                                                                                                           | 100/1000 [00:00<00:03, 279.08 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  20%|███████████████████████████▍                                                                                                             | 200/1000 [00:00<00:02, 309.87 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  30%|█████████████████████████████████████████                                                                                                | 300/1000 [00:00<00:02, 316.27 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  40%|██████████████████████████████████████████████████████▊                                                                                  | 400/1000 [00:01<00:01, 332.16 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  50%|████████████████████████████████████████████████████████████████████▌                                                                    | 500/1000 [00:01<00:01, 354.48 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  60%|██████████████████████████████████████████████████████████████████████████████████▏                                                      | 600/1000 [00:01<00:01, 333.32 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  70%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                         | 700/1000 [00:02<00:00, 337.85 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 800/1000 [00:02<00:00, 354.43 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 900/1000 [00:02<00:00, 351.16 examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 1000 examples in 426577440 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117.incomplete/shiftproject_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 1000 examples in 426577440 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117.incomplete/shiftproject_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 339.77 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset shiftproject_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset shiftproject_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                       | 0/1000 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117/cache-c7a485353daf1454.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117/cache-c7a485353daf1454.arrow\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 1000 examples in 426597195 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117/tmp5lai6ga8.71.07 examples/s]\n",
      "DEBUG:datasets.arrow_writer:Done writing 1000 examples in 426597195 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/corpus/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117/tmp5lai6ga8.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 168.81 examples/s]\n",
      "Generating dataset shiftproject_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117)\n",
      "INFO:datasets.builder:Generating dataset shiftproject_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117)\n",
      "Downloading and preparing dataset shiftproject_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117...\n",
      "INFO:datasets.builder:Downloading and preparing dataset shiftproject_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117...\n",
      "hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/9954e7340af95ebcc39241a108dc8c1aa50ccbfe94a6946bf07d8e4089b076c1.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/9954e7340af95ebcc39241a108dc8c1aa50ccbfe94a6946bf07d8e4089b076c1.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/2.58k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.58k/2.58k [00:00<00:00, 16.3kB/s]\n",
      "storing hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/9954e7340af95ebcc39241a108dc8c1aa50ccbfe94a6946bf07d8e4089b076c1\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/shiftproject_test_beir@84a382e05c4473fed9cff2bbae95fe2379416117/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/9954e7340af95ebcc39241a108dc8c1aa50ccbfe94a6946bf07d8e4089b076c1\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/9954e7340af95ebcc39241a108dc8c1aa50ccbfe94a6946bf07d8e4089b076c1\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/9954e7340af95ebcc39241a108dc8c1aa50ccbfe94a6946bf07d8e4089b076c1\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117.incomplete/shiftproject_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117.incomplete/shiftproject_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 10663.85 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset shiftproject_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset shiftproject_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___shiftproject_test_beir/qrels/0.0.0/84a382e05c4473fed9cff2bbae95fe2379416117\n",
      "\n",
      "\n",
      "encode: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 40.74it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/500 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|▉                                                                                                                                                                  | 3/500 [00:11<32:40,  3.95s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█▋                                                                                                                                                                 | 5/500 [00:17<28:26,  3.45s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▏                                                                                                                                                              | 10/500 [00:32<26:32,  3.25s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   3%|████▊                                                                                                                                                             | 15/500 [00:48<25:44,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   4%|██████▍                                                                                                                                                           | 20/500 [01:04<25:30,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   5%|████████                                                                                                                                                          | 25/500 [01:19<25:00,  3.16s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   6%|█████████▋                                                                                                                                                        | 30/500 [01:35<24:36,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   7%|███████████▎                                                                                                                                                      | 35/500 [01:51<24:22,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   8%|████████████▉                                                                                                                                                     | 40/500 [02:06<24:08,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   9%|██████████████▌                                                                                                                                                   | 45/500 [02:22<23:47,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  10%|████████████████▏                                                                                                                                                 | 50/500 [02:38<23:28,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  11%|█████████████████▊                                                                                                                                                | 55/500 [02:54<23:21,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  12%|███████████████████▍                                                                                                                                              | 60/500 [03:09<23:00,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  13%|█████████████████████                                                                                                                                             | 65/500 [03:25<22:41,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|██████████████████████▋                                                                                                                                           | 70/500 [03:41<22:34,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  15%|████████████████████████▎                                                                                                                                         | 75/500 [03:56<22:13,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  16%|█████████████████████████▉                                                                                                                                        | 80/500 [04:12<21:55,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  17%|███████████████████████████▌                                                                                                                                      | 85/500 [04:28<21:47,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  18%|█████████████████████████████▏                                                                                                                                    | 90/500 [04:43<21:27,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  19%|██████████████████████████████▊                                                                                                                                   | 95/500 [04:59<21:07,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|████████████████████████████████▏                                                                                                                                | 100/500 [05:15<21:00,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  21%|█████████████████████████████████▊                                                                                                                               | 105/500 [05:30<20:40,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  22%|███████████████████████████████████▍                                                                                                                             | 110/500 [05:46<20:21,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  23%|█████████████████████████████████████                                                                                                                            | 115/500 [06:02<20:08,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  24%|██████████████████████████████████████▋                                                                                                                          | 120/500 [06:18<19:54,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  25%|████████████████████████████████████████▎                                                                                                                        | 125/500 [06:33<19:35,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  26%|█████████████████████████████████████████▊                                                                                                                       | 130/500 [06:49<19:17,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  27%|███████████████████████████████████████████▍                                                                                                                     | 135/500 [07:05<19:08,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  28%|█████████████████████████████████████████████                                                                                                                    | 140/500 [07:20<18:49,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  29%|██████████████████████████████████████████████▋                                                                                                                  | 145/500 [07:36<18:30,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  30%|████████████████████████████████████████████████▎                                                                                                                | 150/500 [07:52<18:22,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  31%|█████████████████████████████████████████████████▉                                                                                                               | 155/500 [08:07<18:02,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  32%|███████████████████████████████████████████████████▌                                                                                                             | 160/500 [08:23<17:44,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  33%|█████████████████████████████████████████████████████▏                                                                                                           | 165/500 [08:39<17:35,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  34%|██████████████████████████████████████████████████████▋                                                                                                          | 170/500 [08:54<17:15,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  35%|████████████████████████████████████████████████████████▎                                                                                                        | 175/500 [09:10<16:57,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  36%|█████████████████████████████████████████████████████████▉                                                                                                       | 180/500 [09:26<16:47,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  37%|███████████████████████████████████████████████████████████▌                                                                                                     | 185/500 [09:41<16:28,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  38%|█████████████████████████████████████████████████████████████▏                                                                                                   | 190/500 [09:57<16:10,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  39%|██████████████████████████████████████████████████████████████▊                                                                                                  | 195/500 [10:13<15:56,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|████████████████████████████████████████████████████████████████▍                                                                                                | 200/500 [10:29<15:42,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  41%|██████████████████████████████████████████████████████████████████                                                                                               | 205/500 [10:44<15:23,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  42%|███████████████████████████████████████████████████████████████████▌                                                                                             | 210/500 [11:00<15:06,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  43%|█████████████████████████████████████████████████████████████████████▏                                                                                           | 215/500 [11:16<14:56,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  44%|██████████████████████████████████████████████████████████████████████▊                                                                                          | 220/500 [11:31<14:37,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  45%|████████████████████████████████████████████████████████████████████████▍                                                                                        | 225/500 [11:47<14:19,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  46%|██████████████████████████████████████████████████████████████████████████                                                                                       | 230/500 [12:03<14:09,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  47%|███████████████████████████████████████████████████████████████████████████▋                                                                                     | 235/500 [12:18<13:51,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  48%|█████████████████████████████████████████████████████████████████████████████▎                                                                                   | 240/500 [12:34<13:33,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  49%|██████████████████████████████████████████████████████████████████████████████▉                                                                                  | 245/500 [12:50<13:22,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  50%|████████████████████████████████████████████████████████████████████████████████▌                                                                                | 250/500 [13:05<13:04,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  51%|██████████████████████████████████████████████████████████████████████████████████                                                                               | 255/500 [13:21<12:46,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  52%|███████████████████████████████████████████████████████████████████████████████████▋                                                                             | 260/500 [13:37<12:35,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  53%|█████████████████████████████████████████████████████████████████████████████████████▎                                                                           | 265/500 [13:52<12:17,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  54%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 270/500 [14:08<11:59,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  55%|████████████████████████████████████████████████████████████████████████████████████████▌                                                                        | 275/500 [14:24<11:45,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  56%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                      | 280/500 [14:39<11:31,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  57%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 285/500 [14:55<11:13,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|█████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 290/500 [15:11<10:56,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  59%|██████████████████████████████████████████████████████████████████████████████████████████████▉                                                                  | 295/500 [15:27<10:45,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  60%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                | 300/500 [15:42<10:26,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  61%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 305/500 [15:58<10:09,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 310/500 [16:14<09:58,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  63%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                           | 315/500 [16:29<09:40,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 320/500 [16:45<09:23,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 325/500 [17:01<09:10,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 330/500 [17:16<08:53,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 335/500 [17:32<08:35,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 340/500 [17:48<08:23,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                  | 345/500 [18:03<08:06,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 350/500 [18:19<07:49,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 355/500 [18:35<07:34,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                             | 360/500 [18:50<07:19,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 365/500 [19:06<07:02,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 370/500 [19:21<06:46,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                        | 375/500 [19:37<06:33,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                      | 380/500 [19:53<06:16,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                     | 385/500 [20:08<05:59,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 390/500 [20:24<05:46,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 395/500 [20:40<05:29,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 400/500 [20:56<05:12,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 405/500 [21:11<04:58,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                             | 410/500 [21:27<04:42,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 415/500 [21:43<04:25,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                         | 420/500 [21:59<04:11,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 425/500 [22:14<03:55,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 430/500 [22:30<03:38,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 435/500 [22:45<03:23,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 440/500 [23:01<03:08,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 445/500 [23:17<02:52,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 450/500 [23:32<02:36,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 455/500 [23:48<02:21,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 460/500 [24:04<02:05,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 465/500 [24:19<01:49,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 470/500 [24:35<01:34,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 475/500 [24:51<01:18,  3.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 480/500 [25:06<01:02,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 485/500 [25:22<00:47,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 490/500 [25:38<00:31,  3.13s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 495/500 [25:53<00:15,  3.13s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [26:09<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreSyntheticDocQAAIRetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreSyntheticDocQAAIRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreSyntheticDocQAAIRetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/3adab614b4ab117e708725f3aea4f00a49022a6dd0e449d274ad07a192f154d0.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/3adab614b4ab117e708725f3aea4f00a49022a6dd0e449d274ad07a192f154d0.incomplete\n",
      "\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.11k/1.11k [00:00<00:00, 12.5kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/3adab614b4ab117e708725f3aea4f00a49022a6dd0e449d274ad07a192f154d0\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/3adab614b4ab117e708725f3aea4f00a49022a6dd0e449d274ad07a192f154d0\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/3adab614b4ab117e708725f3aea4f00a49022a6dd0e449d274ad07a192f154d0\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/3adab614b4ab117e708725f3aea4f00a49022a6dd0e449d274ad07a192f154d0\n",
      "Generating dataset synthetic_doc_qa_artificial_intelligence_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_artificial_intelligence_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c)\n",
      "Downloading and preparing dataset synthetic_doc_qa_artificial_intelligence_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_artificial_intelligence_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c...\n",
      "hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/0c4b4f2c0268c3a00e4ade52b6d864385ca2fa21d17ecd08179e0c9ec497237e.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/0c4b4f2c0268c3a00e4ade52b6d864385ca2fa21d17ecd08179e0c9ec497237e.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/7.08k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.08k/7.08k [00:01<00:00, 3.74kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/0c4b4f2c0268c3a00e4ade52b6d864385ca2fa21d17ecd08179e0c9ec497237e\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/0c4b4f2c0268c3a00e4ade52b6d864385ca2fa21d17ecd08179e0c9ec497237e\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/0c4b4f2c0268c3a00e4ade52b6d864385ca2fa21d17ecd08179e0c9ec497237e\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/0c4b4f2c0268c3a00e4ade52b6d864385ca2fa21d17ecd08179e0c9ec497237e\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 8984 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c.incomplete/synthetic_doc_qa_artificial_intelligence_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 8984 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c.incomplete/synthetic_doc_qa_artificial_intelligence_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 5361.16 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_artificial_intelligence_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_artificial_intelligence_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/100 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/cache-dd1dfeb57e4ac3a9.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/cache-dd1dfeb57e4ac3a9.arrow\n",
      "Done writing 100 examples in 10661 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/tmp9dl3o_17.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 10661 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/queries/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/tmp9dl3o_17.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3218.29 examples/s]\n",
      "Generating dataset synthetic_doc_qa_artificial_intelligence_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_artificial_intelligence_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c)\n",
      "Downloading and preparing dataset synthetic_doc_qa_artificial_intelligence_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_artificial_intelligence_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c...\n",
      "hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/9688d251005cf01145001436729bf64365ea2a345317b91109ff18c35001b113.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/9688d251005cf01145001436729bf64365ea2a345317b91109ff18c35001b113.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                              | 0.00/303M [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   3%|█████▏                                                                                                                                               | 10.5M/303M [00:00<00:14, 20.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   7%|██████████▎                                                                                                                                          | 21.0M/303M [00:00<00:08, 31.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  10%|███████████████▍                                                                                                                                     | 31.5M/303M [00:00<00:06, 39.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  14%|████████████████████▌                                                                                                                                | 41.9M/303M [00:01<00:05, 45.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  17%|█████████████████████████▊                                                                                                                           | 52.4M/303M [00:01<00:05, 46.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  21%|██████████████████████████████▉                                                                                                                      | 62.9M/303M [00:01<00:04, 49.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  24%|████████████████████████████████████                                                                                                                 | 73.4M/303M [00:01<00:04, 51.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  28%|█████████████████████████████████████████▏                                                                                                           | 83.9M/303M [00:01<00:04, 52.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  31%|██████████████████████████████████████████████▎                                                                                                      | 94.4M/303M [00:02<00:03, 54.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  35%|███████████████████████████████████████████████████▊                                                                                                  | 105M/303M [00:02<00:03, 55.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  38%|█████████████████████████████████████████████████████████                                                                                             | 115M/303M [00:02<00:03, 55.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  41%|██████████████████████████████████████████████████████████████▏                                                                                       | 126M/303M [00:02<00:03, 55.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  45%|███████████████████████████████████████████████████████████████████▍                                                                                  | 136M/303M [00:02<00:03, 55.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  48%|████████████████████████████████████████████████████████████████████████▌                                                                             | 147M/303M [00:02<00:02, 55.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  52%|█████████████████████████████████████████████████████████████████████████████▊                                                                        | 157M/303M [00:03<00:02, 55.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  55%|██████████████████████████████████████████████████████████████████████████████████▉                                                                   | 168M/303M [00:03<00:02, 55.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  59%|████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 178M/303M [00:03<00:02, 55.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  62%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 189M/303M [00:03<00:02, 55.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 199M/303M [00:03<00:01, 56.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 210M/303M [00:04<00:01, 56.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                         | 220M/303M [00:04<00:01, 56.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 231M/303M [00:04<00:01, 55.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                              | 241M/303M [00:04<00:01, 56.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 252M/303M [00:04<00:00, 56.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 262M/303M [00:05<00:00, 55.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 273M/303M [00:05<00:00, 55.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 283M/303M [00:05<00:00, 56.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 294M/303M [00:05<00:00, 55.7MB/s]\n",
      "\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303M/303M [00:05<00:00, 52.2MB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/9688d251005cf01145001436729bf64365ea2a345317b91109ff18c35001b113\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/9688d251005cf01145001436729bf64365ea2a345317b91109ff18c35001b113\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/9688d251005cf01145001436729bf64365ea2a345317b91109ff18c35001b113\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/9688d251005cf01145001436729bf64365ea2a345317b91109ff18c35001b113\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/968 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  10%|██████████████▎                                                                                                                           | 100/968 [00:00<00:02, 413.26 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  21%|████████████████████████████▌                                                                                                             | 200/968 [00:00<00:01, 434.95 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  31%|██████████████████████████████████████████▊                                                                                               | 300/968 [00:00<00:01, 439.23 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  41%|█████████████████████████████████████████████████████████                                                                                 | 400/968 [00:00<00:01, 468.30 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  52%|███████████████████████████████████████████████████████████████████████▎                                                                  | 500/968 [00:01<00:00, 474.72 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  62%|█████████████████████████████████████████████████████████████████████████████████████▌                                                    | 600/968 [00:01<00:00, 470.22 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 700/968 [00:01<00:00, 477.66 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 800/968 [00:01<00:00, 480.74 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 900/968 [00:01<00:00, 468.05 examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 968 examples in 336104720 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c.incomplete/synthetic_doc_qa_artificial_intelligence_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 968 examples in 336104720 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c.incomplete/synthetic_doc_qa_artificial_intelligence_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 968/968 [00:02<00:00, 465.03 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_artificial_intelligence_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_artificial_intelligence_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/968 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/cache-55ad973e2612efca.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/cache-55ad973e2612efca.arrow\n",
      "Done writing 968 examples in 336123839 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/tmpypxwc_90.\n",
      "DEBUG:datasets.arrow_writer:Done writing 968 examples in 336123839 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/corpus/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/tmpypxwc_90.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[AFinished processing shard number None of 1.█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 968/968 [00:03<00:00, 246.86 examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 968/968 [00:03<00:00, 243.07 examples/s]\n",
      "Generating dataset synthetic_doc_qa_artificial_intelligence_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_artificial_intelligence_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c)\n",
      "Downloading and preparing dataset synthetic_doc_qa_artificial_intelligence_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_artificial_intelligence_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c...\n",
      "hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/88fab2b72c3f209d396481d0c01cc81df3a58f0fd8ba3d425454ed8d753832d4.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/88fab2b72c3f209d396481d0c01cc81df3a58f0fd8ba3d425454ed8d753832d4.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/2.46k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.46k/2.46k [00:00<00:00, 15.5kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/88fab2b72c3f209d396481d0c01cc81df3a58f0fd8ba3d425454ed8d753832d4\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_artificial_intelligence_test_beir@2d9ebea5a1c6e9ef4a3b902a612f605dca11261c/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/88fab2b72c3f209d396481d0c01cc81df3a58f0fd8ba3d425454ed8d753832d4\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/88fab2b72c3f209d396481d0c01cc81df3a58f0fd8ba3d425454ed8d753832d4\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/88fab2b72c3f209d396481d0c01cc81df3a58f0fd8ba3d425454ed8d753832d4\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c.incomplete/synthetic_doc_qa_artificial_intelligence_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c.incomplete/synthetic_doc_qa_artificial_intelligence_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 11210.22 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_artificial_intelligence_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_artificial_intelligence_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_artificial_intelligence_test_beir/qrels/0.0.0/2d9ebea5a1c6e9ef4a3b902a612f605dca11261c\n",
      "\n",
      "\n",
      "encode: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 40.46it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/484 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█                                                                                                                                                                  | 3/484 [00:11<30:22,  3.79s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█▋                                                                                                                                                                 | 5/484 [00:17<28:01,  3.51s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▎                                                                                                                                                              | 10/484 [00:33<26:22,  3.34s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   3%|█████                                                                                                                                                             | 15/484 [00:49<25:29,  3.26s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   4%|██████▋                                                                                                                                                           | 20/484 [01:04<24:41,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   5%|████████▎                                                                                                                                                         | 25/484 [01:20<24:25,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   6%|██████████                                                                                                                                                        | 30/484 [01:36<24:12,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   7%|███████████▋                                                                                                                                                      | 35/484 [01:53<23:58,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   8%|█████████████▍                                                                                                                                                    | 40/484 [02:09<23:42,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   9%|███████████████                                                                                                                                                   | 45/484 [02:24<23:20,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  10%|████████████████▋                                                                                                                                                 | 50/484 [02:40<23:06,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  11%|██████████████████▍                                                                                                                                               | 55/484 [02:57<22:56,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  12%|████████████████████                                                                                                                                              | 60/484 [03:13<22:41,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  13%|█████████████████████▊                                                                                                                                            | 65/484 [03:29<22:28,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|███████████████████████▍                                                                                                                                          | 70/484 [03:44<21:57,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  15%|█████████████████████████                                                                                                                                         | 75/484 [04:01<21:54,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  17%|██████████████████████████▊                                                                                                                                       | 80/484 [04:17<21:34,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  18%|████████████████████████████▍                                                                                                                                     | 85/484 [04:33<21:21,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  19%|██████████████████████████████                                                                                                                                    | 90/484 [04:49<21:07,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|███████████████████████████████▊                                                                                                                                  | 95/484 [05:05<20:46,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  21%|█████████████████████████████████▎                                                                                                                               | 100/484 [05:21<20:37,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  22%|██████████████████████████████████▉                                                                                                                              | 105/484 [05:37<20:18,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  23%|████████████████████████████████████▌                                                                                                                            | 110/484 [05:53<20:02,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  24%|██████████████████████████████████████▎                                                                                                                          | 115/484 [06:09<19:45,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  25%|███████████████████████████████████████▉                                                                                                                         | 120/484 [06:25<19:31,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  26%|█████████████████████████████████████████▌                                                                                                                       | 125/484 [06:41<18:56,  3.17s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  27%|███████████████████████████████████████████▏                                                                                                                     | 130/484 [06:57<18:46,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  28%|████████████████████████████████████████████▉                                                                                                                    | 135/484 [07:12<18:19,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  29%|██████████████████████████████████████████████▌                                                                                                                  | 140/484 [07:28<18:08,  3.16s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  30%|████████████████████████████████████████████████▏                                                                                                                | 145/484 [07:44<17:54,  3.17s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  31%|█████████████████████████████████████████████████▉                                                                                                               | 150/484 [08:00<17:46,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  32%|███████████████████████████████████████████████████▌                                                                                                             | 155/484 [08:16<17:33,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  33%|█████████████████████████████████████████████████████▏                                                                                                           | 160/484 [08:32<17:15,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  34%|██████████████████████████████████████████████████████▉                                                                                                          | 165/484 [08:49<17:05,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  35%|████████████████████████████████████████████████████████▌                                                                                                        | 170/484 [09:05<16:51,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  36%|██████████████████████████████████████████████████████████▏                                                                                                      | 175/484 [09:21<16:30,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  37%|███████████████████████████████████████████████████████████▉                                                                                                     | 180/484 [09:37<16:19,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  38%|█████████████████████████████████████████████████████████████▌                                                                                                   | 185/484 [09:53<16:00,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  39%|███████████████████████████████████████████████████████████████▏                                                                                                 | 190/484 [10:09<15:41,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|████████████████████████████████████████████████████████████████▊                                                                                                | 195/484 [10:25<15:30,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  41%|██████████████████████████████████████████████████████████████████▌                                                                                              | 200/484 [10:41<15:12,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  42%|████████████████████████████████████████████████████████████████████▏                                                                                            | 205/484 [10:57<14:55,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  43%|█████████████████████████████████████████████████████████████████████▊                                                                                           | 210/484 [11:13<14:42,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  44%|███████████████████████████████████████████████████████████████████████▌                                                                                         | 215/484 [11:29<14:27,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  45%|█████████████████████████████████████████████████████████████████████████▏                                                                                       | 220/484 [11:45<14:09,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  46%|██████████████████████████████████████████████████████████████████████████▊                                                                                      | 225/484 [12:02<13:53,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  48%|████████████████████████████████████████████████████████████████████████████▌                                                                                    | 230/484 [12:18<13:41,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  49%|██████████████████████████████████████████████████████████████████████████████▏                                                                                  | 235/484 [12:34<13:28,  3.25s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  50%|███████████████████████████████████████████████████████████████████████████████▊                                                                                 | 240/484 [12:50<13:07,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  51%|█████████████████████████████████████████████████████████████████████████████████▍                                                                               | 245/484 [13:06<12:51,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  52%|███████████████████████████████████████████████████████████████████████████████████▏                                                                             | 250/484 [13:22<12:34,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  53%|████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 255/484 [13:38<12:15,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  54%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                          | 260/484 [13:55<12:01,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  55%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 265/484 [14:11<11:46,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  56%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                                       | 270/484 [14:26<11:18,  3.17s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  57%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 275/484 [14:42<11:06,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                   | 280/484 [14:58<10:52,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  59%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 285/484 [15:14<10:34,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  60%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 290/484 [15:29<10:10,  3.15s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  61%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 295/484 [15:45<09:59,  3.17s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                             | 300/484 [16:01<09:44,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  63%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                           | 305/484 [16:17<09:29,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 310/484 [16:34<09:18,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 315/484 [16:50<09:03,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 320/484 [17:06<08:45,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 325/484 [17:22<08:30,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 330/484 [17:38<08:16,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                 | 335/484 [17:54<07:56,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 340/484 [18:10<07:43,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 345/484 [18:26<07:28,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 350/484 [18:43<07:12,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                           | 355/484 [18:59<06:55,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 360/484 [19:15<06:39,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                       | 365/484 [19:31<06:21,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 370/484 [19:47<06:05,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 375/484 [20:03<05:49,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 380/484 [20:19<05:33,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 385/484 [20:35<05:16,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 390/484 [20:51<05:03,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                             | 395/484 [21:07<04:46,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 400/484 [21:23<04:29,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 405/484 [21:39<04:15,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 410/484 [21:55<03:55,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 415/484 [22:11<03:40,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 420/484 [22:27<03:24,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 425/484 [22:43<03:09,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                  | 430/484 [22:58<02:50,  3.16s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 435/484 [23:14<02:35,  3.18s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 440/484 [23:31<02:20,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 445/484 [23:47<02:04,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 450/484 [24:02<01:47,  3.16s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 455/484 [24:18<01:32,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 460/484 [24:34<01:16,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 465/484 [24:50<01:00,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 470/484 [25:06<00:44,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 475/484 [25:22<00:28,  3.21s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 484/484 [25:51<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreSyntheticDocQAEnergyRetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreSyntheticDocQAEnergyRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreSyntheticDocQAEnergyRetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/e8f53645fb68f9a4e2d1f605da9786a4cb8040feb1322c1885f26ae79aba929e.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/e8f53645fb68f9a4e2d1f605da9786a4cb8040feb1322c1885f26ae79aba929e.incomplete\n",
      "\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.08k/1.08k [00:00<00:00, 7.68kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/e8f53645fb68f9a4e2d1f605da9786a4cb8040feb1322c1885f26ae79aba929e\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/e8f53645fb68f9a4e2d1f605da9786a4cb8040feb1322c1885f26ae79aba929e\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/e8f53645fb68f9a4e2d1f605da9786a4cb8040feb1322c1885f26ae79aba929e\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/e8f53645fb68f9a4e2d1f605da9786a4cb8040feb1322c1885f26ae79aba929e\n",
      "Generating dataset synthetic_doc_qa_energy_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_energy_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7)\n",
      "Downloading and preparing dataset synthetic_doc_qa_energy_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_energy_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7...\n",
      "hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/ec8d68fc03de8698a3a31a0b87ac2fcf47b502648103183c8dc7fa79e97af90b.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/ec8d68fc03de8698a3a31a0b87ac2fcf47b502648103183c8dc7fa79e97af90b.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/7.55k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.55k/7.55k [00:02<00:00, 2.64kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/ec8d68fc03de8698a3a31a0b87ac2fcf47b502648103183c8dc7fa79e97af90b\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/ec8d68fc03de8698a3a31a0b87ac2fcf47b502648103183c8dc7fa79e97af90b\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/ec8d68fc03de8698a3a31a0b87ac2fcf47b502648103183c8dc7fa79e97af90b\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/ec8d68fc03de8698a3a31a0b87ac2fcf47b502648103183c8dc7fa79e97af90b\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/100 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 9583 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7.incomplete/synthetic_doc_qa_energy_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 9583 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7.incomplete/synthetic_doc_qa_energy_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 420.89 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_energy_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_energy_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/100 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7/cache-315d906af1f88339.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7/cache-315d906af1f88339.arrow\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 11260 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7/tmpsg5303qf.xamples/s]\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 11260 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/queries/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7/tmpsg5303qf.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 175.50 examples/s]\n",
      "Generating dataset synthetic_doc_qa_energy_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_energy_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7)\n",
      "Downloading and preparing dataset synthetic_doc_qa_energy_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_energy_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7...\n",
      "hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/b08b5dc3239e5c14273241e05f40fae43a344419c74c8a6ce8d4c4479afdcb1b.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/b08b5dc3239e5c14273241e05f40fae43a344419c74c8a6ce8d4c4479afdcb1b.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                              | 0.00/273M [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   4%|█████▋                                                                                                                                               | 10.5M/273M [00:00<00:13, 19.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   8%|███████████▍                                                                                                                                         | 21.0M/273M [00:00<00:09, 25.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  12%|█████████████████▏                                                                                                                                   | 31.5M/273M [00:01<00:08, 27.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  15%|██████████████████████▉                                                                                                                              | 41.9M/273M [00:01<00:08, 28.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  19%|████████████████████████████▋                                                                                                                        | 52.4M/273M [00:01<00:07, 30.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  23%|██████████████████████████████████▎                                                                                                                  | 62.9M/273M [00:02<00:06, 32.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  27%|████████████████████████████████████████                                                                                                             | 73.4M/273M [00:02<00:05, 33.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  31%|█████████████████████████████████████████████▊                                                                                                       | 83.9M/273M [00:02<00:06, 30.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  35%|███████████████████████████████████████████████████▌                                                                                                 | 94.4M/273M [00:03<00:05, 33.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  38%|█████████████████████████████████████████████████████████▋                                                                                            | 105M/273M [00:03<00:05, 32.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  42%|███████████████████████████████████████████████████████████████▍                                                                                      | 115M/273M [00:03<00:05, 29.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  46%|█████████████████████████████████████████████████████████████████████▏                                                                                | 126M/273M [00:04<00:06, 21.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  50%|██████████████████████████████████████████████████████████████████████████▉                                                                           | 136M/273M [00:05<00:06, 21.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  54%|████████████████████████████████████████████████████████████████████████████████▋                                                                     | 147M/273M [00:05<00:05, 21.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  58%|██████████████████████████████████████████████████████████████████████████████████████▍                                                               | 157M/273M [00:06<00:04, 23.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  62%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 168M/273M [00:06<00:04, 25.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  65%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 178M/273M [00:06<00:03, 23.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 189M/273M [00:07<00:03, 22.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 199M/273M [00:07<00:03, 24.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 210M/273M [00:08<00:03, 19.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                             | 220M/273M [00:08<00:02, 22.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 231M/273M [00:09<00:01, 21.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 241M/273M [00:09<00:01, 21.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 252M/273M [00:10<00:01, 20.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏     | 262M/273M [00:10<00:00, 23.2MB/s]\n",
      "\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 273M/273M [00:11<00:00, 24.1MB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/b08b5dc3239e5c14273241e05f40fae43a344419c74c8a6ce8d4c4479afdcb1b\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/b08b5dc3239e5c14273241e05f40fae43a344419c74c8a6ce8d4c4479afdcb1b\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/b08b5dc3239e5c14273241e05f40fae43a344419c74c8a6ce8d4c4479afdcb1b\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/b08b5dc3239e5c14273241e05f40fae43a344419c74c8a6ce8d4c4479afdcb1b\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/977 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  10%|██████████████▏                                                                                                                            | 100/977 [00:01<00:12, 72.12 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  20%|████████████████████████████▍                                                                                                              | 200/977 [00:02<00:10, 77.25 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  31%|██████████████████████████████████████████▋                                                                                                | 300/977 [00:03<00:08, 81.61 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  41%|████████████████████████████████████████████████████████▉                                                                                  | 400/977 [00:04<00:06, 87.24 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  51%|███████████████████████████████████████████████████████████████████████▏                                                                   | 500/977 [00:05<00:05, 88.08 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  61%|█████████████████████████████████████████████████████████████████████████████████████▎                                                     | 600/977 [00:07<00:04, 82.61 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 700/977 [00:08<00:03, 87.54 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 800/977 [00:09<00:01, 92.89 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 900/977 [00:09<00:00, 114.46 examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 977 examples in 313612285 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7.incomplete/synthetic_doc_qa_energy_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 977 examples in 313612285 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7.incomplete/synthetic_doc_qa_energy_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 977/977 [00:10<00:00, 95.58 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_energy_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_energy_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/977 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7/cache-43c1efbad4c29431.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7/cache-43c1efbad4c29431.arrow\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 977 examples in 313631584 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7/tmpphklsrzk.ples/s]\n",
      "DEBUG:datasets.arrow_writer:Done writing 977 examples in 313631584 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/corpus/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7/tmpphklsrzk.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[AFinished processing shard number None of 1.██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 977/977 [00:41<00:00, 23.79 examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 977/977 [00:41<00:00, 23.48 examples/s]\n",
      "Generating dataset synthetic_doc_qa_energy_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_energy_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7)\n",
      "Downloading and preparing dataset synthetic_doc_qa_energy_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_energy_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7...\n",
      "hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/51e7b92af697da8659e4e504a1b618aad7dc99e4c2e1a7a097fba00986906ab3.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/51e7b92af697da8659e4e504a1b618aad7dc99e4c2e1a7a097fba00986906ab3.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/2.49k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.49k/2.49k [00:00<00:00, 12.5kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/51e7b92af697da8659e4e504a1b618aad7dc99e4c2e1a7a097fba00986906ab3\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_energy_test_beir@9935aadbad5c8deec30910489db1b2c7133ae7a7/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/51e7b92af697da8659e4e504a1b618aad7dc99e4c2e1a7a097fba00986906ab3\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/51e7b92af697da8659e4e504a1b618aad7dc99e4c2e1a7a097fba00986906ab3\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/51e7b92af697da8659e4e504a1b618aad7dc99e4c2e1a7a097fba00986906ab3\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/100 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7.incomplete/synthetic_doc_qa_energy_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7.incomplete/synthetic_doc_qa_energy_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 493.34 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_energy_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_energy_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_energy_test_beir/qrels/0.0.0/9935aadbad5c8deec30910489db1b2c7133ae7a7\n",
      "\n",
      "\n",
      "encode: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 39.93it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/489 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   0%|▋                                                                                                                                                                  | 2/489 [00:10<44:20,  5.46s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█▋                                                                                                                                                                 | 5/489 [00:17<28:13,  3.50s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▎                                                                                                                                                              | 10/489 [00:33<26:23,  3.31s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   3%|████▉                                                                                                                                                             | 15/489 [00:49<25:40,  3.25s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   4%|██████▋                                                                                                                                                           | 20/489 [01:05<25:21,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   5%|████████▎                                                                                                                                                         | 25/489 [01:21<24:54,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   6%|█████████▉                                                                                                                                                        | 30/489 [01:37<24:31,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   7%|███████████▌                                                                                                                                                      | 35/489 [01:53<24:14,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   8%|█████████████▎                                                                                                                                                    | 40/489 [02:09<23:57,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   9%|██████████████▉                                                                                                                                                   | 45/489 [02:25<23:40,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  10%|████████████████▌                                                                                                                                                 | 50/489 [02:41<23:26,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  11%|██████████████████▏                                                                                                                                               | 55/489 [02:57<23:11,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  12%|███████████████████▉                                                                                                                                              | 60/489 [03:13<22:49,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  13%|█████████████████████▌                                                                                                                                            | 65/489 [03:29<22:32,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|███████████████████████▏                                                                                                                                          | 70/489 [03:45<22:23,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  15%|████████████████████████▊                                                                                                                                         | 75/489 [04:01<22:02,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  16%|██████████████████████████▌                                                                                                                                       | 80/489 [04:17<21:46,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  17%|████████████████████████████▏                                                                                                                                     | 85/489 [04:33<21:35,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  18%|█████████████████████████████▊                                                                                                                                    | 90/489 [04:49<21:14,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  19%|███████████████████████████████▍                                                                                                                                  | 95/489 [05:05<20:58,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|████████████████████████████████▉                                                                                                                                | 100/489 [05:21<20:45,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  21%|██████████████████████████████████▌                                                                                                                              | 105/489 [05:37<20:26,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  22%|████████████████████████████████████▏                                                                                                                            | 110/489 [05:52<20:09,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  24%|█████████████████████████████████████▊                                                                                                                           | 115/489 [06:08<19:55,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  25%|███████████████████████████████████████▌                                                                                                                         | 120/489 [06:25<19:41,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  26%|█████████████████████████████████████████▏                                                                                                                       | 125/489 [06:40<19:21,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  27%|██████████████████████████████████████████▊                                                                                                                      | 130/489 [06:56<19:08,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  28%|████████████████████████████████████████████▍                                                                                                                    | 135/489 [07:13<18:54,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  29%|██████████████████████████████████████████████                                                                                                                   | 140/489 [07:28<18:34,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  30%|███████████████████████████████████████████████▋                                                                                                                 | 145/489 [07:44<18:17,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  31%|█████████████████████████████████████████████████▍                                                                                                               | 150/489 [08:01<18:07,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  32%|███████████████████████████████████████████████████                                                                                                              | 155/489 [08:17<17:51,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  33%|████████████████████████████████████████████████████▋                                                                                                            | 160/489 [08:33<17:36,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  34%|██████████████████████████████████████████████████████▎                                                                                                          | 165/489 [08:49<17:25,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  35%|███████████████████████████████████████████████████████▉                                                                                                         | 170/489 [09:05<17:06,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  36%|█████████████████████████████████████████████████████████▌                                                                                                       | 175/489 [09:21<16:49,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  37%|███████████████████████████████████████████████████████████▎                                                                                                     | 180/489 [09:37<16:39,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  38%|████████████████████████████████████████████████████████████▉                                                                                                    | 185/489 [09:53<16:20,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  39%|██████████████████████████████████████████████████████████████▌                                                                                                  | 190/489 [10:10<16:03,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|████████████████████████████████████████████████████████████████▏                                                                                                | 195/489 [10:26<15:49,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  41%|█████████████████████████████████████████████████████████████████▊                                                                                               | 200/489 [10:42<15:34,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  42%|███████████████████████████████████████████████████████████████████▍                                                                                             | 205/489 [10:58<15:15,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  43%|█████████████████████████████████████████████████████████████████████▏                                                                                           | 210/489 [11:14<15:01,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  44%|██████████████████████████████████████████████████████████████████████▊                                                                                          | 215/489 [11:30<14:46,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  45%|████████████████████████████████████████████████████████████████████████▍                                                                                        | 220/489 [11:46<14:26,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  46%|██████████████████████████████████████████████████████████████████████████                                                                                       | 225/489 [12:02<14:09,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  47%|███████████████████████████████████████████████████████████████████████████▋                                                                                     | 230/489 [12:19<13:57,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  48%|█████████████████████████████████████████████████████████████████████████████▎                                                                                   | 235/489 [12:35<13:39,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  49%|███████████████████████████████████████████████████████████████████████████████                                                                                  | 240/489 [12:51<13:24,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  50%|████████████████████████████████████████████████████████████████████████████████▋                                                                                | 245/489 [13:07<13:11,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  51%|██████████████████████████████████████████████████████████████████████████████████▎                                                                              | 250/489 [13:23<12:51,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  52%|███████████████████████████████████████████████████████████████████████████████████▉                                                                             | 255/489 [13:40<12:35,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  53%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                           | 260/489 [13:56<12:22,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  54%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 265/489 [14:12<12:02,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  55%|████████████████████████████████████████████████████████████████████████████████████████▉                                                                        | 270/489 [14:28<11:45,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  56%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 275/489 [14:44<11:30,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  57%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 280/489 [15:00<11:14,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                   | 285/489 [15:16<10:56,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  59%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 290/489 [15:33<10:42,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  60%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 295/489 [15:49<10:27,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  61%|██████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 300/489 [16:05<10:10,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  62%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                            | 305/489 [16:21<09:54,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  63%|██████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 310/489 [16:37<09:39,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 315/489 [16:53<09:20,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 320/489 [17:09<09:04,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 325/489 [17:25<08:48,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                    | 330/489 [17:41<08:30,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 335/489 [17:57<08:13,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  70%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 340/489 [18:13<07:59,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 345/489 [18:29<07:41,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 350/489 [18:45<07:23,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                            | 355/489 [19:01<07:08,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 360/489 [19:17<06:52,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 365/489 [19:33<06:35,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 370/489 [19:49<06:20,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 375/489 [20:05<06:05,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 380/489 [20:21<05:48,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 385/489 [20:37<05:31,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                | 390/489 [20:53<05:16,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 395/489 [21:09<04:59,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 400/489 [21:25<04:43,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 405/489 [21:41<04:29,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 410/489 [21:57<04:12,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                        | 415/489 [22:13<03:55,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 420/489 [22:29<03:41,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 425/489 [22:45<03:24,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                   | 430/489 [23:01<03:08,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 435/489 [23:17<02:52,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 440/489 [23:33<02:36,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 445/489 [23:49<02:20,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 450/489 [24:05<02:04,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 455/489 [24:21<01:48,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 460/489 [24:37<01:32,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 465/489 [24:53<01:16,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 470/489 [25:09<01:00,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 475/489 [25:25<00:44,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 480/489 [25:41<00:28,  3.19s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 489/489 [26:07<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreSyntheticDocQAGovernmentReportsRetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreSyntheticDocQAGovernmentReportsRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreSyntheticDocQAGovernmentReportsRetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/6650e2687d04968f23298bccecc8ad9de57767069199996a37dbcede504823fd.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/6650e2687d04968f23298bccecc8ad9de57767069199996a37dbcede504823fd.incomplete\n",
      "\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.10k/1.10k [00:00<00:00, 13.0kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/6650e2687d04968f23298bccecc8ad9de57767069199996a37dbcede504823fd\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/6650e2687d04968f23298bccecc8ad9de57767069199996a37dbcede504823fd\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/6650e2687d04968f23298bccecc8ad9de57767069199996a37dbcede504823fd\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/6650e2687d04968f23298bccecc8ad9de57767069199996a37dbcede504823fd\n",
      "Generating dataset synthetic_doc_qa_government_reports_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_government_reports_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa)\n",
      "Downloading and preparing dataset synthetic_doc_qa_government_reports_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_government_reports_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa...\n",
      "hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/59bfc20ee05c0b4e699006e960eddd3e31ef55f6fc0ba5859c0d1b93aa8e151c.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/59bfc20ee05c0b4e699006e960eddd3e31ef55f6fc0ba5859c0d1b93aa8e151c.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/7.47k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.47k/7.47k [00:02<00:00, 3.46kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/59bfc20ee05c0b4e699006e960eddd3e31ef55f6fc0ba5859c0d1b93aa8e151c\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/59bfc20ee05c0b4e699006e960eddd3e31ef55f6fc0ba5859c0d1b93aa8e151c\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/59bfc20ee05c0b4e699006e960eddd3e31ef55f6fc0ba5859c0d1b93aa8e151c\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/59bfc20ee05c0b4e699006e960eddd3e31ef55f6fc0ba5859c0d1b93aa8e151c\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 9466 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa.incomplete/synthetic_doc_qa_government_reports_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 9466 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa.incomplete/synthetic_doc_qa_government_reports_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 10578.85 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_government_reports_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_government_reports_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/100 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa/cache-407ea6a24271e819.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa/cache-407ea6a24271e819.arrow\n",
      "Done writing 100 examples in 11143 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa/tmpswpehqld.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 11143 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/queries/0.0.0/b4909afa930f81282fd20601e860668073ad02aa/tmpswpehqld.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3034.82 examples/s]\n",
      "Generating dataset synthetic_doc_qa_government_reports_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_government_reports_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa)\n",
      "Downloading and preparing dataset synthetic_doc_qa_government_reports_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_government_reports_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa...\n",
      "hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/d49dc9d5f7281ebb643a72b24d5b62cdb905c0659ee03342f675553bbdfc015e.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/d49dc9d5f7281ebb643a72b24d5b62cdb905c0659ee03342f675553bbdfc015e.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                              | 0.00/338M [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   3%|████▋                                                                                                                                                | 10.5M/338M [00:00<00:16, 19.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   6%|█████████▎                                                                                                                                           | 21.0M/338M [00:00<00:11, 28.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   9%|█████████████▉                                                                                                                                       | 31.5M/338M [00:01<00:09, 32.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  12%|██████████████████▌                                                                                                                                  | 41.9M/338M [00:01<00:08, 35.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  16%|███████████████████████▏                                                                                                                             | 52.4M/338M [00:01<00:07, 37.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  19%|███████████████████████████▊                                                                                                                         | 62.9M/338M [00:01<00:07, 38.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  22%|████████████████████████████████▍                                                                                                                    | 73.4M/338M [00:02<00:06, 39.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  25%|█████████████████████████████████████                                                                                                                | 83.9M/338M [00:02<00:06, 39.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  28%|█████████████████████████████████████████▋                                                                                                           | 94.4M/338M [00:02<00:06, 38.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  31%|██████████████████████████████████████████████▌                                                                                                       | 105M/338M [00:02<00:05, 39.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  34%|███████████████████████████████████████████████████▎                                                                                                  | 115M/338M [00:03<00:05, 42.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  37%|███████████████████████████████████████████████████████▉                                                                                              | 126M/338M [00:03<00:05, 39.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  40%|████████████████████████████████████████████████████████████▌                                                                                         | 136M/338M [00:03<00:05, 37.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  43%|█████████████████████████████████████████████████████████████████▏                                                                                    | 147M/338M [00:03<00:05, 37.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  47%|█████████████████████████████████████████████████████████████████████▉                                                                                | 157M/338M [00:04<00:04, 40.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  50%|██████████████████████████████████████████████████████████████████████████▌                                                                           | 168M/338M [00:04<00:04, 36.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  53%|███████████████████████████████████████████████████████████████████████████████▏                                                                      | 178M/338M [00:04<00:04, 36.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  56%|███████████████████████████████████████████████████████████████████████████████████▉                                                                  | 189M/338M [00:05<00:03, 38.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  59%|████████████████████████████████████████████████████████████████████████████████████████▌                                                             | 199M/338M [00:05<00:03, 40.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  62%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 210M/338M [00:05<00:03, 41.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  65%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 220M/338M [00:05<00:02, 39.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  68%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 231M/338M [00:06<00:02, 38.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 241M/338M [00:06<00:02, 37.1MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 252M/338M [00:06<00:02, 36.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 262M/338M [00:07<00:02, 37.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 273M/338M [00:07<00:01, 38.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 283M/338M [00:07<00:01, 39.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 294M/338M [00:07<00:01, 41.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 304M/338M [00:07<00:00, 42.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 315M/338M [00:08<00:00, 43.6MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 325M/338M [00:08<00:00, 43.3MB/s]\n",
      "\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 338M/338M [00:08<00:00, 38.0MB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/d49dc9d5f7281ebb643a72b24d5b62cdb905c0659ee03342f675553bbdfc015e\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/d49dc9d5f7281ebb643a72b24d5b62cdb905c0659ee03342f675553bbdfc015e\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/d49dc9d5f7281ebb643a72b24d5b62cdb905c0659ee03342f675553bbdfc015e\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/d49dc9d5f7281ebb643a72b24d5b62cdb905c0659ee03342f675553bbdfc015e\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/972 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  10%|██████████████▏                                                                                                                           | 100/972 [00:00<00:08, 107.61 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  21%|████████████████████████████▍                                                                                                             | 200/972 [00:01<00:06, 111.30 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  31%|██████████████████████████████████████████▌                                                                                               | 300/972 [00:02<00:05, 114.88 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  41%|████████████████████████████████████████████████████████▊                                                                                 | 400/972 [00:03<00:04, 118.47 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  51%|██████████████████████████████████████████████████████████████████████▉                                                                   | 500/972 [00:04<00:03, 121.28 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  62%|█████████████████████████████████████████████████████████████████████████████████████▏                                                    | 600/972 [00:05<00:03, 119.19 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 700/972 [00:05<00:02, 123.41 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 800/972 [00:06<00:01, 125.41 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 900/972 [00:07<00:00, 132.11 examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 972 examples in 369476974 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa.incomplete/synthetic_doc_qa_government_reports_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 972 examples in 369476974 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa.incomplete/synthetic_doc_qa_government_reports_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 972/972 [00:07<00:00, 123.52 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_government_reports_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_government_reports_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/972 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa/cache-02ccfbc82d1e83c0.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa/cache-02ccfbc82d1e83c0.arrow\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 972 examples in 369496174 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa/tmpszbj7_ss.\n",
      "DEBUG:datasets.arrow_writer:Done writing 972 examples in 369496174 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/corpus/0.0.0/b4909afa930f81282fd20601e860668073ad02aa/tmpszbj7_ss.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[AFinished processing shard number None of 1.██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 972/972 [00:41<00:00, 23.39 examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 972/972 [00:42<00:00, 23.10 examples/s]\n",
      "Generating dataset synthetic_doc_qa_government_reports_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_government_reports_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa)\n",
      "Downloading and preparing dataset synthetic_doc_qa_government_reports_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_government_reports_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa...\n",
      "hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/2294db7935626dcce0bd0b8c0cb52f63ebf644a190f66ff722f906b217bc2caf.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/2294db7935626dcce0bd0b8c0cb52f63ebf644a190f66ff722f906b217bc2caf.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/2.47k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.47k/2.47k [00:00<00:00, 12.4kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/2294db7935626dcce0bd0b8c0cb52f63ebf644a190f66ff722f906b217bc2caf\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_government_reports_test_beir@b4909afa930f81282fd20601e860668073ad02aa/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/2294db7935626dcce0bd0b8c0cb52f63ebf644a190f66ff722f906b217bc2caf\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/2294db7935626dcce0bd0b8c0cb52f63ebf644a190f66ff722f906b217bc2caf\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/2294db7935626dcce0bd0b8c0cb52f63ebf644a190f66ff722f906b217bc2caf\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/100 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa.incomplete/synthetic_doc_qa_government_reports_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa.incomplete/synthetic_doc_qa_government_reports_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 439.39 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_government_reports_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_government_reports_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_government_reports_test_beir/qrels/0.0.0/b4909afa930f81282fd20601e860668073ad02aa\n",
      "\n",
      "\n",
      "encode: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 40.61it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/486 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█                                                                                                                                                                  | 3/486 [00:10<29:14,  3.63s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█▋                                                                                                                                                                 | 5/486 [00:17<27:48,  3.47s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▎                                                                                                                                                              | 10/486 [00:33<26:08,  3.29s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   3%|█████                                                                                                                                                             | 15/486 [00:49<25:23,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   4%|██████▋                                                                                                                                                           | 20/486 [01:05<25:05,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   5%|████████▎                                                                                                                                                         | 25/486 [01:21<24:42,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   6%|██████████                                                                                                                                                        | 30/486 [01:36<24:19,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   7%|███████████▋                                                                                                                                                      | 35/486 [01:52<24:02,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   8%|█████████████▎                                                                                                                                                    | 40/486 [02:08<23:46,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   9%|███████████████                                                                                                                                                   | 45/486 [02:24<23:29,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  10%|████████████████▋                                                                                                                                                 | 50/486 [02:40<23:12,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  11%|██████████████████▎                                                                                                                                               | 55/486 [02:56<22:59,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  12%|████████████████████                                                                                                                                              | 60/486 [03:12<22:40,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  13%|█████████████████████▋                                                                                                                                            | 65/486 [03:28<22:24,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|███████████████████████▎                                                                                                                                          | 70/486 [03:44<22:12,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  15%|█████████████████████████                                                                                                                                         | 75/486 [04:00<21:54,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  16%|██████████████████████████▋                                                                                                                                       | 80/486 [04:16<21:36,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  17%|████████████████████████████▎                                                                                                                                     | 85/486 [04:32<21:22,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  19%|██████████████████████████████                                                                                                                                    | 90/486 [04:48<21:04,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|███████████████████████████████▋                                                                                                                                  | 95/486 [05:04<20:49,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  21%|█████████████████████████████████▏                                                                                                                               | 100/486 [05:20<20:34,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  22%|██████████████████████████████████▊                                                                                                                              | 105/486 [05:36<20:17,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  23%|████████████████████████████████████▍                                                                                                                            | 110/486 [05:52<19:58,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  24%|██████████████████████████████████████                                                                                                                           | 115/486 [06:08<19:44,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  25%|███████████████████████████████████████▊                                                                                                                         | 120/486 [06:24<19:30,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  26%|█████████████████████████████████████████▍                                                                                                                       | 125/486 [06:40<19:12,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  27%|███████████████████████████████████████████                                                                                                                      | 130/486 [06:56<18:56,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  28%|████████████████████████████████████████████▋                                                                                                                    | 135/486 [07:12<18:45,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  29%|██████████████████████████████████████████████▍                                                                                                                  | 140/486 [07:28<18:26,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  30%|████████████████████████████████████████████████                                                                                                                 | 145/486 [07:44<18:08,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  31%|█████████████████████████████████████████████████▋                                                                                                               | 150/486 [08:00<17:55,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  32%|███████████████████████████████████████████████████▎                                                                                                             | 155/486 [08:16<17:37,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  33%|█████████████████████████████████████████████████████                                                                                                            | 160/486 [08:32<17:20,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  34%|██████████████████████████████████████████████████████▋                                                                                                          | 165/486 [08:48<17:07,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  35%|████████████████████████████████████████████████████████▎                                                                                                        | 170/486 [09:04<16:50,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  36%|█████████████████████████████████████████████████████████▉                                                                                                       | 175/486 [09:20<16:33,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  37%|███████████████████████████████████████████████████████████▋                                                                                                     | 180/486 [09:36<16:17,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  38%|█████████████████████████████████████████████████████████████▎                                                                                                   | 185/486 [09:52<16:02,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  39%|██████████████████████████████████████████████████████████████▉                                                                                                  | 190/486 [10:08<15:44,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|████████████████████████████████████████████████████████████████▌                                                                                                | 195/486 [10:24<15:29,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  41%|██████████████████████████████████████████████████████████████████▎                                                                                              | 200/486 [10:40<15:15,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  42%|███████████████████████████████████████████████████████████████████▉                                                                                             | 205/486 [10:56<14:57,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  43%|█████████████████████████████████████████████████████████████████████▌                                                                                           | 210/486 [11:12<14:39,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  44%|███████████████████████████████████████████████████████████████████████▏                                                                                         | 215/486 [11:28<14:27,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  45%|████████████████████████████████████████████████████████████████████████▉                                                                                        | 220/486 [11:44<14:08,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  46%|██████████████████████████████████████████████████████████████████████████▌                                                                                      | 225/486 [11:59<13:51,  3.19s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  47%|████████████████████████████████████████████████████████████████████████████▏                                                                                    | 230/486 [12:16<13:41,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  48%|█████████████████████████████████████████████████████████████████████████████▊                                                                                   | 235/486 [12:32<13:25,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  49%|███████████████████████████████████████████████████████████████████████████████▌                                                                                 | 240/486 [12:48<13:10,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  50%|█████████████████████████████████████████████████████████████████████████████████▏                                                                               | 245/486 [13:04<12:55,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  51%|██████████████████████████████████████████████████████████████████████████████████▊                                                                              | 250/486 [13:20<12:40,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  52%|████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 255/486 [13:36<12:24,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  53%|██████████████████████████████████████████████████████████████████████████████████████▏                                                                          | 260/486 [13:53<12:09,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  55%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 265/486 [14:09<11:53,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  56%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 270/486 [14:25<11:36,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  57%|███████████████████████████████████████████████████████████████████████████████████████████                                                                      | 275/486 [14:41<11:20,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|████████████████████████████████████████████████████████████████████████████████████████████▊                                                                    | 280/486 [14:57<11:05,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  59%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                  | 285/486 [15:13<10:48,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  60%|████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 290/486 [15:29<10:31,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  61%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 295/486 [15:45<10:16,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 300/486 [16:01<09:58,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  63%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                            | 305/486 [16:18<09:42,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 310/486 [16:34<09:29,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 315/486 [16:50<09:12,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 320/486 [17:06<08:54,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 325/486 [17:22<08:40,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                   | 330/486 [17:38<08:24,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 335/486 [17:54<08:06,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 340/486 [18:11<07:51,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 345/486 [18:27<07:35,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                             | 350/486 [18:43<07:18,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 355/486 [18:59<07:03,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                         | 360/486 [19:15<06:48,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 365/486 [19:31<06:30,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 370/486 [19:48<06:14,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                    | 375/486 [20:04<05:58,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 380/486 [20:20<05:41,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 385/486 [20:36<05:25,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 390/486 [20:52<05:10,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 395/486 [21:08<04:53,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 400/486 [21:24<04:37,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                          | 405/486 [21:41<04:21,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 410/486 [21:57<04:05,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 415/486 [22:13<03:49,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 420/486 [22:29<03:33,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 425/486 [22:45<03:17,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 430/486 [23:01<03:00,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 435/486 [23:17<02:44,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 440/486 [23:34<02:29,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 445/486 [23:50<02:12,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 450/486 [24:06<01:56,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 455/486 [24:22<01:40,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 460/486 [24:38<01:23,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 465/486 [24:54<01:07,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 470/486 [25:11<00:51,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 475/486 [25:27<00:35,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 480/486 [25:43<00:19,  3.23s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 486/486 [26:02<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Visual Documents Dataset : VidoreSyntheticDocQAHealthcareIndustryRetrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">DocumentUnderstanding</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mDocumentUnderstanding\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VidoreSyntheticDocQAHealthcareIndustryRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">t2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VidoreSyntheticDocQAHealthcareIndustryRetrieval, \u001b[3;38;5;241mt2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/795ee2be8211cdf39a47488087a5e9a4460809d6d161e1ec404ee97ecf9ca4db.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/README.md not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/795ee2be8211cdf39a47488087a5e9a4460809d6d161e1ec404ee97ecf9ca4db.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading readme:   0%|                                                                                                                                                           | 0.00/1.11k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading readme: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.11k/1.11k [00:00<00:00, 10.0kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/795ee2be8211cdf39a47488087a5e9a4460809d6d161e1ec404ee97ecf9ca4db\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/README.md in cache at /home/aamita/.cache/huggingface/datasets/downloads/795ee2be8211cdf39a47488087a5e9a4460809d6d161e1ec404ee97ecf9ca4db\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/795ee2be8211cdf39a47488087a5e9a4460809d6d161e1ec404ee97ecf9ca4db\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/795ee2be8211cdf39a47488087a5e9a4460809d6d161e1ec404ee97ecf9ca4db\n",
      "Generating dataset synthetic_doc_qa_healthcare_industry_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_healthcare_industry_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164)\n",
      "Downloading and preparing dataset synthetic_doc_qa_healthcare_industry_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_healthcare_industry_test_beir/queries to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164...\n",
      "hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/b7ae660bc79ba26b75e245ea120e69a92b4cbd6443d8c3a703315b221afa8598.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/queries/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/b7ae660bc79ba26b75e245ea120e69a92b4cbd6443d8c3a703315b221afa8598.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/7.13k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.13k/7.13k [00:03<00:00, 2.21kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/b7ae660bc79ba26b75e245ea120e69a92b4cbd6443d8c3a703315b221afa8598\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/queries/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/b7ae660bc79ba26b75e245ea120e69a92b4cbd6443d8c3a703315b221afa8598\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/b7ae660bc79ba26b75e245ea120e69a92b4cbd6443d8c3a703315b221afa8598\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/b7ae660bc79ba26b75e245ea120e69a92b4cbd6443d8c3a703315b221afa8598\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 9256 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164.incomplete/synthetic_doc_qa_healthcare_industry_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 9256 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164.incomplete/synthetic_doc_qa_healthcare_industry_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 10881.86 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_healthcare_industry_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_healthcare_industry_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/100 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/cache-2d377b1b3c7cf701.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/cache-2d377b1b3c7cf701.arrow\n",
      "Done writing 100 examples in 10933 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/tmp22hp3h_m.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 10933 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/queries/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/tmp22hp3h_m.\n",
      "Finished processing shard number None of 1.\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3246.59 examples/s]\n",
      "Generating dataset synthetic_doc_qa_healthcare_industry_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_healthcare_industry_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164)\n",
      "Downloading and preparing dataset synthetic_doc_qa_healthcare_industry_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_healthcare_industry_test_beir/corpus to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164...\n",
      "hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/337b1ea21769b717c4c29314916e68e06e22a330d4f043c6c69c1e803eca894e.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/corpus/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/337b1ea21769b717c4c29314916e68e06e22a330d4f043c6c69c1e803eca894e.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                              | 0.00/309M [00:00<?, ?B/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   3%|█████                                                                                                                                                | 10.5M/309M [00:00<00:15, 19.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:   7%|██████████                                                                                                                                           | 21.0M/309M [00:00<00:09, 30.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  10%|███████████████▏                                                                                                                                     | 31.5M/309M [00:00<00:07, 37.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  14%|████████████████████▏                                                                                                                                | 41.9M/309M [00:01<00:06, 43.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  17%|█████████████████████████▎                                                                                                                           | 52.4M/309M [00:01<00:05, 46.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  20%|██████████████████████████████▎                                                                                                                      | 62.9M/309M [00:01<00:05, 49.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  24%|███████████████████████████████████▍                                                                                                                 | 73.4M/309M [00:01<00:04, 50.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  27%|████████████████████████████████████████▍                                                                                                            | 83.9M/309M [00:01<00:04, 51.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  31%|█████████████████████████████████████████████▌                                                                                                       | 94.4M/309M [00:02<00:04, 52.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  34%|██████████████████████████████████████████████████▉                                                                                                   | 105M/309M [00:02<00:03, 53.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  37%|███████████████████████████████████████████████████████▉                                                                                              | 115M/309M [00:02<00:03, 53.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  41%|█████████████████████████████████████████████████████████████                                                                                         | 126M/309M [00:02<00:03, 53.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  44%|██████████████████████████████████████████████████████████████████▏                                                                                   | 136M/309M [00:02<00:03, 54.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  48%|███████████████████████████████████████████████████████████████████████▎                                                                              | 147M/309M [00:03<00:02, 54.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  51%|████████████████████████████████████████████████████████████████████████████▎                                                                         | 157M/309M [00:03<00:02, 55.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  54%|█████████████████████████████████████████████████████████████████████████████████▍                                                                    | 168M/309M [00:03<00:02, 54.2MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  58%|██████████████████████████████████████████████████████████████████████████████████████▌                                                               | 178M/309M [00:03<00:02, 54.3MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  61%|███████████████████████████████████████████████████████████████████████████████████████████▌                                                          | 189M/309M [00:03<00:02, 54.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  64%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 199M/309M [00:04<00:02, 54.8MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 210M/309M [00:04<00:01, 54.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 220M/309M [00:04<00:01, 53.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                      | 231M/309M [00:04<00:01, 54.0MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 241M/309M [00:04<00:01, 53.9MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 252M/309M [00:04<00:01, 54.4MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 262M/309M [00:05<00:00, 54.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 273M/309M [00:05<00:00, 53.7MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 283M/309M [00:05<00:00, 53.5MB/s]\n",
      "\n",
      "\u001b[A\u001b[Aading data:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 294M/309M [00:05<00:00, 53.6MB/s]\n",
      "\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 309M/309M [00:06<00:00, 50.7MB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/337b1ea21769b717c4c29314916e68e06e22a330d4f043c6c69c1e803eca894e\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/corpus/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/337b1ea21769b717c4c29314916e68e06e22a330d4f043c6c69c1e803eca894e\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/337b1ea21769b717c4c29314916e68e06e22a330d4f043c6c69c1e803eca894e\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/337b1ea21769b717c4c29314916e68e06e22a330d4f043c6c69c1e803eca894e\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Ating test split:   0%|                                                                                                                                                     | 0/965 [00:00<?, ? examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  10%|██████████████▎                                                                                                                           | 100/965 [00:00<00:02, 375.90 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  21%|████████████████████████████▌                                                                                                             | 200/965 [00:00<00:01, 450.52 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  31%|██████████████████████████████████████████▉                                                                                               | 300/965 [00:00<00:01, 440.16 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  41%|█████████████████████████████████████████████████████████▏                                                                                | 400/965 [00:00<00:01, 462.19 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  52%|███████████████████████████████████████████████████████████████████████▌                                                                  | 500/965 [00:01<00:01, 438.01 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  62%|█████████████████████████████████████████████████████████████████████████████████████▊                                                    | 600/965 [00:01<00:00, 442.62 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  73%|████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 700/965 [00:01<00:00, 456.91 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 800/965 [00:01<00:00, 456.08 examples/s]\n",
      "\n",
      "\u001b[A\u001b[Ating test split:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 900/965 [00:01<00:00, 463.75 examples/s]\n",
      "\n",
      "\u001b[A\u001b[ADone writing 965 examples in 341548069 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164.incomplete/synthetic_doc_qa_healthcare_industry_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 965 examples in 341548069 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164.incomplete/synthetic_doc_qa_healthcare_industry_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 965/965 [00:02<00:00, 452.63 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_healthcare_industry_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_healthcare_industry_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ASet __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.                                        | 0/965 [00:00<?, ? examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Set __getitem__(key) output type to arrow for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/cache-f4060736265b563b.arrow\n",
      "INFO:datasets.arrow_dataset:Caching processed dataset at /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/cache-f4060736265b563b.arrow\n",
      "Done writing 965 examples in 341567128 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/tmp_xy_105x.\n",
      "DEBUG:datasets.arrow_writer:Done writing 965 examples in 341567128 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/corpus/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/tmp_xy_105x.\n",
      "\n",
      "\n",
      "\u001b[A\u001b[AFinished processing shard number None of 1.█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 965/965 [00:04<00:00, 240.81 examples/s]\n",
      "DEBUG:datasets.arrow_dataset:Finished processing shard number None of 1.\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 965/965 [00:04<00:00, 237.24 examples/s]\n",
      "Generating dataset synthetic_doc_qa_healthcare_industry_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164)\n",
      "INFO:datasets.builder:Generating dataset synthetic_doc_qa_healthcare_industry_test_beir (/home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164)\n",
      "Downloading and preparing dataset synthetic_doc_qa_healthcare_industry_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164...\n",
      "INFO:datasets.builder:Downloading and preparing dataset synthetic_doc_qa_healthcare_industry_test_beir/qrels to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164...\n",
      "hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/be572b54635e9409e18cfd647564187554dd79fbb75edb1b2e797a239a5befce.incomplete\n",
      "INFO:datasets.utils.file_utils:hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/qrels/test-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /home/aamita/.cache/huggingface/datasets/downloads/be572b54635e9409e18cfd647564187554dd79fbb75edb1b2e797a239a5befce.incomplete\n",
      "\n",
      "\n",
      "\u001b[A\u001b[Aading data:   0%|                                                                                                                                                             | 0.00/2.44k [00:00<?, ?B/s]\n",
      "\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.44k/2.44k [00:00<00:00, 14.8kB/s]\n",
      "storing hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/be572b54635e9409e18cfd647564187554dd79fbb75edb1b2e797a239a5befce\n",
      "INFO:datasets.utils.file_utils:storing hf://datasets/vidore/syntheticDocQA_healthcare_industry_test_beir@f9e25d5b6e13e1ad9f5c3cce202565031b3ab164/qrels/test-00000-of-00001.parquet in cache at /home/aamita/.cache/huggingface/datasets/downloads/be572b54635e9409e18cfd647564187554dd79fbb75edb1b2e797a239a5befce\n",
      "creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/be572b54635e9409e18cfd647564187554dd79fbb75edb1b2e797a239a5befce\n",
      "INFO:datasets.utils.file_utils:creating metadata file for /home/aamita/.cache/huggingface/datasets/downloads/be572b54635e9409e18cfd647564187554dd79fbb75edb1b2e797a239a5befce\n",
      "Downloading took 0.0 min\n",
      "INFO:datasets.download.download_manager:Downloading took 0.0 min\n",
      "Checksum Computation took 0.0 min\n",
      "INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n",
      "Generating test split\n",
      "INFO:datasets.builder:Generating test split\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ADone writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164.incomplete/synthetic_doc_qa_healthcare_industry_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "DEBUG:datasets.arrow_writer:Done writing 100 examples in 2439 bytes /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164.incomplete/synthetic_doc_qa_healthcare_industry_test_beir-test-00000-00000-of-NNNNN.arrow.\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 11893.34 examples/s]\n",
      "Renaming 1 shards.\n",
      "DEBUG:datasets.builder:Renaming 1 shards.\n",
      "All the splits matched successfully.\n",
      "INFO:datasets.utils.info_utils:All the splits matched successfully.\n",
      "Dataset synthetic_doc_qa_healthcare_industry_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164. Subsequent calls will reuse this data.\n",
      "INFO:datasets.builder:Dataset synthetic_doc_qa_healthcare_industry_test_beir downloaded and prepared to /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164. Subsequent calls will reuse this data.\n",
      "Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164\n",
      "DEBUG:datasets.builder:Constructing Dataset for split test, from /home/aamita/.cache/huggingface/datasets/vidore___synthetic_doc_qa_healthcare_industry_test_beir/qrels/0.0.0/f9e25d5b6e13e1ad9f5c3cce202565031b3ab164\n",
      "\n",
      "\n",
      "encode: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 40.72it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A:   0%|                                                                                                                                                                           | 0/483 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█                                                                                                                                                                  | 3/483 [00:11<31:42,  3.96s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   1%|█▋                                                                                                                                                                 | 5/483 [00:17<27:46,  3.49s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   2%|███▎                                                                                                                                                              | 10/483 [00:33<26:11,  3.32s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   3%|█████                                                                                                                                                             | 15/483 [00:49<25:31,  3.27s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   4%|██████▋                                                                                                                                                           | 20/483 [01:05<25:04,  3.25s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   5%|████████▍                                                                                                                                                         | 25/483 [01:21<24:39,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   6%|██████████                                                                                                                                                        | 30/483 [01:37<24:22,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   7%|███████████▋                                                                                                                                                      | 35/483 [01:53<24:07,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   8%|█████████████▍                                                                                                                                                    | 40/483 [02:09<23:44,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:   9%|███████████████                                                                                                                                                   | 45/483 [02:25<23:29,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  10%|████████████████▊                                                                                                                                                 | 50/483 [02:42<23:16,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  11%|██████████████████▍                                                                                                                                               | 55/483 [02:57<22:53,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  12%|████████████████████                                                                                                                                              | 60/483 [03:14<22:37,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  13%|█████████████████████▊                                                                                                                                            | 65/483 [03:30<22:21,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  14%|███████████████████████▍                                                                                                                                          | 70/483 [03:46<22:09,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  16%|█████████████████████████▏                                                                                                                                        | 75/483 [04:02<21:51,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  17%|██████████████████████████▊                                                                                                                                       | 80/483 [04:18<21:34,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  18%|████████████████████████████▌                                                                                                                                     | 85/483 [04:34<21:20,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  19%|██████████████████████████████▏                                                                                                                                   | 90/483 [04:50<21:03,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  20%|███████████████████████████████▊                                                                                                                                  | 95/483 [05:06<20:46,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  21%|█████████████████████████████████▎                                                                                                                               | 100/483 [05:22<20:32,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  22%|███████████████████████████████████                                                                                                                              | 105/483 [05:38<20:14,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  23%|████████████████████████████████████▋                                                                                                                            | 110/483 [05:54<19:56,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  24%|██████████████████████████████████████▎                                                                                                                          | 115/483 [06:10<19:44,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  25%|████████████████████████████████████████                                                                                                                         | 120/483 [06:26<19:27,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  26%|█████████████████████████████████████████▋                                                                                                                       | 125/483 [06:42<19:07,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  27%|███████████████████████████████████████████▎                                                                                                                     | 130/483 [06:59<18:54,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  28%|████████████████████████████████████████████▉                                                                                                                    | 135/483 [07:15<18:40,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  29%|██████████████████████████████████████████████▋                                                                                                                  | 140/483 [07:31<18:21,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  30%|████████████████████████████████████████████████▎                                                                                                                | 145/483 [07:47<18:07,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  31%|█████████████████████████████████████████████████▉                                                                                                               | 150/483 [08:03<17:52,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  32%|███████████████████████████████████████████████████▋                                                                                                             | 155/483 [08:19<17:34,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  33%|█████████████████████████████████████████████████████▎                                                                                                           | 160/483 [08:35<17:19,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  34%|███████████████████████████████████████████████████████                                                                                                          | 165/483 [08:51<17:05,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  35%|████████████████████████████████████████████████████████▋                                                                                                        | 170/483 [09:07<16:46,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  36%|██████████████████████████████████████████████████████████▎                                                                                                      | 175/483 [09:23<16:29,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  37%|████████████████████████████████████████████████████████████                                                                                                     | 180/483 [09:39<16:13,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  38%|█████████████████████████████████████████████████████████████▋                                                                                                   | 185/483 [09:55<15:57,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  39%|███████████████████████████████████████████████████████████████▎                                                                                                 | 190/483 [10:11<15:40,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  40%|█████████████████████████████████████████████████████████████████                                                                                                | 195/483 [10:28<15:26,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  41%|██████████████████████████████████████████████████████████████████▋                                                                                              | 200/483 [10:44<15:11,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  42%|████████████████████████████████████████████████████████████████████▎                                                                                            | 205/483 [11:00<14:52,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  43%|██████████████████████████████████████████████████████████████████████                                                                                           | 210/483 [11:16<14:37,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  45%|███████████████████████████████████████████████████████████████████████▋                                                                                         | 215/483 [11:32<14:21,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  46%|█████████████████████████████████████████████████████████████████████████▎                                                                                       | 220/483 [11:48<14:02,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  47%|███████████████████████████████████████████████████████████████████████████                                                                                      | 225/483 [12:04<13:46,  3.20s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  48%|████████████████████████████████████████████████████████████████████████████▋                                                                                    | 230/483 [12:20<13:33,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  49%|██████████████████████████████████████████████████████████████████████████████▎                                                                                  | 235/483 [12:36<13:17,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  50%|████████████████████████████████████████████████████████████████████████████████                                                                                 | 240/483 [12:52<13:00,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  51%|█████████████████████████████████████████████████████████████████████████████████▋                                                                               | 245/483 [13:08<12:48,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  52%|███████████████████████████████████████████████████████████████████████████████████▎                                                                             | 250/483 [13:24<12:29,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  53%|█████████████████████████████████████████████████████████████████████████████████████                                                                            | 255/483 [13:40<12:11,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  54%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 260/483 [13:57<11:57,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  55%|████████████████████████████████████████████████████████████████████████████████████████▎                                                                        | 265/483 [14:13<11:41,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  56%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 270/483 [14:29<11:22,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  57%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                     | 275/483 [14:45<11:10,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  58%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 280/483 [15:01<10:53,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  59%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 285/483 [15:17<10:35,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  60%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 290/483 [15:33<10:21,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  61%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                              | 295/483 [15:49<10:05,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 300/483 [16:05<09:48,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  63%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                           | 305/483 [16:21<09:31,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 310/483 [16:37<09:17,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                        | 315/483 [16:53<09:00,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 320/483 [17:09<08:43,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 325/483 [17:26<08:28,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 330/483 [17:42<08:11,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                 | 335/483 [17:58<07:55,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 340/483 [18:14<07:39,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 345/483 [18:30<07:23,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 350/483 [18:46<07:06,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 355/483 [19:02<06:52,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 360/483 [19:18<06:34,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 365/483 [19:34<06:19,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 370/483 [19:50<06:03,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 375/483 [20:06<05:46,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                  | 380/483 [20:22<05:30,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 385/483 [20:38<05:14,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 390/483 [20:54<04:59,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 395/483 [21:10<04:43,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 400/483 [21:26<04:26,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 405/483 [21:43<04:10,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                        | 410/483 [21:59<03:54,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 415/483 [22:15<03:39,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 420/483 [22:31<03:23,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 425/483 [22:47<03:06,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 430/483 [23:03<02:50,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 435/483 [23:19<02:35,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 440/483 [23:36<02:18,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 445/483 [23:52<02:02,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 450/483 [24:08<01:46,  3.24s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 455/483 [24:24<01:30,  3.23s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 460/483 [24:40<01:13,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 465/483 [24:56<00:57,  3.21s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 470/483 [25:12<00:41,  3.22s/it]\n",
      "\n",
      "\u001b[A\u001b[A:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎  | 475/483 [25:28<00:25,  3.21s/it]\n",
      "\n",
      "encode: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 483/483 [25:52<00:00,  3.21s/it]\n"
     ]
    }
   ],
   "source": [
    "for key, value in vidore_tasks.items():\n",
    "    print(f\"*****************Visual Documents Dataset : {key}\")\n",
    "    try:\n",
    "        tasks = mteb.get_tasks(tasks=[key])\n",
    "        evaluation = mteb.MTEB(tasks=tasks)\n",
    "        results = evaluation.run(\n",
    "            model,\n",
    "            output_folder=f\"results/{model}\",\n",
    "            batch_size=2,\n",
    "            save_corpus_embeddings=True,\n",
    "            save_predictions=True,\n",
    "            export_errors=True,\n",
    "            verbosity=3,\n",
    "        )\n",
    "\n",
    "    except:\n",
    "        print(f\"*****************Visual Documents : {key}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb34c8-c559-43f4-ab6d-9473d907c987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f108bd-8e77-4948-8e11-06644bd313e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74420d5-eef5-4bcc-b736-bbdc7f4d83c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312bcaf-11cd-4586-bf20-11a77fb610f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da6e7106-9f6b-4a12-b4da-01b3b0ade483",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(\n",
    "    tasks=[\n",
    "        \"BLINKIT2IRetrieval\"\n",
    "        # Compositionality\n",
    "        # \"ImageCoDeT2IMultiChoice\",\n",
    "        # \"AROCocoOrder\", \"AROFlickrOrder\",\n",
    "        # \"AROVisualAttribution\", \"AROVisualRelation\", \"SugarCrepe\", \"Winoground\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339189c2-fbed-4c45-92b9-a1e1c89844b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    # DocumentUnderstanding\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9551a447-2e5d-458d-bb02-5a2fd28607ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:The `batch_size` argument is deprecated and will be removed in the next release. Please use `encode_kwargs = {'batch_size': ...}` to set the batch size instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Any2AnyRetrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAny2AnyRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - BLINKIT2IRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">it2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - BLINKIT2IRetrieval, \u001b[3;38;5;241mit2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "results = evaluation.run(\n",
    "    model,\n",
    "    output_folder=f\"results/{model_name}\",\n",
    "    batch_size=8,\n",
    "    save_corpus_embeddings=True,\n",
    "    save_predictions=True,\n",
    "    export_errors=True,\n",
    "    verbosity=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a4ed294-17a6-4f9d-b258-b88259e58f6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': [{'ndcg_at_1': 0.31343,\n",
       "   'ndcg_at_3': 0.45445,\n",
       "   'ndcg_at_5': 0.47737,\n",
       "   'ndcg_at_10': 0.49656,\n",
       "   'ndcg_at_20': 0.51385,\n",
       "   'ndcg_at_100': 0.54366,\n",
       "   'ndcg_at_1000': 0.55789,\n",
       "   'map_at_1': 0.31343,\n",
       "   'map_at_3': 0.42206,\n",
       "   'map_at_5': 0.43499,\n",
       "   'map_at_10': 0.44285,\n",
       "   'map_at_20': 0.44743,\n",
       "   'map_at_100': 0.4513,\n",
       "   'map_at_1000': 0.45197,\n",
       "   'recall_at_1': 0.31343,\n",
       "   'recall_at_3': 0.54726,\n",
       "   'recall_at_5': 0.60199,\n",
       "   'recall_at_10': 0.66169,\n",
       "   'recall_at_20': 0.73134,\n",
       "   'recall_at_100': 0.89552,\n",
       "   'recall_at_1000': 1.0,\n",
       "   'cv_recall_at_1': 0.31592,\n",
       "   'cv_recall_at_3': 0.54726,\n",
       "   'cv_recall_at_5': 0.60199,\n",
       "   'cv_recall_at_10': 0.66169,\n",
       "   'cv_recall_at_20': 0.73134,\n",
       "   'cv_recall_at_100': 0.89552,\n",
       "   'cv_recall_at_1000': 1.0,\n",
       "   'precision_at_1': 0.31343,\n",
       "   'precision_at_3': 0.18242,\n",
       "   'precision_at_5': 0.1204,\n",
       "   'precision_at_10': 0.06617,\n",
       "   'precision_at_20': 0.03657,\n",
       "   'precision_at_100': 0.00896,\n",
       "   'precision_at_1000': 0.001,\n",
       "   'mrr_at_1': 0.31592,\n",
       "   'mrr_at_3': 0.4233,\n",
       "   'mrr_at_5': 0.436235,\n",
       "   'mrr_at_10': 0.444089,\n",
       "   'mrr_at_20': 0.448657,\n",
       "   'mrr_at_100': 0.452543,\n",
       "   'mrr_at_1000': 0.453215,\n",
       "   'nauc_ndcg_at_1_max': 0.064845,\n",
       "   'nauc_ndcg_at_1_std': -0.483083,\n",
       "   'nauc_ndcg_at_1_diff1': 0.411592,\n",
       "   'nauc_ndcg_at_3_max': 0.030269,\n",
       "   'nauc_ndcg_at_3_std': -0.686846,\n",
       "   'nauc_ndcg_at_3_diff1': 0.366698,\n",
       "   'nauc_ndcg_at_5_max': 0.009254,\n",
       "   'nauc_ndcg_at_5_std': -0.729754,\n",
       "   'nauc_ndcg_at_5_diff1': 0.361546,\n",
       "   'nauc_ndcg_at_10_max': 0.008247,\n",
       "   'nauc_ndcg_at_10_std': -0.733668,\n",
       "   'nauc_ndcg_at_10_diff1': 0.37145,\n",
       "   'nauc_ndcg_at_20_max': 0.006457,\n",
       "   'nauc_ndcg_at_20_std': -0.727186,\n",
       "   'nauc_ndcg_at_20_diff1': 0.359694,\n",
       "   'nauc_ndcg_at_100_max': 0.023478,\n",
       "   'nauc_ndcg_at_100_std': -0.695412,\n",
       "   'nauc_ndcg_at_100_diff1': 0.370955,\n",
       "   'nauc_ndcg_at_1000_max': 0.022765,\n",
       "   'nauc_ndcg_at_1000_std': -0.685229,\n",
       "   'nauc_ndcg_at_1000_diff1': 0.37133,\n",
       "   'nauc_map_at_1_max': 0.064845,\n",
       "   'nauc_map_at_1_std': -0.483083,\n",
       "   'nauc_map_at_1_diff1': 0.411592,\n",
       "   'nauc_map_at_3_max': 0.039924,\n",
       "   'nauc_map_at_3_std': -0.636391,\n",
       "   'nauc_map_at_3_diff1': 0.377112,\n",
       "   'nauc_map_at_5_max': 0.028734,\n",
       "   'nauc_map_at_5_std': -0.659815,\n",
       "   'nauc_map_at_5_diff1': 0.374235,\n",
       "   'nauc_map_at_10_max': 0.028445,\n",
       "   'nauc_map_at_10_std': -0.660174,\n",
       "   'nauc_map_at_10_diff1': 0.377689,\n",
       "   'nauc_map_at_20_max': 0.028205,\n",
       "   'nauc_map_at_20_std': -0.658097,\n",
       "   'nauc_map_at_20_diff1': 0.374695,\n",
       "   'nauc_map_at_100_max': 0.030478,\n",
       "   'nauc_map_at_100_std': -0.653768,\n",
       "   'nauc_map_at_100_diff1': 0.376488,\n",
       "   'nauc_map_at_1000_max': 0.030475,\n",
       "   'nauc_map_at_1000_std': -0.653249,\n",
       "   'nauc_map_at_1000_diff1': 0.376475,\n",
       "   'nauc_recall_at_1_max': 0.064845,\n",
       "   'nauc_recall_at_1_std': -0.483083,\n",
       "   'nauc_recall_at_1_diff1': 0.411592,\n",
       "   'nauc_recall_at_3_max': 0.001059,\n",
       "   'nauc_recall_at_3_std': -0.837111,\n",
       "   'nauc_recall_at_3_diff1': 0.335979,\n",
       "   'nauc_recall_at_5_max': -0.055519,\n",
       "   'nauc_recall_at_5_std': -0.953931,\n",
       "   'nauc_recall_at_5_diff1': 0.321701,\n",
       "   'nauc_recall_at_10_max': -0.065969,\n",
       "   'nauc_recall_at_10_std': -0.99612,\n",
       "   'nauc_recall_at_10_diff1': 0.356279,\n",
       "   'nauc_recall_at_20_max': -0.089765,\n",
       "   'nauc_recall_at_20_std': -1.008952,\n",
       "   'nauc_recall_at_20_diff1': 0.292443,\n",
       "   'nauc_recall_at_100_max': 0.03831,\n",
       "   'nauc_recall_at_100_std': -0.889353,\n",
       "   'nauc_recall_at_100_diff1': 0.358686,\n",
       "   'nauc_recall_at_1000_max': nan,\n",
       "   'nauc_recall_at_1000_std': nan,\n",
       "   'nauc_recall_at_1000_diff1': nan,\n",
       "   'nauc_precision_at_1_max': 0.064845,\n",
       "   'nauc_precision_at_1_std': -0.483083,\n",
       "   'nauc_precision_at_1_diff1': 0.411592,\n",
       "   'nauc_precision_at_3_max': 0.001059,\n",
       "   'nauc_precision_at_3_std': -0.837111,\n",
       "   'nauc_precision_at_3_diff1': 0.335979,\n",
       "   'nauc_precision_at_5_max': -0.055519,\n",
       "   'nauc_precision_at_5_std': -0.953931,\n",
       "   'nauc_precision_at_5_diff1': 0.321701,\n",
       "   'nauc_precision_at_10_max': -0.065969,\n",
       "   'nauc_precision_at_10_std': -0.99612,\n",
       "   'nauc_precision_at_10_diff1': 0.356279,\n",
       "   'nauc_precision_at_20_max': -0.089765,\n",
       "   'nauc_precision_at_20_std': -1.008952,\n",
       "   'nauc_precision_at_20_diff1': 0.292443,\n",
       "   'nauc_precision_at_100_max': 0.03831,\n",
       "   'nauc_precision_at_100_std': -0.889353,\n",
       "   'nauc_precision_at_100_diff1': 0.358686,\n",
       "   'nauc_precision_at_1000_max': nan,\n",
       "   'nauc_precision_at_1000_std': nan,\n",
       "   'nauc_precision_at_1000_diff1': nan,\n",
       "   'nauc_cv_recall_at_1_max': 0.063889,\n",
       "   'nauc_cv_recall_at_1_std': -0.47003,\n",
       "   'nauc_cv_recall_at_1_diff1': 0.403944,\n",
       "   'nauc_cv_recall_at_3_max': 0.001059,\n",
       "   'nauc_cv_recall_at_3_std': -0.837111,\n",
       "   'nauc_cv_recall_at_3_diff1': 0.335979,\n",
       "   'nauc_cv_recall_at_5_max': -0.055519,\n",
       "   'nauc_cv_recall_at_5_std': -0.953931,\n",
       "   'nauc_cv_recall_at_5_diff1': 0.321701,\n",
       "   'nauc_cv_recall_at_10_max': -0.065969,\n",
       "   'nauc_cv_recall_at_10_std': -0.99612,\n",
       "   'nauc_cv_recall_at_10_diff1': 0.356279,\n",
       "   'nauc_cv_recall_at_20_max': -0.089765,\n",
       "   'nauc_cv_recall_at_20_std': -1.008952,\n",
       "   'nauc_cv_recall_at_20_diff1': 0.292443,\n",
       "   'nauc_cv_recall_at_100_max': 0.03831,\n",
       "   'nauc_cv_recall_at_100_std': -0.889353,\n",
       "   'nauc_cv_recall_at_100_diff1': 0.358686,\n",
       "   'nauc_cv_recall_at_1000_max': nan,\n",
       "   'nauc_cv_recall_at_1000_std': nan,\n",
       "   'nauc_cv_recall_at_1000_diff1': nan,\n",
       "   'nauc_mrr_at_1_max': 0.063889,\n",
       "   'nauc_mrr_at_1_std': -0.47003,\n",
       "   'nauc_mrr_at_1_diff1': 0.403944,\n",
       "   'nauc_mrr_at_3_max': 0.039455,\n",
       "   'nauc_mrr_at_3_std': -0.629685,\n",
       "   'nauc_mrr_at_3_diff1': 0.37326,\n",
       "   'nauc_mrr_at_5_max': 0.028266,\n",
       "   'nauc_mrr_at_5_std': -0.653,\n",
       "   'nauc_mrr_at_5_diff1': 0.370331,\n",
       "   'nauc_mrr_at_10_max': 0.027971,\n",
       "   'nauc_mrr_at_10_std': -0.653271,\n",
       "   'nauc_mrr_at_10_diff1': 0.373732,\n",
       "   'nauc_mrr_at_20_max': 0.027655,\n",
       "   'nauc_mrr_at_20_std': -0.651144,\n",
       "   'nauc_mrr_at_20_diff1': 0.370727,\n",
       "   'nauc_mrr_at_100_max': 0.029884,\n",
       "   'nauc_mrr_at_100_std': -0.646755,\n",
       "   'nauc_mrr_at_100_diff1': 0.372455,\n",
       "   'nauc_mrr_at_1000_max': 0.02988,\n",
       "   'nauc_mrr_at_1000_std': -0.646223,\n",
       "   'nauc_mrr_at_1000_diff1': 0.372433,\n",
       "   'main_score': 0.49656,\n",
       "   'hf_subset': 'default',\n",
       "   'languages': ['eng-Latn']}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd90630-679f-413f-bff0-098c79ff260a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Any2AnyRetrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mAny2AnyRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - BLINKIT2IRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">it2i</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - BLINKIT2IRetrieval, \u001b[3;38;5;241mit2i\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "results = evaluation.run(model, output_folder=f\"results/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8834264c-2f1a-4530-9155-55d2fd180ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200744e7-ce03-4417-ac58-37441e00032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb.overview import TASKS_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1fb2d47-f187-4a47-923e-8b378403ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb.models.overview import MODEL_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b81a27-05d5-456f-8880-0f3092739974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb.models.overview import MODEL_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "859e5222-31a5-41d7-a39d-26b80caf1cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : kakaobrain/align-base | Value : name='kakaobrain/align-base' revision='e96a37facc7b1f59090ece82293226b817afd6ba' release_date='2023-02-24' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.align_models.ALIGNModelWrapper'>, model_name='kakaobrain/align-base') n_parameters=176000000 memory_usage_mb=671.0 max_tokens=64.0 embed_dim=768 license=None open_weights=True public_training_code='https://github.com/kakaobrain/coyo-align' public_training_data=True framework=['PyTorch'] reference='https://huggingface.co/kakaobrain/align-base' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Snowflake/snowflake-arctic-embed-xs | Value : name='Snowflake/snowflake-arctic-embed-xs' revision='742da4f66e1823b5b4dbe6c320a1375a1fd85f9e' release_date='2024-07-08' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Snowflake/snowflake-arctic-embed-xs', revision='742da4f66e1823b5b4dbe6c320a1375a1fd85f9e') n_parameters=22600000 memory_usage_mb=86.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Snowflake/snowflake-arctic-embed-xs' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'NQ-PL': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVER-NL': ['test'], 'FEVERHardNegatives': ['test']} adapted_from='sentence-transformers/all-MiniLM-L6-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Snowflake/snowflake-arctic-embed-s | Value : name='Snowflake/snowflake-arctic-embed-s' revision='d3c1d2d433dd0fdc8e9ca01331a5f225639e798f' release_date='2024-04-12' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Snowflake/snowflake-arctic-embed-s', revision='d3c1d2d433dd0fdc8e9ca01331a5f225639e798f') n_parameters=32200000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Snowflake/snowflake-arctic-embed-s' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'NQ-PL': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVER-NL': ['test'], 'FEVERHardNegatives': ['test']} adapted_from='intfloat/e5-small-unsupervised' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Snowflake/snowflake-arctic-embed-m | Value : name='Snowflake/snowflake-arctic-embed-m' revision='cc17beacbac32366782584c8752220405a0f3f40' release_date='2024-04-12' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Snowflake/snowflake-arctic-embed-m', revision='cc17beacbac32366782584c8752220405a0f3f40') n_parameters=109000000 memory_usage_mb=415.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Snowflake/snowflake-arctic-embed-m' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'NQ-PL': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVER-NL': ['test'], 'FEVERHardNegatives': ['test']} adapted_from='intfloat/e5-base-unsupervised' superseded_by='Snowflake/snowflake-arctic-embed-m-v1.5' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Snowflake/snowflake-arctic-embed-m-long | Value : name='Snowflake/snowflake-arctic-embed-m-long' revision='89d0f6ab196eead40b90cb6f9fefec01a908d2d1' release_date='2024-04-12' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Snowflake/snowflake-arctic-embed-m-long', revision='89d0f6ab196eead40b90cb6f9fefec01a908d2d1', trust_remote_code=True) n_parameters=137000000 memory_usage_mb=522.0 max_tokens=2048.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Snowflake/snowflake-arctic-embed-m-long' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'NQ-PL': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVER-NL': ['test'], 'FEVERHardNegatives': ['test']} adapted_from='nomic-ai/nomic-embed-text-v1-unsupervised' superseded_by='Snowflake/snowflake-arctic-embed-m-v2.0' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Snowflake/snowflake-arctic-embed-l | Value : name='Snowflake/snowflake-arctic-embed-l' revision='9a9e5834d2e89cdd8bb72b64111dde496e4fe78c' release_date='2024-04-12' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Snowflake/snowflake-arctic-embed-l', revision='9a9e5834d2e89cdd8bb72b64111dde496e4fe78c') n_parameters=335000000 memory_usage_mb=1274.0 max_tokens=512.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Snowflake/snowflake-arctic-embed-l' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'NQ-PL': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVER-NL': ['test'], 'FEVERHardNegatives': ['test']} adapted_from='intfloat/e5-base-unsupervised' superseded_by='Snowflake/snowflake-arctic-embed-l-v2.0' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Snowflake/snowflake-arctic-embed-m-v1.5 | Value : name='Snowflake/snowflake-arctic-embed-m-v1.5' revision='97eab2e17fcb7ccb8bb94d6e547898fa1a6a0f47' release_date='2024-07-08' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Snowflake/snowflake-arctic-embed-m-v1.5', revision='97eab2e17fcb7ccb8bb94d6e547898fa1a6a0f47', model_prompts={'query': 'Represent this sentence for searching relevant passages: '}) n_parameters=109000000 memory_usage_mb=415.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v1.5' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'NQ-PL': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVER-NL': ['test'], 'FEVERHardNegatives': ['test']} adapted_from=None superseded_by='Snowflake/snowflake-arctic-embed-m-v2.0' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Snowflake/snowflake-arctic-embed-m-v2.0 | Value : name='Snowflake/snowflake-arctic-embed-m-v2.0' revision='f2a7d59d80dfda5b1d14f096f3ce88bb6bf9ebdc' release_date='2024-12-04' languages=['afr_Latn', 'ara_Arab', 'aze_Latn', 'bel_Cyrl', 'bul_Cyrl', 'ben_Beng', 'cat_Latn', 'ceb_Latn', 'ces_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'ell_Grek', 'eng_Latn', 'spa_Latn', 'est_Latn', 'eus_Latn', 'fas_Arab', 'fin_Latn', 'fra_Latn', 'glg_Latn', 'guj_Gujr', 'heb_Hebr', 'hin_Deva', 'hrv_Latn', 'hat_Latn', 'hun_Latn', 'hye_Armn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jpn_Jpan', 'jav_Latn', 'kat_Geor', 'kaz_Cyrl', 'khm_Khmr', 'kan_Knda', 'kor_Hang', 'kir_Cyrl', 'lao_Laoo', 'lit_Latn', 'lav_Latn', 'mkd_Cyrl', 'mal_Mlym', 'mon_Cyrl', 'mar_Deva', 'msa_Latn', 'mya_Mymr', 'nep_Deva', 'nld_Latn', 'pan_Guru', 'pol_Latn', 'por_Latn', 'que_Latn', 'ron_Latn', 'rus_Cyrl', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sqi_Latn', 'srp_Cyrl', 'swe_Latn', 'swa_Latn', 'tam_Taml', 'tel_Telu', 'tha_Thai', 'tgl_Latn', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'vie_Latn', 'yor_Latn', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Snowflake/snowflake-arctic-embed-m-v2.0', revision='f2a7d59d80dfda5b1d14f096f3ce88bb6bf9ebdc', trust_remote_code=True) n_parameters=305000000 memory_usage_mb=1165.0 max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v2.0' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'NQ-PL': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVER-NL': ['test'], 'FEVERHardNegatives': ['test'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train']} adapted_from='Alibaba-NLP/gte-multilingual-base' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Snowflake/snowflake-arctic-embed-l-v2.0 | Value : name='Snowflake/snowflake-arctic-embed-l-v2.0' revision='edc2df7b6c25794b340229ca082e7c78782e6374' release_date='2024-12-04' languages=['afr_Latn', 'ara_Arab', 'aze_Latn', 'bel_Cyrl', 'bul_Cyrl', 'ben_Beng', 'cat_Latn', 'ceb_Latn', 'ces_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'ell_Grek', 'eng_Latn', 'spa_Latn', 'est_Latn', 'eus_Latn', 'fas_Arab', 'fin_Latn', 'fra_Latn', 'glg_Latn', 'guj_Gujr', 'heb_Hebr', 'hin_Deva', 'hrv_Latn', 'hat_Latn', 'hun_Latn', 'hye_Armn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jpn_Jpan', 'jav_Latn', 'kat_Geor', 'kaz_Cyrl', 'khm_Khmr', 'kan_Knda', 'kor_Hang', 'kir_Cyrl', 'lao_Laoo', 'lit_Latn', 'lav_Latn', 'mkd_Cyrl', 'mal_Mlym', 'mon_Cyrl', 'mar_Deva', 'msa_Latn', 'mya_Mymr', 'nep_Deva', 'nld_Latn', 'pan_Guru', 'pol_Latn', 'por_Latn', 'que_Latn', 'ron_Latn', 'rus_Cyrl', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sqi_Latn', 'srp_Cyrl', 'swe_Latn', 'swa_Latn', 'tam_Taml', 'tel_Telu', 'tha_Thai', 'tgl_Latn', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'vie_Latn', 'yor_Latn', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Snowflake/snowflake-arctic-embed-l-v2.0', revision='edc2df7b6c25794b340229ca082e7c78782e6374') n_parameters=568000000 memory_usage_mb=2166.0 max_tokens=8192.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Snowflake/snowflake-arctic-embed-l-v2.0' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'NQ-PL': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVER-NL': ['test'], 'FEVERHardNegatives': ['test'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train']} adapted_from='BAAI/bge-m3-retromae' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : bedrock/amazon-titan-embed-text-v1 | Value : name='bedrock/amazon-titan-embed-text-v1' revision='1' release_date='2023-09-27' languages=None loader=functools.partial(<class 'mteb.models.bedrock_models.BedrockWrapper'>, model_id='amazon.titan-embed-text-v1', provider='amazon', max_tokens=8192) n_parameters=None memory_usage_mb=None max_tokens=8192.0 embed_dim=1536 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://aws.amazon.com/about-aws/whats-new/2023/09/amazon-titan-embeddings-generally-available/' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : bedrock/amazon-titan-embed-text-v2 | Value : name='bedrock/amazon-titan-embed-text-v2' revision='1' release_date='2024-04-30' languages=None loader=functools.partial(<class 'mteb.models.bedrock_models.BedrockWrapper'>, model_id='amazon.titan-embed-text-v2:0', provider='amazon', max_tokens=8192) n_parameters=None memory_usage_mb=None max_tokens=8192.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://aws.amazon.com/about-aws/whats-new/2024/04/amazon-titan-text-embeddings-v2-amazon-bedrock/' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : bedrock/cohere-embed-english-v3 | Value : name='bedrock/cohere-embed-english-v3' revision='1' release_date='2023-11-02' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.bedrock_models.BedrockWrapper'>, model_id='cohere.embed-english-v3', provider='cohere', max_tokens=512, model_prompts={'Classification': 'classification', 'MultilabelClassification': 'classification', 'Clustering': 'clustering', 'query': 'search_query', 'passage': 'search_document'}) n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cohere.com/blog/introducing-embed-v3' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : bedrock/cohere-embed-multilingual-v3 | Value : name='bedrock/cohere-embed-multilingual-v3' revision='1' release_date='2023-11-02' languages=['afr-Latn', 'amh-Ethi', 'ara-Arab', 'asm-Beng', 'aze-Latn', 'bel-Cyrl', 'bul-Cyrl', 'ben-Beng', 'bod-Tibt', 'bos-Latn', 'cat-Latn', 'ceb-Latn', 'cos-Latn', 'ces-Latn', 'cym-Latn', 'dan-Latn', 'deu-Latn', 'ell-Grek', 'eng-Latn', 'epo-Latn', 'spa-Latn', 'est-Latn', 'eus-Latn', 'fas-Arab', 'fin-Latn', 'fra-Latn', 'fry-Latn', 'gle-Latn', 'gla-Latn', 'glg-Latn', 'guj-Gujr', 'hau-Latn', 'haw-Latn', 'heb-Hebr', 'hin-Deva', 'hmn-Latn', 'hrv-Latn', 'hat-Latn', 'hun-Latn', 'hye-Armn', 'ind-Latn', 'ibo-Latn', 'isl-Latn', 'ita-Latn', 'jpn-Jpan', 'jav-Latn', 'kat-Geor', 'kaz-Cyrl', 'khm-Khmr', 'kan-Knda', 'kor-Kore', 'kur-Arab', 'kir-Cyrl', 'lat-Latn', 'ltz-Latn', 'lao-Laoo', 'lit-Latn', 'lav-Latn', 'mlg-Latn', 'mri-Latn', 'mkd-Cyrl', 'mal-Mlym', 'mon-Cyrl', 'mar-Deva', 'msa-Latn', 'mlt-Latn', 'mya-Mymr', 'nep-Deva', 'nld-Latn', 'nor-Latn', 'nya-Latn', 'ori-Orya', 'pan-Guru', 'pol-Latn', 'por-Latn', 'ron-Latn', 'rus-Cyrl', 'kin-Latn', 'sin-Sinh', 'slk-Latn', 'slv-Latn', 'smo-Latn', 'sna-Latn', 'som-Latn', 'sqi-Latn', 'srp-Cyrl', 'sot-Latn', 'sun-Latn', 'swe-Latn', 'swa-Latn', 'tam-Taml', 'tel-Telu', 'tgk-Cyrl', 'tha-Thai', 'tuk-Latn', 'tgl-Latn', 'tur-Latn', 'tat-Cyrl', 'uig-Arab', 'ukr-Cyrl', 'urd-Arab', 'uzb-Latn', 'vie-Latn', 'wol-Latn', 'xho-Latn', 'yid-Hebr', 'yor-Latn', 'zho-Hans', 'zul-Latn'] loader=functools.partial(<class 'mteb.models.bedrock_models.BedrockWrapper'>, model_id='cohere.embed-multilingual-v3', provider='cohere', max_tokens=512, model_prompts={'Classification': 'classification', 'MultilabelClassification': 'classification', 'Clustering': 'clustering', 'query': 'search_query', 'passage': 'search_document'}) n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cohere.com/blog/introducing-embed-v3' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-small-en-v1.5 | Value : name='BAAI/bge-small-en-v1.5' revision='5c38ec7c405ec4b44b94cc5a9bb96e735b38267a' release_date='2023-09-12' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-small-en-v1.5', revision='5c38ec7c405ec4b44b94cc5a9bb96e735b38267a', model_prompts={'query': 'Represent this sentence for searching relevant passages: '}) n_parameters=33400000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=512 license='mit' open_weights=True public_training_code=None public_training_data='https://data.baai.ac.cn/details/BAAI-MTP' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-small-en-v1.5' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-base-en-v1.5 | Value : name='BAAI/bge-base-en-v1.5' revision='a5beb1e3e68b9ab74eb54cfd186867f64f240e1a' release_date='2023-09-11' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-base-en-v1.5', revision='a5beb1e3e68b9ab74eb54cfd186867f64f240e1a', model_prompts={'query': 'Represent this sentence for searching relevant passages: '}) n_parameters=109000000 memory_usage_mb=390.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data='https://data.baai.ac.cn/details/BAAI-MTP' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-base-en-v1.5' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-large-en-v1.5 | Value : name='BAAI/bge-large-en-v1.5' revision='d4aa6901d3a41ba39fb536a557fa166f842b0e09' release_date='2023-09-12' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-large-en-v1.5', revision='d4aa6901d3a41ba39fb536a557fa166f842b0e09', model_prompts={'query': 'Represent this sentence for searching relevant passages: '}) n_parameters=335000000 memory_usage_mb=1242.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data='https://data.baai.ac.cn/details/BAAI-MTP' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-large-en-v1.5' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-small-zh | Value : name='BAAI/bge-small-zh' revision='1d2363c5de6ce9ba9c890c8e23a4c72dce540ca8' release_date='2023-08-05' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-small-zh', revision='1d2363c5de6ce9ba9c890c8e23a4c72dce540ca8', model_prompts={'query': '为这个句子生成表示以用于检索相关文章：'}) n_parameters=33400000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=512 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-small-zh' similarity_fn_name='cosine' use_instructions=True training_datasets={'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CMedQAv2-reranking': ['train'], 'Cmnli': ['train'], 'Ocnli': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'NQ': ['test'], 'NQHardNegatives': ['test'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'QuoraRetrieval': ['train'], 'QuoraRetrievalHardNegatives': ['train'], 'Quora-PLHardNegatives': ['train'], 'QuoraRetrieval-Fa': ['train'], 'Quora-PL': ['train']} adapted_from=None superseded_by='BAAI/bge-small-zh-v1.5' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-base-zh | Value : name='BAAI/bge-base-zh' revision='0e5f83d4895db7955e4cb9ed37ab73f7ded339b6' release_date='2023-08-05' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-base-zh', revision='0e5f83d4895db7955e4cb9ed37ab73f7ded339b6', model_prompts={'query': '为这个句子生成表示以用于检索相关文章：'}) n_parameters=109000000 memory_usage_mb=390.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-base-zh' similarity_fn_name='cosine' use_instructions=True training_datasets={'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CMedQAv2-reranking': ['train'], 'Cmnli': ['train'], 'Ocnli': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'NQ': ['test'], 'NQHardNegatives': ['test'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'QuoraRetrieval': ['train'], 'QuoraRetrievalHardNegatives': ['train'], 'Quora-PLHardNegatives': ['train'], 'QuoraRetrieval-Fa': ['train'], 'Quora-PL': ['train']} adapted_from=None superseded_by='BAAI/bge-base-zh-v1.5' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-large-zh | Value : name='BAAI/bge-large-zh' revision='b5d9f5c027e87b6f0b6fa4b614f8f9cdc45ce0e8' release_date='2023-08-02' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-large-zh', revision='b5d9f5c027e87b6f0b6fa4b614f8f9cdc45ce0e8', model_prompts={'query': '为这个句子生成表示以用于检索相关文章：'}) n_parameters=335000000 memory_usage_mb=1242.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-large-zh' similarity_fn_name='cosine' use_instructions=True training_datasets={'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CMedQAv2-reranking': ['train'], 'Cmnli': ['train'], 'Ocnli': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'NQ': ['test'], 'NQHardNegatives': ['test'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'QuoraRetrieval': ['train'], 'QuoraRetrievalHardNegatives': ['train'], 'Quora-PLHardNegatives': ['train'], 'QuoraRetrieval-Fa': ['train'], 'Quora-PL': ['train']} adapted_from=None superseded_by='BAAI/bge-large-zh-v1.5' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-small-en | Value : name='BAAI/bge-small-en' revision='4778d71a06863076696b03fd2777eb118712cad8' release_date='2023-08-05' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-small-en', revision='4778d71a06863076696b03fd2777eb118712cad8', model_prompts={'query': 'Represent this sentence for searching relevant passages: '}) n_parameters=33400000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=512 license='mit' open_weights=True public_training_code=None public_training_data='https://data.baai.ac.cn/details/BAAI-MTP' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-small-en' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from=None superseded_by='BAAI/bge-small-en-v1.5' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-base-en | Value : name='BAAI/bge-base-en' revision='b737bf5dcc6ee8bdc530531266b4804a5d77b5d8' release_date='2023-08-05' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-base-en', revision='b737bf5dcc6ee8bdc530531266b4804a5d77b5d8', model_prompts={'query': 'Represent this sentence for searching relevant passages: '}) n_parameters=109000000 memory_usage_mb=390.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data='https://data.baai.ac.cn/details/BAAI-MTP' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-base-en' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from=None superseded_by='BAAI/bge-base-en-v1.5' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-large-en | Value : name='BAAI/bge-large-en' revision='abe7d9d814b775ca171121fb03f394dc42974275' release_date='2023-08-05' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-large-en', revision='abe7d9d814b775ca171121fb03f394dc42974275', model_prompts={'query': 'Represent this sentence for searching relevant passages: '}) n_parameters=335000000 memory_usage_mb=1242.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data='https://data.baai.ac.cn/details/BAAI-MTP' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-large-en' similarity_fn_name='cosine' use_instructions=True training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from=None superseded_by='BAAI/bge-large-en-v1.5' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-small-zh-v1.5 | Value : name='BAAI/bge-small-zh-v1.5' revision='7999e1d3359715c523056ef9478215996d62a620' release_date='2023-09-12' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-small-zh-v1.5', revision='7999e1d3359715c523056ef9478215996d62a620', model_prompts={'query': '为这个句子生成表示以用于检索相关文章：'}) n_parameters=33400000 memory_usage_mb=91.0 max_tokens=512.0 embed_dim=512 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-small-zh-v1.5' similarity_fn_name='cosine' use_instructions=True training_datasets={'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CMedQAv2-reranking': ['train'], 'Cmnli': ['train'], 'Ocnli': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'NQ': ['test'], 'NQHardNegatives': ['test'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'QuoraRetrieval': ['train'], 'QuoraRetrievalHardNegatives': ['train'], 'Quora-PLHardNegatives': ['train'], 'QuoraRetrieval-Fa': ['train'], 'Quora-PL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-base-zh-v1.5 | Value : name='BAAI/bge-base-zh-v1.5' revision='f03589ceff5aac7111bd60cfc7d497ca17ecac65' release_date='2023-09-11' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-base-zh-v1.5', revision='f03589ceff5aac7111bd60cfc7d497ca17ecac65', model_prompts={'query': '为这个句子生成表示以用于检索相关文章：'}) n_parameters=109000000 memory_usage_mb=416.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-base-zh-v1.5' similarity_fn_name='cosine' use_instructions=True training_datasets={'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CMedQAv2-reranking': ['train'], 'Cmnli': ['train'], 'Ocnli': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'NQ': ['test'], 'NQHardNegatives': ['test'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'QuoraRetrieval': ['train'], 'QuoraRetrievalHardNegatives': ['train'], 'Quora-PLHardNegatives': ['train'], 'QuoraRetrieval-Fa': ['train'], 'Quora-PL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-large-zh-v1.5 | Value : name='BAAI/bge-large-zh-v1.5' revision='79e7739b6ab944e86d6171e44d24c997fc1e0116' release_date='2023-09-12' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-large-zh-v1.5', revision='79e7739b6ab944e86d6171e44d24c997fc1e0116', model_prompts={'query': '为这个句子生成表示以用于检索相关文章：'}) n_parameters=335000000 memory_usage_mb=1278.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-large-zh-v1.5' similarity_fn_name='cosine' use_instructions=True training_datasets={'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CMedQAv2-reranking': ['train'], 'Cmnli': ['train'], 'Ocnli': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'NQ': ['test'], 'NQHardNegatives': ['test'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'QuoraRetrieval': ['train'], 'QuoraRetrievalHardNegatives': ['train'], 'Quora-PLHardNegatives': ['train'], 'QuoraRetrieval-Fa': ['train'], 'Quora-PL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-m3 | Value : name='BAAI/bge-m3' revision='5617a9f61b028005a4858fdac845db406aefb181' release_date='2024-06-28' languages=['afr_Latn', 'amh_Ethi', 'azj_Latn', 'ast_Latn', 'azj_Latn', 'ben_Beng', 'bul_Cyrl', 'bel_Cyrl', 'cat_Latn', 'ceb_Latn', 'ckb_Arab', 'dan_Latn', 'deu_Latn', 'ell_Grek', 'eng_Latn', 'est_Latn', 'fin_Latn', 'fra_Latn', 'glg_Latn', 'guj_Gujr', 'heb_Hebr', 'hin_Deva', 'ita_Latn', 'jpn_Jpan', 'kor_Hang', 'rus_Cyrl', 'tha_Thai', 'ukr_Cyrl', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-m3', revision='5617a9f61b028005a4858fdac845db406aefb181') n_parameters=568000000 memory_usage_mb=2167.0 max_tokens=8194.0 embed_dim=4096 license='mit' open_weights=True public_training_code=None public_training_data='https://huggingface.co/datasets/cfli/bge-full-data' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-m3' similarity_fn_name='cosine' use_instructions=False training_datasets={'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'LeCaRDv2': ['train'], 'CMedQAv1-reranking': ['train'], 'CMedQAv2-reranking': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CodeSearchNet': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-multilingual-gemma2 | Value : name='BAAI/bge-multilingual-gemma2' revision='992e13d8984fde2c31ef8a3cb2c038aeec513b8a' release_date='2024-07-25' languages=['eng_Latn', 'zho_Hans', 'kor_Hang', 'kor_Latn', 'fra_Latn', 'jpn_Jpan', 'jpn_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-multilingual-gemma2', revision='992e13d8984fde2c31ef8a3cb2c038aeec513b8a') n_parameters=9240000000 memory_usage_mb=35254.0 max_tokens=8192.0 embed_dim=3584 license='gemma' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-multilingual-gemma2' similarity_fn_name='cosine' use_instructions=False training_datasets={'HotpotQA': ['train'], 'HotpotQA-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'MSMARCO': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'ArguAna': ['train'], 'ArguAna-NL': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'SciDocsReranking': ['train'], 'StackOverflowDupQuestions': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ImdbClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'ArxivClusteringS2S': ['train'], 'ArxivClusteringP2P': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringP2P': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'STS22': ['train'], 'STS22.v2': ['train'], 'STSBenchmark': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'LeCaRDv2': ['train'], 'CMedQAv1-reranking': ['train'], 'CMedQAv2-reranking': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CodeSearchNet': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-en-icl | Value : name='BAAI/bge-en-icl' revision='971c7e1445cc86656ca0bd85ed770b8675a40bb5' release_date='2024-07-25' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='BAAI/bge-en-icl', revision='971c7e1445cc86656ca0bd85ed770b8675a40bb5') n_parameters=7110000000 memory_usage_mb=27125.0 max_tokens=32768.0 embed_dim=4096 license='apache-2' open_weights=True public_training_code='https://github.com/FlagOpen/FlagEmbedding' public_training_data='https://huggingface.co/datasets/cfli/bge-full-data' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/BAAI/bge-en-icl' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'ArguAna': ['train'], 'ArguAna-NL': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'SciDocsReranking': ['train'], 'StackOverflowDupQuestions': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ImdbClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'ArxivClusteringS2S': ['train'], 'ArxivClusteringP2P': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringP2P': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'STS22': ['train'], 'STS22.v2': ['train'], 'STSBenchmark': ['train']} adapted_from='intfloat/e5-mistral-7b-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : manu/bge-m3-custom-fr | Value : name='manu/bge-m3-custom-fr' revision='ed3ef88678ba83ddf4c0fab71a93cb90d89a9078' release_date='2024-04-11' languages=None loader=None n_parameters=567754752 memory_usage_mb=2166.0 max_tokens=8194.0 embed_dim=1024 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/manu/bge-m3-custom-fr' similarity_fn_name='cosine' use_instructions=None training_datasets={'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'LeCaRDv2': ['train'], 'CMedQAv1-reranking': ['train'], 'CMedQAv2-reranking': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CodeSearchNet': ['train']} adapted_from='BAAI/bge-m3' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Salesforce/blip2-opt-2.7b | Value : name='Salesforce/blip2-opt-2.7b' revision='51572668da0eb669e01a189dc22abe6088589a24' release_date='2024-03-22' languages=['eng_Latn'] loader=functools.partial(<function blip2_loader at 0x7f5a678525c0>, model_name='Salesforce/blip2-opt-2.7b') n_parameters=3740000000 memory_usage_mb=14285.0 max_tokens=None embed_dim=768 license='mit' open_weights=True public_training_code='https://github.com/salesforce/LAVIS/tree/main/projects/blip2' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip2-opt-2.7b' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip2-opt-6.7b-coco | Value : name='Salesforce/blip2-opt-6.7b-coco' revision='0d580de59320a25a4d2c386387bcef310d5f286e' release_date='2024-03-31' languages=['eng_Latn'] loader=functools.partial(<function blip2_loader at 0x7f5a678525c0>, model_name='Salesforce/blip2-opt-6.7b-coco') n_parameters=7750000000 memory_usage_mb=29577.0 max_tokens=None embed_dim=768 license='mit' open_weights=True public_training_code='https://github.com/salesforce/LAVIS/tree/main/projects/blip2' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip2-opt-6.7b-coco' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip-image-captioning-large | Value : name='Salesforce/blip-image-captioning-large' revision='2227ac38c9f16105cb0412e7cab4759978a8fd90' release_date='2023-12-07' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.blip_models.BLIPModelWrapper'>, model_name='Salesforce/blip-image-captioning-large') n_parameters=470000000 memory_usage_mb=1792.0 max_tokens=512.0 embed_dim=768 license='bsd-3-clause' open_weights=True public_training_code='https://github.com/salesforce/BLIP' public_training_data='https://github.com/salesforce/BLIP' framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip-image-captioning-large' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip-image-captioning-base | Value : name='Salesforce/blip-image-captioning-base' revision='89b09ea1789f7addf2f6d6f0dfc4ce10ab58ef84' release_date='2023-08-01' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.blip_models.BLIPModelWrapper'>, model_name='Salesforce/blip-image-captioning-base') n_parameters=247000000 memory_usage_mb=942.0 max_tokens=512.0 embed_dim=768 license='bsd-3-clause' open_weights=True public_training_code='https://github.com/salesforce/BLIP' public_training_data='https://github.com/salesforce/BLIP' framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip-image-captioning-base' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip-vqa-base | Value : name='Salesforce/blip-vqa-base' revision='c7df8e7cd7aa2ee9af18f56e2b29e59a92651b64' release_date='2023-12-07' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.blip_models.BLIPModelWrapper'>, model_name='Salesforce/blip-vqa-base') n_parameters=247000000 memory_usage_mb=1467.0 max_tokens=512.0 embed_dim=768 license='bsd-3-clause' open_weights=True public_training_code='https://github.com/salesforce/BLIP' public_training_data='https://github.com/salesforce/BLIP' framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip-vqa-base' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip-vqa-capfilt-large | Value : name='Salesforce/blip-vqa-capfilt-large' revision='e53f95265aeab69013fabb5380500ab984adbbb4' release_date='2023-01-22' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.blip_models.BLIPModelWrapper'>, model_name='Salesforce/blip-vqa-capfilt-large') n_parameters=247000000 memory_usage_mb=942.0 max_tokens=512.0 embed_dim=768 license='bsd-3-clause' open_weights=True public_training_code='https://github.com/salesforce/BLIP' public_training_data='https://github.com/salesforce/BLIP' framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip-vqa-capfilt-large' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip-itm-base-coco | Value : name='Salesforce/blip-itm-base-coco' revision='7eaa90c11850c0b17fc38c6a11e7d88bd6ac231f' release_date='2023-08-01' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.blip_models.BLIPModelWrapper'>, model_name='Salesforce/blip-itm-base-coco') n_parameters=247000000 memory_usage_mb=942.0 max_tokens=512.0 embed_dim=768 license='bsd-3-clause' open_weights=True public_training_code='https://github.com/salesforce/BLIP' public_training_data='https://github.com/salesforce/BLIP' framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip-itm-base-coco' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip-itm-large-coco | Value : name='Salesforce/blip-itm-large-coco' revision='fef05cafc05298067cbbca00b125749394a77a6f' release_date='2023-08-01' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.blip_models.BLIPModelWrapper'>, model_name='Salesforce/blip-itm-large-coco') n_parameters=470000000 memory_usage_mb=1793.0 max_tokens=512.0 embed_dim=768 license='bsd-3-clause' open_weights=True public_training_code='https://github.com/salesforce/BLIP' public_training_data='https://github.com/salesforce/BLIP' framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip-itm-large-coco' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip-itm-base-flickr | Value : name='Salesforce/blip-itm-base-flickr' revision='1de29e660d91ae1786c1876212ea805a22eab251' release_date='2023-08-01' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.blip_models.BLIPModelWrapper'>, model_name='Salesforce/blip-itm-base-flickr') n_parameters=247000000 memory_usage_mb=942.0 max_tokens=512.0 embed_dim=768 license='bsd-3-clause' open_weights=True public_training_code='https://github.com/salesforce/BLIP' public_training_data='https://github.com/salesforce/BLIP' framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip-itm-base-flickr' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Salesforce/blip-itm-large-flickr | Value : name='Salesforce/blip-itm-large-flickr' revision='bda12e6506758f54261b5ab174b2c55a3ba143fb' release_date='2023-08-01' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.blip_models.BLIPModelWrapper'>, model_name='Salesforce/blip-itm-large-flickr') n_parameters=470000000 memory_usage_mb=1793.0 max_tokens=512.0 embed_dim=768 license='bsd-3-clause' open_weights=True public_training_code='https://github.com/salesforce/BLIP' public_training_data='https://github.com/salesforce/BLIP' framework=['PyTorch'] reference='https://huggingface.co/Salesforce/blip-itm-large-flickr' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : bm25s | Value : name='bm25s' revision='0_1_10' release_date='2024-07-10' languages=['eng_Latn'] loader=functools.partial(<function bm25_loader at 0x7f5a67853a60>, model_name='bm25s') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code='https://github.com/xhluca/bm25s' public_training_data=None framework=[] reference='https://github.com/xhluca/bm25s' similarity_fn_name=None use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : openai/clip-vit-large-patch14 | Value : name='openai/clip-vit-large-patch14' revision='32bd64288804d66eefd0ccbe215aa642df71cc41' release_date='2021-02-26' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.clip_models.CLIPModelWrapper'>, model_name='openai/clip-vit-large-patch14') n_parameters=428000000 memory_usage_mb=1631.0 max_tokens=77.0 embed_dim=768 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/openai/clip-vit-large-patch14' similarity_fn_name=None use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : openai/clip-vit-base-patch32 | Value : name='openai/clip-vit-base-patch32' revision='3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268' release_date='2021-02-26' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.clip_models.CLIPModelWrapper'>, model_name='openai/clip-vit-base-patch32') n_parameters=151000000 memory_usage_mb=576.0 max_tokens=77.0 embed_dim=512 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/openai/clip-vit-base-patch32' similarity_fn_name=None use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : openai/clip-vit-base-patch16 | Value : name='openai/clip-vit-base-patch16' revision='57c216476eefef5ab752ec549e440a49ae4ae5f3' release_date='2021-02-26' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.clip_models.CLIPModelWrapper'>, model_name='openai/clip-vit-base-patch16') n_parameters=151000000 memory_usage_mb=576.0 max_tokens=77.0 embed_dim=512 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/openai/clip-vit-base-patch16' similarity_fn_name=None use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : codesage/codesage-large-v2 | Value : name='codesage/codesage-large-v2' revision='6e5d6dc15db3e310c37c6dbac072409f95ffa5c5' release_date='2024-02-03' languages=['python-Code', 'javascript-Code', 'go-Code', 'ruby-Code', 'java-Code', 'php-Code'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='codesage/codesage-large-v2', revision='6e5d6dc15db3e310c37c6dbac072409f95ffa5c5') n_parameters=1300000000 memory_usage_mb=4959.0 max_tokens=2048.0 embed_dim=2048 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/codesage/codesage-large-v2' similarity_fn_name='cosine' use_instructions=False training_datasets={'CodeSearchNetRetrieval': ['train'], 'CodeSearchNetCCRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : codesage/codesage-base-v2 | Value : name='codesage/codesage-base-v2' revision='92eac4f44c8674638f039f1b0d8280f2539cb4c7' release_date='2024-02-03' languages=['python-Code', 'javascript-Code', 'go-Code', 'ruby-Code', 'java-Code', 'php-Code'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='codesage/codesage-base-v2', revision='92eac4f44c8674638f039f1b0d8280f2539cb4c7') n_parameters=356000000 memory_usage_mb=1358.0 max_tokens=2048.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/codesage/codesage-base-v2' similarity_fn_name='cosine' use_instructions=False training_datasets={'CodeSearchNetRetrieval': ['train'], 'CodeSearchNetCCRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : codesage/codesage-small-v2 | Value : name='codesage/codesage-small-v2' revision='4844c2f24b25e181aa43ca058cc73dd2622565c1' release_date='2024-02-03' languages=['python-Code', 'javascript-Code', 'go-Code', 'ruby-Code', 'java-Code', 'php-Code'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='codesage/codesage-small-v2', revision='4844c2f24b25e181aa43ca058cc73dd2622565c1') n_parameters=130000000 memory_usage_mb=496.0 max_tokens=2048.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/codesage/codesage-small-v2' similarity_fn_name='cosine' use_instructions=False training_datasets={'CodeSearchNetRetrieval': ['train'], 'CodeSearchNetCCRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jxm/cde-small-v1 | Value : name='jxm/cde-small-v1' revision='8d5736163718a8b65cd787b75ed61020d18bad3c' release_date='2024-09-24' languages=['eng_Latn'] loader=<function no_model_implementation_available at 0x7f5a64dc3380> n_parameters=281000000 memory_usage_mb=1072.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code='https://github.com/jxmorris12/cde' public_training_data='https://huggingface.co/datasets/cfli/bge-full-data' framework=['Sentence Transformers'] reference='https://huggingface.co/jxm/cde-small-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'HotpotQA': ['train'], 'HotpotQA-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'MSMARCO': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'ArguAna': ['train'], 'ArguAna-NL': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'SciDocsReranking': ['train'], 'StackOverflowDupQuestions': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ImdbClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'ArxivClusteringS2S': ['train'], 'ArxivClusteringP2P': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringP2P': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'STS22': ['train'], 'STS22.v2': ['train'], 'STSBenchmark': ['train']} adapted_from='nomic-ai/nomic-bert-2048' superseded_by='jxm/cde-small-v2' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jxm/cde-small-v2 | Value : name='jxm/cde-small-v2' revision='a7e5882ad52c27ea2831fc8258f24379c25cb459' release_date='2025-01-13' languages=['eng_Latn'] loader=<function no_model_implementation_available at 0x7f5a64dc3380> n_parameters=306000000 memory_usage_mb=1166.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code='https://github.com/jxmorris12/cde' public_training_data='https://huggingface.co/datasets/cfli/bge-full-data' framework=['Sentence Transformers'] reference='https://huggingface.co/jxm/cde-small-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'HotpotQA': ['train'], 'HotpotQA-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'MSMARCO': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'ArguAna': ['train'], 'ArguAna-NL': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'SciDocsReranking': ['train'], 'StackOverflowDupQuestions': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ImdbClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'ArxivClusteringS2S': ['train'], 'ArxivClusteringP2P': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringP2P': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'STS22': ['train'], 'STS22.v2': ['train'], 'STSBenchmark': ['train']} adapted_from='answerdotai/ModernBERT-base' superseded_by='jxm/cde-small-v2' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Cohere/Cohere-embed-multilingual-v3.0 | Value : name='Cohere/Cohere-embed-multilingual-v3.0' revision='1' release_date='2023-11-02' languages=['afr-Latn', 'amh-Ethi', 'ara-Arab', 'asm-Beng', 'aze-Latn', 'bel-Cyrl', 'bul-Cyrl', 'ben-Beng', 'bod-Tibt', 'bos-Latn', 'cat-Latn', 'ceb-Latn', 'cos-Latn', 'ces-Latn', 'cym-Latn', 'dan-Latn', 'deu-Latn', 'ell-Grek', 'eng-Latn', 'epo-Latn', 'spa-Latn', 'est-Latn', 'eus-Latn', 'fas-Arab', 'fin-Latn', 'fra-Latn', 'fry-Latn', 'gle-Latn', 'gla-Latn', 'glg-Latn', 'guj-Gujr', 'hau-Latn', 'haw-Latn', 'heb-Hebr', 'hin-Deva', 'hmn-Latn', 'hrv-Latn', 'hat-Latn', 'hun-Latn', 'hye-Armn', 'ind-Latn', 'ibo-Latn', 'isl-Latn', 'ita-Latn', 'jpn-Jpan', 'jav-Latn', 'kat-Geor', 'kaz-Cyrl', 'khm-Khmr', 'kan-Knda', 'kor-Kore', 'kur-Arab', 'kir-Cyrl', 'lat-Latn', 'ltz-Latn', 'lao-Laoo', 'lit-Latn', 'lav-Latn', 'mlg-Latn', 'mri-Latn', 'mkd-Cyrl', 'mal-Mlym', 'mon-Cyrl', 'mar-Deva', 'msa-Latn', 'mlt-Latn', 'mya-Mymr', 'nep-Deva', 'nld-Latn', 'nor-Latn', 'nya-Latn', 'ori-Orya', 'pan-Guru', 'pol-Latn', 'por-Latn', 'ron-Latn', 'rus-Cyrl', 'kin-Latn', 'sin-Sinh', 'slk-Latn', 'slv-Latn', 'smo-Latn', 'sna-Latn', 'som-Latn', 'sqi-Latn', 'srp-Cyrl', 'sot-Latn', 'sun-Latn', 'swe-Latn', 'swa-Latn', 'tam-Taml', 'tel-Telu', 'tgk-Cyrl', 'tha-Thai', 'tuk-Latn', 'tgl-Latn', 'tur-Latn', 'tat-Cyrl', 'uig-Arab', 'ukr-Cyrl', 'urd-Arab', 'uzb-Latn', 'vie-Latn', 'wol-Latn', 'xho-Latn', 'yid-Hebr', 'yor-Latn', 'zho-Hans', 'zul-Latn'] loader=functools.partial(<class 'mteb.models.cohere_models.CohereTextEmbeddingModel'>, model_name='embed-multilingual-v3.0', model_prompts={'Classification': 'classification', 'MultilabelClassification': 'classification', 'Clustering': 'clustering', 'query': 'search_query', 'passage': 'search_document'}) n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=512 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cohere.com/blog/introducing-embed-v3' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Cohere/Cohere-embed-english-v3.0 | Value : name='Cohere/Cohere-embed-english-v3.0' revision='1' release_date='2023-11-02' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.cohere_models.CohereTextEmbeddingModel'>, model_name='embed-english-v3.0', model_prompts={'Classification': 'classification', 'MultilabelClassification': 'classification', 'Clustering': 'clustering', 'query': 'search_query', 'passage': 'search_document'}) n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cohere.com/blog/introducing-embed-v3' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Cohere/Cohere-embed-multilingual-light-v3.0 | Value : name='Cohere/Cohere-embed-multilingual-light-v3.0' revision='1' release_date='2023-11-02' languages=['afr-Latn', 'amh-Ethi', 'ara-Arab', 'asm-Beng', 'aze-Latn', 'bel-Cyrl', 'bul-Cyrl', 'ben-Beng', 'bod-Tibt', 'bos-Latn', 'cat-Latn', 'ceb-Latn', 'cos-Latn', 'ces-Latn', 'cym-Latn', 'dan-Latn', 'deu-Latn', 'ell-Grek', 'eng-Latn', 'epo-Latn', 'spa-Latn', 'est-Latn', 'eus-Latn', 'fas-Arab', 'fin-Latn', 'fra-Latn', 'fry-Latn', 'gle-Latn', 'gla-Latn', 'glg-Latn', 'guj-Gujr', 'hau-Latn', 'haw-Latn', 'heb-Hebr', 'hin-Deva', 'hmn-Latn', 'hrv-Latn', 'hat-Latn', 'hun-Latn', 'hye-Armn', 'ind-Latn', 'ibo-Latn', 'isl-Latn', 'ita-Latn', 'jpn-Jpan', 'jav-Latn', 'kat-Geor', 'kaz-Cyrl', 'khm-Khmr', 'kan-Knda', 'kor-Kore', 'kur-Arab', 'kir-Cyrl', 'lat-Latn', 'ltz-Latn', 'lao-Laoo', 'lit-Latn', 'lav-Latn', 'mlg-Latn', 'mri-Latn', 'mkd-Cyrl', 'mal-Mlym', 'mon-Cyrl', 'mar-Deva', 'msa-Latn', 'mlt-Latn', 'mya-Mymr', 'nep-Deva', 'nld-Latn', 'nor-Latn', 'nya-Latn', 'ori-Orya', 'pan-Guru', 'pol-Latn', 'por-Latn', 'ron-Latn', 'rus-Cyrl', 'kin-Latn', 'sin-Sinh', 'slk-Latn', 'slv-Latn', 'smo-Latn', 'sna-Latn', 'som-Latn', 'sqi-Latn', 'srp-Cyrl', 'sot-Latn', 'sun-Latn', 'swe-Latn', 'swa-Latn', 'tam-Taml', 'tel-Telu', 'tgk-Cyrl', 'tha-Thai', 'tuk-Latn', 'tgl-Latn', 'tur-Latn', 'tat-Cyrl', 'uig-Arab', 'ukr-Cyrl', 'urd-Arab', 'uzb-Latn', 'vie-Latn', 'wol-Latn', 'xho-Latn', 'yid-Hebr', 'yor-Latn', 'zho-Hans', 'zul-Latn'] loader=functools.partial(<class 'mteb.models.cohere_models.CohereTextEmbeddingModel'>, model_name='embed-multilingual-light-v3.0', model_prompts={'Classification': 'classification', 'MultilabelClassification': 'classification', 'Clustering': 'clustering', 'query': 'search_query', 'passage': 'search_document'}) n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=384 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cohere.com/blog/introducing-embed-v3' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Cohere/Cohere-embed-english-light-v3.0 | Value : name='Cohere/Cohere-embed-english-light-v3.0' revision='1' release_date='2023-11-02' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.cohere_models.CohereTextEmbeddingModel'>, model_name='embed-english-light-v3.0', model_prompts={'Classification': 'classification', 'MultilabelClassification': 'classification', 'Clustering': 'clustering', 'query': 'search_query', 'passage': 'search_document'}) n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=384 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cohere.com/blog/introducing-embed-v3' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : embed-multilingual-v3.0-v | Value : name='embed-multilingual-v3.0-v' revision='1' release_date='2024-10-24' languages=[] loader=functools.partial(<function cohere_v_loader at 0x7f5a64dc3b00>, model_name='embed-multilingual-v3.0') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=[] reference='https://huggingface.co/Cohere/Cohere-embed-multilingual-v3.0' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : embed-english-v3.0-v | Value : name='embed-english-v3.0-v' revision='1' release_date='2024-10-24' languages=['eng-Latn'] loader=functools.partial(<function cohere_v_loader at 0x7f5a64dc3b00>, model_name='embed-english-v3.0') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=[] reference='https://huggingface.co/Cohere/Cohere-embed-english-v3.0' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : colbert-ir/colbertv2.0 | Value : name='colbert-ir/colbertv2.0' revision='c1e84128e85ef755c096a95bdb06b47793b13acf' release_date='2024-09-21' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.colbert_models.ColBERTWrapper'>, model_name='colbert-ir/colbertv2.0') n_parameters=110000000 memory_usage_mb=418.0 max_tokens=180.0 embed_dim=None license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyLate', 'ColBERT'] reference='https://huggingface.co/colbert-ir/colbertv2.0' similarity_fn_name='max_sim' use_instructions=False training_datasets={'MSMARCO': ['train'], 'mMARCO-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jinaai/jina-colbert-v2 | Value : name='jinaai/jina-colbert-v2' revision='4cf816e5e2b03167b132a3c847a9ecd48ba708e1' release_date='2024-08-16' languages=['ara-Arab', 'ben-Beng', 'deu-Latn', 'spa-Latn', 'eng-Latn', 'fas-Arab', 'fin-Latn', 'fra-Latn', 'hin-Deva', 'ind-Latn', 'jpn-Jpan', 'kor-Kore', 'rus-Cyrl', 'swa-Latn', 'tel-Telu', 'tha-Thai', 'yor-Latn', 'zho-Hans', 'nld-Latn', 'ita-Latn', 'por-Latn', 'vie-Latn'] loader=functools.partial(<class 'mteb.models.colbert_models.ColBERTWrapper'>, model_name='jinaai/jina-colbert-v2', query_prefix='[QueryMarker]', document_prefix='[DocumentMarker]', attend_to_expansion_tokens=True, trust_remote_code=True) n_parameters=559000000 memory_usage_mb=1067.0 max_tokens=8192.0 embed_dim=None license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['PyLate', 'ColBERT'] reference='https://huggingface.co/jinaai/jina-colbert-v2' similarity_fn_name='max_sim' use_instructions=False training_datasets={'MSMARCO': ['train'], 'mMARCO-NL': ['train'], 'DuRetrieval': [], 'MIRACL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : facebook/dinov2-small | Value : name='facebook/dinov2-small' revision='ed25f3a31f01632728cabb09d1542f84ab7b0056' release_date='2023-07-18' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.dino_models.DINOModelWrapper'>, model_name='facebook/dinov2-small') n_parameters=22100000 memory_usage_mb=84.0 max_tokens=None embed_dim=384 license='apache-2.0' open_weights=True public_training_code='https://github.com/facebookresearch/dinov2' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/facebook/dinov2-small' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image']\n",
      "\n",
      "Model Name : facebook/dinov2-base | Value : name='facebook/dinov2-base' revision='f9e44c814b77203eaa57a6bdbbd535f21ede1415' release_date='2023-07-18' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.dino_models.DINOModelWrapper'>, model_name='facebook/dinov2-base') n_parameters=86600000 memory_usage_mb=330.0 max_tokens=None embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/facebookresearch/dinov2' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/facebook/dinov2-base' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image']\n",
      "\n",
      "Model Name : facebook/dinov2-large | Value : name='facebook/dinov2-large' revision='47b73eefe95e8d44ec3623f8890bd894b6ea2d6c' release_date='2023-07-18' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.dino_models.DINOModelWrapper'>, model_name='facebook/dinov2-large') n_parameters=304000000 memory_usage_mb=1161.0 max_tokens=None embed_dim=1024 license='apache-2.0' open_weights=True public_training_code='https://github.com/facebookresearch/dinov2' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/facebook/dinov2-large' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image']\n",
      "\n",
      "Model Name : facebook/dinov2-giant | Value : name='facebook/dinov2-giant' revision='611a9d42f2335e0f921f1e313ad3c1b7178d206d' release_date='2023-07-18' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.dino_models.DINOModelWrapper'>, model_name='facebook/dinov2-giant') n_parameters=1140000000 memory_usage_mb=4335.0 max_tokens=None embed_dim=1536 license='apache-2.0' open_weights=True public_training_code='https://github.com/facebookresearch/dinov2' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/facebook/dinov2-giant' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image']\n",
      "\n",
      "Model Name : intfloat/multilingual-e5-large-instruct | Value : name='intfloat/multilingual-e5-large-instruct' revision='baa7be480a7de1539afce709c8f13f833a510e0a' release_date='2024-02-08' languages=['afr_Latn', 'amh_Latn', 'ara_Latn', 'asm_Latn', 'aze_Latn', 'bel_Latn', 'bul_Latn', 'ben_Latn', 'ben_Beng', 'bre_Latn', 'bos_Latn', 'cat_Latn', 'ces_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'ell_Latn', 'eng_Latn', 'epo_Latn', 'spa_Latn', 'est_Latn', 'eus_Latn', 'fas_Latn', 'fin_Latn', 'fra_Latn', 'fry_Latn', 'gle_Latn', 'gla_Latn', 'glg_Latn', 'guj_Latn', 'hau_Latn', 'heb_Latn', 'hin_Latn', 'hin_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jpn_Latn', 'jav_Latn', 'kat_Latn', 'kaz_Latn', 'khm_Latn', 'kan_Latn', 'kor_Latn', 'kur_Latn', 'kir_Latn', 'lat_Latn', 'lao_Latn', 'lit_Latn', 'lav_Latn', 'mlg_Latn', 'mkd_Latn', 'mal_Latn', 'mon_Latn', 'mar_Latn', 'msa_Latn', 'mya_Latn', 'nep_Latn', 'nld_Latn', 'nob_Latn', 'orm_Latn', 'ori_Latn', 'pan_Latn', 'pol_Latn', 'pus_Latn', 'por_Latn', 'ron_Latn', 'rus_Latn', 'san_Latn', 'snd_Latn', 'sin_Latn', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sqi_Latn', 'srp_Latn', 'sun_Latn', 'swe_Latn', 'swa_Latn', 'tam_Latn', 'tam_Taml', 'tel_Latn', 'tel_Telu', 'tha_Latn', 'tgl_Latn', 'tur_Latn', 'uig_Latn', 'ukr_Latn', 'urd_Latn', 'urd_Arab', 'uzb_Latn', 'vie_Latn', 'xho_Latn', 'yid_Latn', 'zho_Hant', 'zho_Hans'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='intfloat/multilingual-e5-large-instruct', instruction_template='Instruct: {instruction}\\nQuery: ', attn='cccc', pooling_method='mean', mode='embedding', torch_dtype=torch.float16, normalized=True) n_parameters=560000000 memory_usage_mb=1068.0 max_tokens=514.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['GritLM', 'PyTorch'] reference='https://huggingface.co/intfloat/multilingual-e5-large-instruct' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='FacebookAI/xlm-roberta-large' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/e5-mistral-7b-instruct | Value : name='intfloat/e5-mistral-7b-instruct' revision='07163b72af1488142a360786df853f237b1a3ca1' release_date='2024-02-08' languages=['eng_Latn', 'fra_Latn', 'deu_Latn', 'ita_Latn', 'spa_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='intfloat/e5-mistral-7b-instruct', instruction_template='Instruct: {instruction}\\nQuery: ', attn='cccc', pooling_method='lasttoken', mode='embedding', torch_dtype=torch.float16, normalized=True) n_parameters=7111000000 memory_usage_mb=13563.0 max_tokens=32768.0 embed_dim=4096 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['GritLM', 'PyTorch'] reference='https://huggingface.co/intfloat/e5-mistral-7b-instruct' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='mistralai/Mistral-7B-v0.1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : zeta-alpha-ai/Zeta-Alpha-E5-Mistral | Value : name='zeta-alpha-ai/Zeta-Alpha-E5-Mistral' revision='c791d37474fa6a5c72eb3a2522be346bc21fbfc3' release_date='2024-08-30' languages=['eng_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='zeta-alpha-ai/Zeta-Alpha-E5-Mistral', instruction_template='Instruct: {instruction}\\nQuery: ', attn='cccc', pooling_method='lasttoken', mode='embedding', torch_dtype=torch.bfloat16, normalized=True) n_parameters=7110660096 memory_usage_mb=13563.0 max_tokens=32768.0 embed_dim=4096 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/zeta-alpha-ai/Zeta-Alpha-E5-Mistral' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['test'], 'NQHardNegatives': ['test'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['test'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'AmazonCounterfactualClassification': ['train'], 'AmazonReviewsClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'ImdbClassification': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'STSBenchmark': ['train']} adapted_from='intfloat/e5-mistral-7b-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/multilingual-e5-small | Value : name='intfloat/multilingual-e5-small' revision='fd1525a9fd15316a2d503bf26ab031a61d056e98' release_date='2024-02-08' languages=['afr_Latn', 'amh_Latn', 'ara_Latn', 'asm_Latn', 'aze_Latn', 'bel_Latn', 'bul_Latn', 'ben_Latn', 'ben_Beng', 'bre_Latn', 'bos_Latn', 'cat_Latn', 'ces_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'ell_Latn', 'eng_Latn', 'epo_Latn', 'spa_Latn', 'est_Latn', 'eus_Latn', 'fas_Latn', 'fin_Latn', 'fra_Latn', 'fry_Latn', 'gle_Latn', 'gla_Latn', 'glg_Latn', 'guj_Latn', 'hau_Latn', 'heb_Latn', 'hin_Latn', 'hin_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jpn_Latn', 'jav_Latn', 'kat_Latn', 'kaz_Latn', 'khm_Latn', 'kan_Latn', 'kor_Latn', 'kur_Latn', 'kir_Latn', 'lat_Latn', 'lao_Latn', 'lit_Latn', 'lav_Latn', 'mlg_Latn', 'mkd_Latn', 'mal_Latn', 'mon_Latn', 'mar_Latn', 'msa_Latn', 'mya_Latn', 'nep_Latn', 'nld_Latn', 'nob_Latn', 'orm_Latn', 'ori_Latn', 'pan_Latn', 'pol_Latn', 'pus_Latn', 'por_Latn', 'ron_Latn', 'rus_Latn', 'san_Latn', 'snd_Latn', 'sin_Latn', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sqi_Latn', 'srp_Latn', 'sun_Latn', 'swe_Latn', 'swa_Latn', 'tam_Latn', 'tam_Taml', 'tel_Latn', 'tel_Telu', 'tha_Latn', 'tgl_Latn', 'tur_Latn', 'uig_Latn', 'ukr_Latn', 'urd_Latn', 'urd_Arab', 'uzb_Latn', 'vie_Latn', 'xho_Latn', 'yid_Latn', 'zho_Hant', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/multilingual-e5-small', revision='fd1525a9fd15316a2d503bf26ab031a61d056e98', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=118000000 memory_usage_mb=449.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/multilingual-e5-small' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='microsoft/Multilingual-MiniLM-L12-H384' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/multilingual-e5-base | Value : name='intfloat/multilingual-e5-base' revision='d13f1b27baf31030b7fd040960d60d909913633f' release_date='2024-02-08' languages=['afr_Latn', 'amh_Latn', 'ara_Latn', 'asm_Latn', 'aze_Latn', 'bel_Latn', 'bul_Latn', 'ben_Latn', 'ben_Beng', 'bre_Latn', 'bos_Latn', 'cat_Latn', 'ces_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'ell_Latn', 'eng_Latn', 'epo_Latn', 'spa_Latn', 'est_Latn', 'eus_Latn', 'fas_Latn', 'fin_Latn', 'fra_Latn', 'fry_Latn', 'gle_Latn', 'gla_Latn', 'glg_Latn', 'guj_Latn', 'hau_Latn', 'heb_Latn', 'hin_Latn', 'hin_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jpn_Latn', 'jav_Latn', 'kat_Latn', 'kaz_Latn', 'khm_Latn', 'kan_Latn', 'kor_Latn', 'kur_Latn', 'kir_Latn', 'lat_Latn', 'lao_Latn', 'lit_Latn', 'lav_Latn', 'mlg_Latn', 'mkd_Latn', 'mal_Latn', 'mon_Latn', 'mar_Latn', 'msa_Latn', 'mya_Latn', 'nep_Latn', 'nld_Latn', 'nob_Latn', 'orm_Latn', 'ori_Latn', 'pan_Latn', 'pol_Latn', 'pus_Latn', 'por_Latn', 'ron_Latn', 'rus_Latn', 'san_Latn', 'snd_Latn', 'sin_Latn', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sqi_Latn', 'srp_Latn', 'sun_Latn', 'swe_Latn', 'swa_Latn', 'tam_Latn', 'tam_Taml', 'tel_Latn', 'tel_Telu', 'tha_Latn', 'tgl_Latn', 'tur_Latn', 'uig_Latn', 'ukr_Latn', 'urd_Latn', 'urd_Arab', 'uzb_Latn', 'vie_Latn', 'xho_Latn', 'yid_Latn', 'zho_Hant', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/multilingual-e5-base', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=278000000 memory_usage_mb=1061.0 max_tokens=514.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/multilingual-e5-base' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='FacebookAI/xlm-roberta-base' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/multilingual-e5-large | Value : name='intfloat/multilingual-e5-large' revision='ab10c1a7f42e74530fe7ae5be82e6d4f11a719eb' release_date='2024-02-08' languages=['afr_Latn', 'amh_Latn', 'ara_Latn', 'asm_Latn', 'aze_Latn', 'bel_Latn', 'bul_Latn', 'ben_Latn', 'ben_Beng', 'bre_Latn', 'bos_Latn', 'cat_Latn', 'ces_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'ell_Latn', 'eng_Latn', 'epo_Latn', 'spa_Latn', 'est_Latn', 'eus_Latn', 'fas_Latn', 'fin_Latn', 'fra_Latn', 'fry_Latn', 'gle_Latn', 'gla_Latn', 'glg_Latn', 'guj_Latn', 'hau_Latn', 'heb_Latn', 'hin_Latn', 'hin_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jpn_Latn', 'jav_Latn', 'kat_Latn', 'kaz_Latn', 'khm_Latn', 'kan_Latn', 'kor_Latn', 'kur_Latn', 'kir_Latn', 'lat_Latn', 'lao_Latn', 'lit_Latn', 'lav_Latn', 'mlg_Latn', 'mkd_Latn', 'mal_Latn', 'mon_Latn', 'mar_Latn', 'msa_Latn', 'mya_Latn', 'nep_Latn', 'nld_Latn', 'nob_Latn', 'orm_Latn', 'ori_Latn', 'pan_Latn', 'pol_Latn', 'pus_Latn', 'por_Latn', 'ron_Latn', 'rus_Latn', 'san_Latn', 'snd_Latn', 'sin_Latn', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sqi_Latn', 'srp_Latn', 'sun_Latn', 'swe_Latn', 'swa_Latn', 'tam_Latn', 'tam_Taml', 'tel_Latn', 'tel_Telu', 'tha_Latn', 'tgl_Latn', 'tur_Latn', 'uig_Latn', 'ukr_Latn', 'urd_Latn', 'urd_Arab', 'uzb_Latn', 'vie_Latn', 'xho_Latn', 'yid_Latn', 'zho_Hant', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/multilingual-e5-large', revision='ab10c1a7f42e74530fe7ae5be82e6d4f11a719eb', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=560000000 memory_usage_mb=2136.0 max_tokens=514.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/multilingual-e5-large' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='FacebookAI/xlm-roberta-large' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/e5-small-v2 | Value : name='intfloat/e5-small-v2' revision='dca8b1a9dae0d4575df2bf423a5edb485a431236' release_date='2024-02-08' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/e5-small-v2', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=33000000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/e5-small-v2' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='intfloat/e5-small' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/e5-small | Value : name='intfloat/e5-small' revision='e272f3049e853b47cb5ca3952268c6662abda68f' release_date='2024-02-08' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/e5-small', revision='e272f3049e853b47cb5ca3952268c6662abda68f', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=33000000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/e5-small' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='sentence-transformers/all-MiniLM-L6-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/e5-base-v2 | Value : name='intfloat/e5-base-v2' revision='1c644c92ad3ba1efdad3f1451a637716616a20e8' release_date='2024-02-08' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/e5-base-v2', revision='1c644c92ad3ba1efdad3f1451a637716616a20e8', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=109000000 memory_usage_mb=418.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/e5-base-v2' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='intfloat/e5-base' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/e5-large-v2 | Value : name='intfloat/e5-large-v2' revision='b322e09026e4ea05f42beadf4d661fb4e101d311' release_date='2024-02-08' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/e5-large-v2', revision='b322e09026e4ea05f42beadf4d661fb4e101d311', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=335000000 memory_usage_mb=1278.0 max_tokens=514.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/e5-large-v2' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='intfloat/e5-large' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/e5-large | Value : name='intfloat/e5-large' revision='4dc6d853a804b9c8886ede6dda8a073b7dc08a81' release_date='2022-12-26' languages=['eng-Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/e5-large', revision='4dc6d853a804b9c8886ede6dda8a073b7dc08a81', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=335000000 memory_usage_mb=1278.0 max_tokens=512.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/e5-large' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='google-bert/bert-large-uncased-whole-word-masking' superseded_by='intfloat/e5-large-v2' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : intfloat/e5-base | Value : name='intfloat/e5-base' revision='b533fe4636f4a2507c08ddab40644d20b0006d6a' release_date='2022-12-26' languages=['eng-Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='intfloat/e5-base', revision='b533fe4636f4a2507c08ddab40644d20b0006d6a', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=109000000 memory_usage_mb=418.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/intfloat/e5-base' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='google-bert/bert-base-uncased' superseded_by='intfloat/e5-base-v2' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : royokong/e5-v | Value : name='royokong/e5-v' revision='0c1f22679417b3ae925d779442221c40cd1861ab' release_date='2024-07-17' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.e5_v.E5VWrapper'>, model_name='royokong/e5-v', torch_dtype=torch.float16, device_map='auto') n_parameters=8360000000 memory_usage_mb=15936.0 max_tokens=8192.0 embed_dim=4096 license=None open_weights=True public_training_code='https://github.com/kongds/E5-V' public_training_data='https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse' framework=['PyTorch'] reference='https://huggingface.co/royokong/e5-v' similarity_fn_name=None use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : QuanSun/EVA02-CLIP-B-16 | Value : name='QuanSun/EVA02-CLIP-B-16' revision='11afd202f2ae80869d6cef18b1ec775e79bd8d12' release_date='2023-04-26' languages=['eng_Latn'] loader=functools.partial(<function evaclip_loader at 0x7f5a64dee840>, model_name='EVA02-CLIP-B-16') n_parameters=149000000 memory_usage_mb=568.0 max_tokens=77.0 embed_dim=512 license='mit' open_weights=True public_training_code='https://github.com/baaivision/EVA/tree/master/EVA-CLIP' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/QuanSun/EVA-CLIP' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : QuanSun/EVA02-CLIP-L-14 | Value : name='QuanSun/EVA02-CLIP-L-14' revision='11afd202f2ae80869d6cef18b1ec775e79bd8d12' release_date='2023-04-26' languages=['eng_Latn'] loader=functools.partial(<function evaclip_loader at 0x7f5a64dee840>, model_name='EVA02-CLIP-L-14') n_parameters=428000000 memory_usage_mb=1633.0 max_tokens=77.0 embed_dim=768 license='mit' open_weights=True public_training_code='https://github.com/baaivision/EVA/tree/master/EVA-CLIP' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/QuanSun/EVA-CLIP' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : QuanSun/EVA02-CLIP-bigE-14 | Value : name='QuanSun/EVA02-CLIP-bigE-14' revision='11afd202f2ae80869d6cef18b1ec775e79bd8d12' release_date='2023-04-26' languages=['eng_Latn'] loader=functools.partial(<function evaclip_loader at 0x7f5a64dee840>, model_name='EVA02-CLIP-bigE-14') n_parameters=4700000000 memory_usage_mb=17929.0 max_tokens=77.0 embed_dim=1024 license='mit' open_weights=True public_training_code='https://github.com/baaivision/EVA/tree/master/EVA-CLIP' public_training_data='https://laion.ai/blog/laion-5b/' framework=['PyTorch'] reference='https://huggingface.co/QuanSun/EVA-CLIP' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : QuanSun/EVA02-CLIP-bigE-14-plus | Value : name='QuanSun/EVA02-CLIP-bigE-14-plus' revision='11afd202f2ae80869d6cef18b1ec775e79bd8d12' release_date='2023-04-26' languages=['eng_Latn'] loader=functools.partial(<function evaclip_loader at 0x7f5a64dee840>, model_name='EVA02-CLIP-bigE-14-plus') n_parameters=5000000000 memory_usage_mb=19073.0 max_tokens=77.0 embed_dim=1024 license='mit' open_weights=True public_training_code='https://github.com/baaivision/EVA/tree/master/EVA-CLIP' public_training_data='https://laion.ai/blog/laion-5b/' framework=['PyTorch'] reference='https://huggingface.co/QuanSun/EVA-CLIP' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/text-embedding-004 | Value : name='google/text-embedding-004' revision='1' release_date='2024-05-14' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.google_models.GoogleTextEmbeddingModel'>, model_name='text-embedding-004', model_prompts={'Classification': 'CLASSIFICATION', 'MultilabelClassification': 'CLASSIFICATION', 'Clustering': 'CLUSTERING', 'STS': 'SIMILARITY', 'query': 'RETRIEVAL_QUERY', 'passage': 'RETRIEVAL_DOCUMENT'}) n_parameters=None memory_usage_mb=None max_tokens=2048.0 embed_dim=768 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : google/text-embedding-005 | Value : name='google/text-embedding-005' revision='1' release_date='2024-11-18' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.google_models.GoogleTextEmbeddingModel'>, model_name='text-embedding-005', model_prompts={'Classification': 'CLASSIFICATION', 'MultilabelClassification': 'CLASSIFICATION', 'Clustering': 'CLUSTERING', 'STS': 'SIMILARITY', 'query': 'RETRIEVAL_QUERY', 'passage': 'RETRIEVAL_DOCUMENT'}) n_parameters=None memory_usage_mb=None max_tokens=2048.0 embed_dim=768 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : google/text-multilingual-embedding-002 | Value : name='google/text-multilingual-embedding-002' revision='1' release_date='2024-05-14' languages=['arb_Arab', 'ben_Beng', 'eng_Latn', 'spa_Latn', 'deu_Latn', 'pes_Arab', 'fin_Latn', 'fra_Latn', 'hin_Deva', 'ind_Latn', 'jpn_Jpan', 'kor_Hang', 'rus_Cyrl', 'swh_Latn', 'tel_Telu', 'tha_Thai', 'yor_Latn', 'zho_Hant', 'zho_Hans'] loader=functools.partial(<class 'mteb.models.google_models.GoogleTextEmbeddingModel'>, model_name='text-multilingual-embedding-002', model_prompts={'Classification': 'CLASSIFICATION', 'MultilabelClassification': 'CLASSIFICATION', 'Clustering': 'CLUSTERING', 'STS': 'SIMILARITY', 'query': 'RETRIEVAL_QUERY', 'passage': 'RETRIEVAL_DOCUMENT'}) n_parameters=None memory_usage_mb=None max_tokens=2048.0 embed_dim=768 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : GritLM/GritLM-7B | Value : name='GritLM/GritLM-7B' revision='13f00a0e36500c80ce12870ea513846a066004af' release_date='2024-02-15' languages=['eng_Latn', 'fra_Latn', 'deu_Latn', 'ita_Latn', 'spa_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='GritLM/GritLM-7B', instruction_template=<function gritlm_instruction at 0x7f5a64deef20>, mode='embedding', torch_dtype='auto') n_parameters=7240000000 memory_usage_mb=13813.0 max_tokens=4096.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code='https://github.com/ContextualAI/gritlm' public_training_data=None framework=['GritLM', 'PyTorch'] reference='https://huggingface.co/GritLM/GritLM-7B' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : GritLM/GritLM-8x7B | Value : name='GritLM/GritLM-8x7B' revision='7f089b13e3345510281733ca1e6ff871b5b4bc76' release_date='2024-02-15' languages=['eng_Latn', 'fra_Latn', 'deu_Latn', 'ita_Latn', 'spa_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='GritLM/GritLM-8x7B', instruction_template=<function gritlm_instruction at 0x7f5a64deef20>, mode='embedding', torch_dtype='auto') n_parameters=57920000000 memory_usage_mb=89079.0 max_tokens=4096.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code='https://github.com/ContextualAI/gritlm' public_training_data=None framework=['GritLM', 'PyTorch'] reference='https://huggingface.co/GritLM/GritLM-8x7B' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Alibaba-NLP/gte-Qwen2-7B-instruct | Value : name='Alibaba-NLP/gte-Qwen2-7B-instruct' revision='e26182b2122f4435e8b3ebecbf363990f409b45b' release_date='2024-06-15' languages=None loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='Alibaba-NLP/gte-Qwen2-7B-instruct', instruction_template=<function instruction_template at 0x7f5a64def380>, attn='bbcc', pooling_method='lasttoken', mode='embedding', torch_dtype=torch.float16, normalized=True, embed_eos='<|endoftext|>') n_parameters=7613000000 memory_usage_mb=29040.0 max_tokens=32768.0 embed_dim=3584 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Alibaba-NLP/gte-Qwen1.5-7B-instruct | Value : name='Alibaba-NLP/gte-Qwen1.5-7B-instruct' revision='07d27e5226328010336563bc1b564a5e3436a298' release_date='2024-04-20' languages=['eng_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='Alibaba-NLP/gte-Qwen1.5-7B-instruct', instruction_template=<function instruction_template at 0x7f5a64def380>, attn='bbcc', pooling_method='lasttoken', mode='embedding', torch_dtype=torch.float16, normalized=True, embed_eos='<|endoftext|>') n_parameters=7720000000 memory_usage_mb=29449.0 max_tokens=32768.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Alibaba-NLP/gte-Qwen1.5-7B-instruct' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Alibaba-NLP/gte-Qwen2-1.5B-instruct | Value : name='Alibaba-NLP/gte-Qwen2-1.5B-instruct' revision='c6c1b92f4a3e1b92b326ad29dd3c8433457df8dd' release_date='2024-07-29' languages=['eng_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='Alibaba-NLP/gte-Qwen2-1.5B-instruct', instruction_template=<function instruction_template at 0x7f5a64def380>, attn='bbcc', pooling_method='lasttoken', mode='embedding', torch_dtype=torch.float16, normalized=True, embed_eos='<|endoftext|>') n_parameters=1780000000 memory_usage_mb=6776.0 max_tokens=32768.0 embed_dim=8960 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : thenlper/gte-small-zh | Value : name='thenlper/gte-small-zh' revision='af7bd46fbb00b3a6963c8dd7f1786ddfbfbe973a' release_date='2023-11-08' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='thenlper/gte-small-zh', revision='af7bd46fbb00b3a6963c8dd7f1786ddfbfbe973a') n_parameters=30300000 memory_usage_mb=58.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/thenlper/gte-small-zh' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : thenlper/gte-base-zh | Value : name='thenlper/gte-base-zh' revision='71ab7947d6fac5b64aa299e6e40e6c2b2e85976c' release_date='2023-11-08' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='thenlper/gte-base-zh', revision='71ab7947d6fac5b64aa299e6e40e6c2b2e85976c') n_parameters=102000000 memory_usage_mb=195.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/thenlper/gte-base-zh' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : thenlper/gte-large-zh | Value : name='thenlper/gte-large-zh' revision='64c364e579de308104a9b2c170ca009502f4f545' release_date='2023-11-08' languages=['zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='thenlper/gte-large-zh', revision='64c364e579de308104a9b2c170ca009502f4f545') n_parameters=326000000 memory_usage_mb=621.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/thenlper/gte-large-zh' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Alibaba-NLP/gte-multilingual-base | Value : name='Alibaba-NLP/gte-multilingual-base' revision='ca1791e0bcc104f6db161f27de1340241b13c5a4' release_date='2024-07-20' languages=['afr_Latn', 'ara_Arab', 'aze_Latn', 'bel_Cyrl', 'bul_Cyrl', 'ben_Beng', 'cat_Latn', 'ceb_Latn', 'ces_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'ell_Grek', 'eng_Latn', 'spa_Latn', 'est_Latn', 'eus_Latn', 'fas_Arab', 'fin_Latn', 'fra_Latn', 'glg_Latn', 'guj_Gujr', 'heb_Hebr', 'hin_Deva', 'hrv_Latn', 'hat_Latn', 'hun_Latn', 'hye_Armn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jpn_Jpan', 'jav_Latn', 'kat_Geor', 'kaz_Cyrl', 'khm_Khmr', 'kan_Knda', 'kor_Hang', 'kir_Cyrl', 'lao_Laoo', 'lit_Latn', 'lav_Latn', 'mkd_Cyrl', 'mal_Mlym', 'mon_Cyrl', 'mar_Deva', 'msa_Latn', 'mya_Mymr', 'nep_Deva', 'nld_Latn', 'nor_Latn', 'pan_Guru', 'pol_Latn', 'por_Latn', 'que_Latn', 'ron_Latn', 'rus_Cyrl', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'swa_Latn', 'tam_Taml', 'tel_Telu', 'tha_Thai', 'tgl_Latn', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'vie_Latn', 'yor_Latn', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Alibaba-NLP/gte-multilingual-base', revision='ca1791e0bcc104f6db161f27de1340241b13c5a4') n_parameters=305000000 memory_usage_mb=582.0 max_tokens=8192.0 embed_dim=1024 license='apache-2' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Alibaba-NLP/gte-multilingual-base' similarity_fn_name='cosine' use_instructions=False training_datasets={'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CMedQAv2-reranking': ['train'], 'NQ-NL': ['train'], 'NQ': ['train'], 'MSMARCO': ['train'], 'mMARCO-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'MrTidyRetrieval': ['train'], 'MultiLongDocRetrieval': ['train'], 'MIRACLReranking': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Alibaba-NLP/gte-modernbert-base | Value : name='Alibaba-NLP/gte-modernbert-base' revision='7ca8b4ca700621b67618669f5378fe5f5820b8e4' release_date='2025-01-21' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Alibaba-NLP/gte-modernbert-base', revision='7ca8b4ca700621b67618669f5378fe5f5820b8e4') n_parameters=149000000 memory_usage_mb=284.0 max_tokens=8192.0 embed_dim=768 license='apache-2' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Alibaba-NLP/gte-modernbert-base' similarity_fn_name='cosine' use_instructions=False training_datasets={'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CMedQAv2-reranking': ['train'], 'NQ-NL': ['train'], 'NQ': ['train'], 'MSMARCO': ['train'], 'mMARCO-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'MrTidyRetrieval': ['train'], 'MultiLongDocRetrieval': ['train'], 'MIRACLReranking': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Alibaba-NLP/gte-base-en-v1.5 | Value : name='Alibaba-NLP/gte-base-en-v1.5' revision='a829fd0e060bb84554da0dfd354d0de0f7712b7f' release_date='2024-06-20' languages=['eng-Latn'] loader=None n_parameters=137000000 memory_usage_mb=None max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Alibaba-NLP/gte-base-en-v1.5' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ibm-granite/granite-embedding-107m-multilingual | Value : name='ibm-granite/granite-embedding-107m-multilingual' revision='47db56afe692f731540413c67dd818ff492277e7' release_date='2024-12-18' languages=['ara_Latn', 'ces_Latn', 'deu_Latn', 'eng_Latn', 'spa_Latn', 'fra_Latn', 'ita_Latn', 'jpn_Latn', 'kor_Latn', 'nld_Latn', 'por_Latn', 'zho_Hant', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='ibm-granite/granite-embedding-107m-multilingual', revision='47db56afe692f731540413c67dd818ff492277e7') n_parameters=107000000 memory_usage_mb=204.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ibm-granite/granite-embedding-107m-multilingual' similarity_fn_name='cosine' use_instructions=False training_datasets={'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'StackOverflowDupQuestions': [], 'AskUbuntuDupQuestions': [], 'StackExchangeClusteringP2P': [], 'StackExchangeClusteringP2P.v2': [], 'StackExchangeClustering': [], 'StackExchangeClustering.v2': [], 'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'DBPedia': ['train'], 'DBPedia-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ibm-granite/granite-embedding-278m-multilingual | Value : name='ibm-granite/granite-embedding-278m-multilingual' revision='84e3546b88b0cb69f8078608a1df558020bcbf1f' release_date='2024-12-18' languages=['ara_Latn', 'ces_Latn', 'deu_Latn', 'eng_Latn', 'spa_Latn', 'fra_Latn', 'ita_Latn', 'jpn_Latn', 'kor_Latn', 'nld_Latn', 'por_Latn', 'zho_Hant', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='ibm-granite/granite-embedding-278m-multilingual', revision='84e3546b88b0cb69f8078608a1df558020bcbf1f') n_parameters=278000000 memory_usage_mb=530.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ibm-granite/granite-embedding-278m-multilingual' similarity_fn_name='cosine' use_instructions=False training_datasets={'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'StackOverflowDupQuestions': [], 'AskUbuntuDupQuestions': [], 'StackExchangeClusteringP2P': [], 'StackExchangeClusteringP2P.v2': [], 'StackExchangeClustering': [], 'StackExchangeClustering.v2': [], 'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'DBPedia': ['train'], 'DBPedia-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ibm-granite/granite-embedding-30m-english | Value : name='ibm-granite/granite-embedding-30m-english' revision='eddbb57470f896b5f8e2bfcb823d8f0e2d2024a5' release_date='2024-12-18' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='ibm-granite/granite-embedding-30m-english', revision='eddbb57470f896b5f8e2bfcb823d8f0e2d2024a5') n_parameters=30000000 memory_usage_mb=58.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ibm-granite/granite-embedding-30m-english' similarity_fn_name='cosine' use_instructions=False training_datasets={'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'StackOverflowDupQuestions': [], 'AskUbuntuDupQuestions': [], 'StackExchangeClusteringP2P': [], 'StackExchangeClusteringP2P.v2': [], 'StackExchangeClustering': [], 'StackExchangeClustering.v2': [], 'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'DBPedia': ['train'], 'DBPedia-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ibm-granite/granite-embedding-125m-english | Value : name='ibm-granite/granite-embedding-125m-english' revision='e48d3a5b47eaa18e3fe07d4676e187fd80f32730' release_date='2024-12-18' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='ibm-granite/granite-embedding-125m-english', revision='e48d3a5b47eaa18e3fe07d4676e187fd80f32730') n_parameters=125000000 memory_usage_mb=238.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ibm-granite/granite-embedding-125m-english' similarity_fn_name='cosine' use_instructions=False training_datasets={'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'StackOverflowDupQuestions': [], 'AskUbuntuDupQuestions': [], 'StackExchangeClusteringP2P': [], 'StackExchangeClusteringP2P.v2': [], 'StackExchangeClustering': [], 'StackExchangeClustering.v2': [], 'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'DBPedia': ['train'], 'DBPedia-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : infly/inf-retriever-v1 | Value : name='infly/inf-retriever-v1' revision='cb70ca7c31dfa866b2eff2dad229c144d8ddfd91' release_date='2024-12-24' languages=['eng_Latn', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='infly/inf-retriever-v1', revision='cb70ca7c31dfa866b2eff2dad229c144d8ddfd91', trust_remote_code=True) n_parameters=7069121024 memory_usage_mb=13483.0 max_tokens=32768.0 embed_dim=3584 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/infly/inf-retriever-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'ArguAna': ['train'], 'CQADupstackRetrieval': ['train'], 'ClimateFEVER': ['train'], 'DBPedia': ['train'], 'FEVER': ['train'], 'FiQA2018': ['train'], 'HotpotQA': ['train'], 'MSMARCO': ['train'], 'NFCorpus': ['train'], 'NQ': ['train'], 'QuoraRetrieval': ['train'], 'SCIDOCS': ['train'], 'SciFact': ['train'], 'TRECCOVID': ['train'], 'Touche2020': ['train'], 'CmedqaRetrieval': ['train'], 'CovidRetrieval': ['train'], 'DuRetrieval': ['train'], 'EcomRetrieval': ['train'], 'MMarcoRetrieval': ['train'], 'MedicalRetrieval': ['train'], 'T2Retrieval': ['train'], 'VideoRetrieval': ['train']} adapted_from='Alibaba-NLP/gte-Qwen2-7B-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : infly/inf-retriever-v1-1.5b | Value : name='infly/inf-retriever-v1-1.5b' revision='c9c05c2dd50707a486966ba81703021ae2094a06' release_date='2025-02-08' languages=['eng_Latn', 'zho_Hans'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='infly/inf-retriever-v1-1.5b', revision='c9c05c2dd50707a486966ba81703021ae2094a06', trust_remote_code=True) n_parameters=1543268864 memory_usage_mb=2944.0 max_tokens=32768.0 embed_dim=1536 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/infly/inf-retriever-v1-1.5b' similarity_fn_name='cosine' use_instructions=True training_datasets={'ArguAna': ['train'], 'CQADupstackRetrieval': ['train'], 'ClimateFEVER': ['train'], 'DBPedia': ['train'], 'FEVER': ['train'], 'FiQA2018': ['train'], 'HotpotQA': ['train'], 'MSMARCO': ['train'], 'NFCorpus': ['train'], 'NQ': ['train'], 'QuoraRetrieval': ['train'], 'SCIDOCS': ['train'], 'SciFact': ['train'], 'TRECCOVID': ['train'], 'Touche2020': ['train'], 'CmedqaRetrieval': ['train'], 'CovidRetrieval': ['train'], 'DuRetrieval': ['train'], 'EcomRetrieval': ['train'], 'MMarcoRetrieval': ['train'], 'MedicalRetrieval': ['train'], 'T2Retrieval': ['train'], 'VideoRetrieval': ['train']} adapted_from='Alibaba-NLP/gte-Qwen2-1.5B-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : infgrad/jasper_en_vision_language_v1 | Value : name='infgrad/jasper_en_vision_language_v1' revision='d6330ce98f8a0d741e781df845904c9484f00efa' release_date='2024-12-11' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.jasper_models.JasperWrapper'>, model_name='infgrad/jasper_en_vision_language_v1', revision='d6330ce98f8a0d741e781df845904c9484f00efa', config_kwargs={'is_text_encoder': True, 'vector_dim': 12288}, model_kwargs={'attn_implementation': 'sdpa', 'torch_dtype': torch.float16}, trust_remote_code=True, max_seq_length=2048, instruction_template='Instruct: {instruction}\\nQuery: ') n_parameters=1999000000 memory_usage_mb=3802.0 max_tokens=131072.0 embed_dim=8960 license='apache-2.0' open_weights=True public_training_code='https://github.com/NovaSearch-Team/RAG-Retrieval/blob/c40f4638b705eb77d88305d2056901ed550f9f4b/rag_retrieval/train/embedding/README.md' public_training_data='https://huggingface.co/datasets/infgrad/jasper_text_distill_dataset' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/infgrad/jasper_en_vision_language_v1/tree/main' similarity_fn_name='cosine' use_instructions=True training_datasets={'ArguAna': ['train'], 'ArguAna-PL': ['train'], 'ArguAna-NL': ['train'], 'NanoArguAnaRetrieval': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'ArxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'StackExchangeClustering': ['train'], 'StackExchangeClustering.v2': ['train'], 'StackExchangeClusteringP2P': ['train'], 'StackExchangeClusteringP2P.v2': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClusteringP2P.v2': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jinaai/jina-embeddings-v3 | Value : name='jinaai/jina-embeddings-v3' revision='215a6e121fa0183376388ac6b1ae230326bfeaed' release_date='2024-09-18' languages=['afr_Latn', 'amh_Latn', 'ara_Latn', 'asm_Latn', 'aze_Latn', 'bel_Latn', 'bul_Latn', 'ben_Latn', 'ben_Beng', 'bre_Latn', 'bos_Latn', 'cat_Latn', 'ces_Latn', 'cym_Latn', 'dan_Latn', 'deu_Latn', 'ell_Latn', 'eng_Latn', 'epo_Latn', 'spa_Latn', 'est_Latn', 'eus_Latn', 'fas_Latn', 'fin_Latn', 'fra_Latn', 'fry_Latn', 'gle_Latn', 'gla_Latn', 'glg_Latn', 'guj_Latn', 'hau_Latn', 'heb_Latn', 'hin_Latn', 'hin_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Latn', 'ind_Latn', 'isl_Latn', 'ita_Latn', 'jpn_Latn', 'jav_Latn', 'kat_Latn', 'kaz_Latn', 'khm_Latn', 'kan_Latn', 'kor_Latn', 'kur_Latn', 'kir_Latn', 'lat_Latn', 'lao_Latn', 'lit_Latn', 'lav_Latn', 'mlg_Latn', 'mkd_Latn', 'mal_Latn', 'mon_Latn', 'mar_Latn', 'msa_Latn', 'mya_Latn', 'nep_Latn', 'nld_Latn', 'nob_Latn', 'orm_Latn', 'ori_Latn', 'pan_Latn', 'pol_Latn', 'pus_Latn', 'por_Latn', 'ron_Latn', 'rus_Latn', 'san_Latn', 'snd_Latn', 'sin_Latn', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sqi_Latn', 'srp_Latn', 'sun_Latn', 'swe_Latn', 'swa_Latn', 'tam_Latn', 'tam_Taml', 'tel_Latn', 'tel_Telu', 'tha_Latn', 'tgl_Latn', 'tur_Latn', 'uig_Latn', 'ukr_Latn', 'urd_Latn', 'urd_Arab', 'uzb_Latn', 'vie_Latn', 'xho_Latn', 'yid_Latn', 'zho_Hant', 'zho_Hans'] loader=functools.partial(<class 'mteb.models.jina_models.JinaWrapper'>, model='jinaai/jina-embeddings-v3', revision='215a6e121fa0183376388ac6b1ae230326bfeaed', trust_remote_code=True, model_prompts={'Retrieval-query': 'retrieval.query', 'Retrieval-passage': 'retrieval.passage', 'Clustering': 'separation', 'Classification': 'classification', 'STS': 'text-matching', 'PairClassification': 'classification', 'BitextMining': 'text-matching', 'MultilabelClassification': 'classification', 'Reranking': 'separation', 'Summarization': 'text-matching'}) n_parameters=572000000 memory_usage_mb=1092.0 max_tokens=8194.0 embed_dim=1024 license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/jinaai/jina-embeddings-v3' similarity_fn_name='cosine' use_instructions=True training_datasets={'STS12': [], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='XLM-RoBERTa' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jinaai/jina-embeddings-v2-base-en | Value : name='jinaai/jina-embeddings-v2-base-en' revision='6e85f575bc273f1fd840a658067d0157933c83f0' release_date='2023-09-27' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.sentence_transformer_wrapper.SentenceTransformerWrapper'>, model_name='jinaai/jina-embeddings-v2-base-en', revision='6e85f575bc273f1fd840a658067d0157933c83f0', trust_remote_code=True) n_parameters=137000000 memory_usage_mb=262.0 max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/jinaai/jina-embeddings-v2-base-en' similarity_fn_name='cosine' use_instructions=False training_datasets={'PAQ': ['train'], 'GooAQ': ['train'], 'WikiAnswers': ['train'], 'AmazonQA': ['train'], 'ELI5': ['train'], 'SentenceCompression': ['train'], 'SimpleWikipedia': ['train'], 'Specter': ['train'], 'Squad2': ['train'], 'Tmdb': ['train'], 'TrivialQA': ['train'], 'TweetQA': ['train'], 'WikiHow': ['train'], 'Xmarket': [], 'S2ORC': [], 'YahooAnswers': [], 'MSMARCO': ['train'], 'StackExchange': [], 'QuoraQA': ['train'], 'MsCocoCaptions': ['train'], 'Flickr30k': ['train'], 'SNLI': ['train'], 'ESCI': ['train'], 'NegationDataset': ['train'], 'NQ': ['train'], 'HotpotQA': ['train'], 'FEVER': ['train'], 'CC-NEWS': []} adapted_from='jina-bert-base-en-v1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jinaai/jina-embeddings-v2-small-en | Value : name='jinaai/jina-embeddings-v2-small-en' revision='44e7d1d6caec8c883c2d4b207588504d519788d0' release_date='2023-09-27' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.sentence_transformer_wrapper.SentenceTransformerWrapper'>, model_name='jinaai/jina-embeddings-v2-small-en', revision='44e7d1d6caec8c883c2d4b207588504d519788d0', trust_remote_code=True) n_parameters=32700000 memory_usage_mb=62.0 max_tokens=8192.0 embed_dim=512 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/jinaai/jina-embeddings-v2-small-en' similarity_fn_name='cosine' use_instructions=False training_datasets={'PAQ': ['train'], 'GooAQ': ['train'], 'WikiAnswers': ['train'], 'AmazonQA': ['train'], 'ELI5': ['train'], 'SentenceCompression': ['train'], 'SimpleWikipedia': ['train'], 'Specter': ['train'], 'Squad2': ['train'], 'Tmdb': ['train'], 'TrivialQA': ['train'], 'TweetQA': ['train'], 'WikiHow': ['train'], 'Xmarket': [], 'S2ORC': [], 'YahooAnswers': [], 'MSMARCO': ['train'], 'StackExchange': [], 'QuoraQA': ['train'], 'MsCocoCaptions': ['train'], 'Flickr30k': ['train'], 'SNLI': ['train'], 'ESCI': ['train'], 'NegationDataset': ['train'], 'NQ': ['train'], 'HotpotQA': ['train'], 'FEVER': ['train'], 'CC-NEWS': []} adapted_from='jina-bert-smalll-en-v1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jinaai/jina-embedding-b-en-v1 | Value : name='jinaai/jina-embedding-b-en-v1' revision='32aa658e5ceb90793454d22a57d8e3a14e699516' release_date='2023-07-07' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.sentence_transformer_wrapper.SentenceTransformerWrapper'>, model_name='jinaai/jina-embedding-b-en-v1', revision='32aa658e5ceb90793454d22a57d8e3a14e699516') n_parameters=110000000 memory_usage_mb=420.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/jinaai/jina-embedding-b-en-v1' similarity_fn_name='cosine' use_instructions=False training_datasets={'PAQ': ['train'], 'GooAQ': ['train'], 'WikiAnswers': ['train'], 'AmazonQA': ['train'], 'ELI5': ['train'], 'SentenceCompression': ['train'], 'SimpleWikipedia': ['train'], 'Specter': ['train'], 'Squad2': ['train'], 'Tmdb': ['train'], 'TrivialQA': ['train'], 'TweetQA': ['train'], 'WikiHow': ['train'], 'Xmarket': [], 'S2ORC': [], 'YahooAnswers': [], 'MSMARCO': ['train'], 'StackExchange': [], 'QuoraQA': ['train'], 'MsCocoCaptions': ['train'], 'Flickr30k': ['train'], 'SNLI': ['train'], 'ESCI': ['train'], 'NegationDataset': ['train']} adapted_from='google-t5/t5-base' superseded_by='jinaai/jina-embeddings-v2-base-en' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jinaai/jina-embedding-s-en-v1 | Value : name='jinaai/jina-embedding-s-en-v1' revision='5ac6cd473e2324c6d5f9e558a6a9f65abb57143e' release_date='2023-07-07' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.sentence_transformer_wrapper.SentenceTransformerWrapper'>, model_name='jinaai/jina-embedding-s-en-v1', revision='5ac6cd473e2324c6d5f9e558a6a9f65abb57143e') n_parameters=35000000 memory_usage_mb=134.0 max_tokens=512.0 embed_dim=512 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/jinaai/jina-embedding-s-en-v1' similarity_fn_name='cosine' use_instructions=False training_datasets={'PAQ': ['train'], 'GooAQ': ['train'], 'WikiAnswers': ['train'], 'AmazonQA': ['train'], 'ELI5': ['train'], 'SentenceCompression': ['train'], 'SimpleWikipedia': ['train'], 'Specter': ['train'], 'Squad2': ['train'], 'Tmdb': ['train'], 'TrivialQA': ['train'], 'TweetQA': ['train'], 'WikiHow': ['train'], 'Xmarket': [], 'S2ORC': [], 'YahooAnswers': [], 'MSMARCO': ['train'], 'StackExchange': [], 'QuoraQA': ['train'], 'MsCocoCaptions': ['train'], 'Flickr30k': ['train'], 'SNLI': ['train'], 'ESCI': ['train'], 'NegationDataset': ['train']} adapted_from='google-t5/t5-small' superseded_by='jinaai/jina-embeddings-v2-small-en' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : jinaai/jina-clip-v1 | Value : name='jinaai/jina-clip-v1' revision='06150c7c382d7a4faedc7d5a0d8cdb59308968f4' release_date='2024-05-30' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.jina_clip.JinaCLIPModelWrapper'>, model_name='jinaai/jina-clip-v1') n_parameters=223000000 memory_usage_mb=849.0 max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/jinaai/jina-clip-v1' similarity_fn_name=None use_instructions=True training_datasets={'MSMARCO': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : yibinlei/LENS-d4000 | Value : name='yibinlei/LENS-d4000' revision='e473b33364e6c48a324796fd1411d3b93670c6fe' release_date='2025-01-17' languages=None loader=None n_parameters=7110000000 memory_usage_mb=27125.0 max_tokens=32768.0 embed_dim=4000 license='apache-2.0' open_weights=True public_training_code=None public_training_data='https://huggingface.co/datasets/cfli/bge-full-data' framework=['PyTorch'] reference='https://huggingface.co/yibinlei/LENS-d4000' similarity_fn_name='cosine' use_instructions=True training_datasets={'HotpotQA': ['train'], 'HotpotQA-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'MSMARCO': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'ArguAna': ['train'], 'ArguAna-NL': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'SciDocsReranking': ['train'], 'StackOverflowDupQuestions': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ImdbClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'ArxivClusteringS2S': ['train'], 'ArxivClusteringP2P': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringP2P': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'STS22': ['train'], 'STS22.v2': ['train'], 'STSBenchmark': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : yibinlei/LENS-d8000 | Value : name='yibinlei/LENS-d8000' revision='a0b87bd91cb27b6f2f0b0fe22c28026da1d464ef' release_date='2025-01-17' languages=None loader=None n_parameters=7110000000 memory_usage_mb=27125.0 max_tokens=32768.0 embed_dim=8000 license='apache-2.0' open_weights=True public_training_code=None public_training_data='https://huggingface.co/datasets/cfli/bge-full-data' framework=['PyTorch'] reference='https://huggingface.co/yibinlei/LENS-d8000' similarity_fn_name='cosine' use_instructions=True training_datasets={'HotpotQA': ['train'], 'HotpotQA-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'MSMARCO': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'ArguAna': ['train'], 'ArguAna-NL': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'SciDocsReranking': ['train'], 'StackOverflowDupQuestions': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ImdbClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'ArxivClusteringS2S': ['train'], 'ArxivClusteringP2P': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringP2P': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'STS22': ['train'], 'STS22.v2': ['train'], 'STSBenchmark': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Linq-AI-Research/Linq-Embed-Mistral | Value : name='Linq-AI-Research/Linq-Embed-Mistral' revision='0c1a0b0589177079acc552433cad51d7c9132379' release_date='2024-05-29' languages=['eng_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='Linq-AI-Research/Linq-Embed-Mistral', instruction_template=<function instruction_template at 0x7f5a64e3c400>, attn='cccc', pooling_method='lasttoken', mode='embedding', torch_dtype=torch.bfloat16, normalized=True) n_parameters=7110000000 memory_usage_mb=13563.0 max_tokens=32768.0 embed_dim=4096 license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='intfloat/e5-mistral-7b-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : microsoft/LLM2CLIP-Openai-L-14-336 | Value : name='microsoft/LLM2CLIP-Openai-L-14-336' revision='92512331f393a003c3d98404677f991c188162c9' release_date='2024-11-07' languages=['eng_Latn'] loader=functools.partial(<function llm2clip_loader at 0x7f5a64e3c5e0>, model_name='microsoft/LLM2CLIP-Openai-L-14-336') n_parameters=579000000 memory_usage_mb=None max_tokens=None embed_dim=1280 license='apache-2.0' open_weights=True public_training_code='https://github.com/microsoft/LLM2CLIP' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/microsoft/LLM2CLIP-Openai-L-14-336' similarity_fn_name=None use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : microsoft/LLM2CLIP-Openai-L-14-224 | Value : name='microsoft/LLM2CLIP-Openai-L-14-224' revision='6b8a11a94ff380fa220dfefe73ac9293d2677575' release_date='2024-11-07' languages=['eng_Latn'] loader=functools.partial(<function llm2clip_loader at 0x7f5a64e3c5e0>, model_name='microsoft/LLM2CLIP-Openai-L-14-224') n_parameters=578000000 memory_usage_mb=None max_tokens=None embed_dim=1280 license='apache-2.0' open_weights=True public_training_code='https://github.com/microsoft/LLM2CLIP' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/microsoft/LLM2CLIP-Openai-L-14-224' similarity_fn_name=None use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : microsoft/LLM2CLIP-Openai-B-16 | Value : name='microsoft/LLM2CLIP-Openai-B-16' revision='ecfb347eb3dcfeb2fbc2a2eae7de6ac5a001aaf8' release_date='2024-11-07' languages=['eng_Latn'] loader=functools.partial(<function llm2clip_loader at 0x7f5a64e3c5e0>, model_name='microsoft/LLM2CLIP-Openai-B-16') n_parameters=361000000 memory_usage_mb=None max_tokens=None embed_dim=1280 license='apache-2.0' open_weights=True public_training_code='https://github.com/microsoft/LLM2CLIP' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/microsoft/LLM2CLIP-Openai-B-16' similarity_fn_name=None use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised | Value : name='McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised' revision='baa8ebf04a1c2500e61288e7dad65e8ae42601a7' release_date='2024-04-09' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3cea0> n_parameters=7505000000 memory_usage_mb=28629.0 max_tokens=8192.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/McGill-NLP/llm2vec/tree/250292a307428240d801fadd85825464e71c3277/train_configs' public_training_data=None framework=['LLM2Vec', 'PyTorch'] reference='https://huggingface.co/McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised' similarity_fn_name='cosine' use_instructions=True training_datasets={'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FEVER-NL': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-unsup-simcse | Value : name='McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-unsup-simcse' revision='1cb7b735326d13a8541db8f57f35da5373f5e9c6' release_date='2024-04-09' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3cf40> n_parameters=7505000000 memory_usage_mb=28629.0 max_tokens=8192.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/McGill-NLP/llm2vec/tree/250292a307428240d801fadd85825464e71c3277/train_configs' public_training_data=None framework=['LLM2Vec', 'PyTorch'] reference='https://huggingface.co/McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-unsup-simcse' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-supervised | Value : name='McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-supervised' revision='0ae69bdd5816105778b971c3138e8f8a18eaa3ae' release_date='2024-04-09' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3cfe0> n_parameters=7111000000 memory_usage_mb=27126.0 max_tokens=32768.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/McGill-NLP/llm2vec/tree/250292a307428240d801fadd85825464e71c3277/train_configs' public_training_data=None framework=['LLM2Vec', 'PyTorch'] reference='https://huggingface.co/McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-supervised' similarity_fn_name='cosine' use_instructions=True training_datasets={'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FEVER-NL': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse | Value : name='McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse' revision='2c055a5d77126c0d3dc6cd8ffa30e2908f4f45f8' release_date='2024-04-09' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3d080> n_parameters=7111000000 memory_usage_mb=27126.0 max_tokens=32768.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/McGill-NLP/llm2vec/tree/250292a307428240d801fadd85825464e71c3277/train_configs' public_training_data=None framework=['LLM2Vec', 'PyTorch'] reference='https://huggingface.co/McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp-supervised | Value : name='McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp-supervised' revision='2c055a5d77126c0d3dc6cd8ffa30e2908f4f45f8' release_date='2024-04-09' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3d120> n_parameters=7111000000 memory_usage_mb=27126.0 max_tokens=32768.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/McGill-NLP/llm2vec/tree/250292a307428240d801fadd85825464e71c3277/train_configs' public_training_data=None framework=['LLM2Vec', 'PyTorch'] reference='https://huggingface.co/McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp-supervised' similarity_fn_name='cosine' use_instructions=True training_datasets={'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FEVER-NL': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp-unsup-simcse | Value : name='McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp-unsup-simcse' revision='a76944871d169ebe7c97eb921764cd063afed785' release_date='2024-04-09' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3d1c0> n_parameters=7111000000 memory_usage_mb=27126.0 max_tokens=32768.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/McGill-NLP/llm2vec/tree/250292a307428240d801fadd85825464e71c3277/train_configs' public_training_data=None framework=['LLM2Vec', 'PyTorch'] reference='https://huggingface.co/McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp-unsup-simcse' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-supervised | Value : name='McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-supervised' revision='a5943d406c6b016fef3f07906aac183cf1a0b47d' release_date='2024-04-09' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3d260> n_parameters=7111000000 memory_usage_mb=27126.0 max_tokens=32768.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/McGill-NLP/llm2vec/tree/250292a307428240d801fadd85825464e71c3277/train_configs' public_training_data=None framework=['LLM2Vec', 'PyTorch'] reference='https://huggingface.co/McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-supervised' similarity_fn_name='cosine' use_instructions=True training_datasets={'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FEVER-NL': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-unsup-simcse | Value : name='McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-unsup-simcse' revision='a5943d406c6b016fef3f07906aac183cf1a0b47d' release_date='2024-04-09' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3d300> n_parameters=7111000000 memory_usage_mb=27126.0 max_tokens=32768.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/McGill-NLP/llm2vec/tree/250292a307428240d801fadd85825464e71c3277/train_configs' public_training_data=None framework=['LLM2Vec', 'PyTorch'] reference='https://huggingface.co/McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-unsup-simcse' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Haon-Chen/speed-embedding-7b-instruct | Value : name='Haon-Chen/speed-embedding-7b-instruct' revision='c167e9a8144b397622ce47b85d9edcdeecef3d3f' release_date='2024-10-31' languages=['eng_Latn'] loader=None n_parameters=7110660096 memory_usage_mb=13563.0 max_tokens=32768.0 embed_dim=None license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/Haon-Chen/speed-embedding-7b-instruct' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='mistralai/Mistral-7B-v0.1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Gameselo/STS-multilingual-mpnet-base-v2 | Value : name='Gameselo/STS-multilingual-mpnet-base-v2' revision='449f917af30f590fc31f9ffb226c94f21a2f47b8' release_date='2024-06-07' languages=[] loader=None n_parameters=278043648 memory_usage_mb=1061.0 max_tokens=514.0 embed_dim=768 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Gameselo/STS-multilingual-mpnet-base-v2' similarity_fn_name='cosine' use_instructions=None training_datasets={'AlphaNLI': ['train'], 'RTE3': ['train'], 'AmazonPolarityClassification': ['train'], 'AmazonReviewsClassification': ['train'], 'ArguAna': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringS2S': ['train'], 'AskUbuntuDupQuestions': ['train'], 'BIOSSES': ['train'], 'Banking77Classification': ['train'], 'BiorxivClusteringP2P': ['train'], 'BiorxivClusteringS2S': ['train'], 'CQADupstackRetrieval': ['train'], 'ClimateFEVER': ['train'], 'DBPedia': ['train'], 'EmotionClassification': ['train'], 'FEVER': ['train'], 'FiQA2018': ['train'], 'HotpotQA': ['train'], 'ImdbClassification': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'MedrxivClusteringP2P': ['train'], 'MedrxivClusteringS2S': ['train'], 'MindSmallReranking': ['train'], 'NFCorpus': ['train'], 'NQ': ['train'], 'QuoraRetrieval': ['train'], 'RedditClustering': ['train'], 'RedditClusteringP2P': ['train'], 'SCIDOCS': ['train'], 'SICK-R': ['train'], 'STS12': ['train'], 'STS13': ['train'], 'STS14': ['train'], 'STS15': ['train'], 'STS16': ['train'], 'STSBenchmark': ['train'], 'SciDocsRR': ['train'], 'SciFact': ['train'], 'SprintDuplicateQuestions': ['train'], 'StackExchangeClustering': ['train'], 'StackExchangeClusteringP2P': ['train'], 'StackOverflowDupQuestions': ['train'], 'SummEval': ['train'], 'TRECCOVID': ['train'], 'Touche2020': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwitterSemEval2015': ['train'], 'TwitterURLCorpus': ['train'], 'MSMARCO': ['train'], 'AmazonCounterfactualClassification': ['train'], 'STS17': ['train'], 'STS22': ['train']} adapted_from='sentence-transformers/paraphrase-multilingual-mpnet-base-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1 | Value : name='HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1' revision='45e42c89990c40aca042659133fc8b13c28634b5' release_date='2024-10-23' languages=None loader=None n_parameters=494032768 memory_usage_mb=1885.0 max_tokens=512.0 embed_dim=896 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1' similarity_fn_name='cosine' use_instructions=None training_datasets={'CodeFeedbackMT': ['train'], 'CodeFeedbackST': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringS2S': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'TRECCOVID': ['train'], 'DBPedia': ['train'], 'ESCIReranking': ['train'], 'FEVER': ['train'], 'FiQA2018': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FEVER-NL': ['train'], 'FiQA2018-NL': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MultiLongDocRetrieval': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'MSMARCOv2': ['train'], 'NFCorpus': ['train'], 'SciFact': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'YahooAnswersTopicsClassification': ['train'], 'ContractNLIConfidentialityOfAgreementLegalBenchClassification': ['train'], 'ContractNLIExplicitIdentificationLegalBenchClassification': ['train'], 'ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification': ['train'], 'ContractNLILimitedUseLegalBenchClassification': ['train'], 'ContractNLINoLicensingLegalBenchClassification': ['train'], 'ContractNLINoticeOnCompelledDisclosureLegalBenchClassification': ['train'], 'ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification': ['train'], 'ContractNLIPermissibleCopyLegalBenchClassification': ['train'], 'ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification': ['train'], 'ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification': ['train'], 'ContractNLIReturnOfConfidentialInformationLegalBenchClassification': ['train'], 'ContractNLISharingWithEmployeesLegalBenchClassification': ['train'], 'ContractNLISharingWithThirdPartiesLegalBenchClassification': ['train'], 'ContractNLISurvivalOfObligationsLegalBenchClassification': ['train'], 'QuoraRetrieval': ['train'], 'NanoQuoraRetrieval': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'Banking77Classification': ['train'], 'AmazonPolarityClassification': ['train'], 'ImdbClassification': ['train'], 'EmotionClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'PawsXPairClassification': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'MultilingualSentiment': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train']} adapted_from='/mnt/shgeminicephfs/wx-dc-plt-hpc/xinshuohu/Output/Embedding/Qwen2-0.5B-eos_mean_pretrain_0806_1e-4_uen_sft_1022_filtered_v2_inst_3node_g8_1e-5_sin-0.1_mrl' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : HIT-TMG/KaLM-embedding-multilingual-mini-v1 | Value : name='HIT-TMG/KaLM-embedding-multilingual-mini-v1' revision='8a82a0cd2b322b91723e252486f7cce6fd8ac9d3' release_date='2024-08-27' languages=None loader=None n_parameters=494032768 memory_usage_mb=1885.0 max_tokens=512.0 embed_dim=896 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/HIT-TMG/KaLM-embedding-multilingual-mini-v1' similarity_fn_name='cosine' use_instructions=None training_datasets={'CodeFeedbackMT': ['train'], 'CodeFeedbackST': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringS2S': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'TRECCOVID': ['train'], 'DBPedia': ['train'], 'ESCIReranking': ['train'], 'FEVER': ['train'], 'FiQA2018': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FEVER-NL': ['train'], 'FiQA2018-NL': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MultiLongDocRetrieval': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'MSMARCOv2': ['train'], 'NFCorpus': ['train'], 'SciFact': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'YahooAnswersTopicsClassification': ['train'], 'ContractNLIConfidentialityOfAgreementLegalBenchClassification': ['train'], 'ContractNLIExplicitIdentificationLegalBenchClassification': ['train'], 'ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification': ['train'], 'ContractNLILimitedUseLegalBenchClassification': ['train'], 'ContractNLINoLicensingLegalBenchClassification': ['train'], 'ContractNLINoticeOnCompelledDisclosureLegalBenchClassification': ['train'], 'ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification': ['train'], 'ContractNLIPermissibleCopyLegalBenchClassification': ['train'], 'ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification': ['train'], 'ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification': ['train'], 'ContractNLIReturnOfConfidentialInformationLegalBenchClassification': ['train'], 'ContractNLISharingWithEmployeesLegalBenchClassification': ['train'], 'ContractNLISharingWithThirdPartiesLegalBenchClassification': ['train'], 'ContractNLISurvivalOfObligationsLegalBenchClassification': ['train'], 'QuoraRetrieval': ['train'], 'NanoQuoraRetrieval': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'Banking77Classification': ['train'], 'AmazonPolarityClassification': ['train'], 'ImdbClassification': ['train'], 'EmotionClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'PawsXPairClassification': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'MultilingualSentiment': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train']} adapted_from='/mnt/shgeminicephfs/wx-dc-plt-hpc/xinshuohu/Output/Embedding/Qwen2-0.5B-eos_mean_pretrain_0806_1e-4_uen_sft_0902_filtered_v2_3node_g8_1e-5_sin-0.1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Hum-Works/lodestone-base-4096-v1 | Value : name='Hum-Works/lodestone-base-4096-v1' revision='9bbc2d0b57dd2198aea029404b0f976712a7d966' release_date='2023-08-25' languages=['eng_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/Hum-Works/lodestone-base-4096-v1' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='hum-lodestone-v1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Jaume/gemma-2b-embeddings | Value : name='Jaume/gemma-2b-embeddings' revision='86431f65d7c3f66b2af096c61e614a2958f191f1' release_date='2024-06-29' languages=[] loader=None n_parameters=2506172416 memory_usage_mb=9560.0 max_tokens=8192.0 embed_dim=2048 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Jaume/gemma-2b-embeddings' similarity_fn_name='cosine' use_instructions=None training_datasets={} adapted_from='google/gemma-2b' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : BeastyZ/e5-R-mistral-7b | Value : name='BeastyZ/e5-R-mistral-7b' revision='3f810a6a7fd220369ad248e3705cf13d71803602' release_date='2024-06-28' languages=['eng_Latn'] loader=None n_parameters=7241732096 memory_usage_mb=27625.0 max_tokens=32768.0 embed_dim=None license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/BeastyZ/e5-R-mistral-7b' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='intfloat/e5-mistral-7b-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Lajavaness/bilingual-embedding-base | Value : name='Lajavaness/bilingual-embedding-base' revision='0bfc54bb2aa2666dd84715289c7ef58a95eb4d8d' release_date='2024-06-26' languages=None loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Lajavaness/bilingual-embedding-base', revision='0bfc54bb2aa2666dd84715289c7ef58a95eb4d8d', trust_remote_code=True) n_parameters=278043648 memory_usage_mb=1061.0 max_tokens=514.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Lajavaness/bilingual-embedding-base' similarity_fn_name='cosine' use_instructions=None training_datasets={'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'XNLI': ['train']} adapted_from='dangvantuan/bilingual_impl' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Lajavaness/bilingual-embedding-large | Value : name='Lajavaness/bilingual-embedding-large' revision='e83179d7a66e8aed1b3015e98bb5ae234ed89598' release_date='2024-06-24' languages=['fra_Latn', 'eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Lajavaness/bilingual-embedding-large', revision='e83179d7a66e8aed1b3015e98bb5ae234ed89598', trust_remote_code=True) n_parameters=559890432 memory_usage_mb=2136.0 max_tokens=514.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Lajavaness/bilingual-embedding-large' similarity_fn_name='cosine' use_instructions=None training_datasets={'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'XNLI': ['train']} adapted_from='dangvantuan/bilingual_impl' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Lajavaness/bilingual-embedding-small | Value : name='Lajavaness/bilingual-embedding-small' revision='ed4a1dd814de0db81d4a4e287c296a03194463e3' release_date='2024-07-17' languages=['fra_Latn', 'eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='Lajavaness/bilingual-embedding-small', revision='ed4a1dd814de0db81d4a4e287c296a03194463e3', trust_remote_code=True) n_parameters=117653760 memory_usage_mb=449.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Lajavaness/bilingual-embedding-small' similarity_fn_name='cosine' use_instructions=None training_datasets={'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'XNLI': ['train']} adapted_from='dangvantuan/bilingual_impl' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Mihaiii/Bulbasaur | Value : name='Mihaiii/Bulbasaur' revision='6876f839e18ae36224049a41194a431953f08747' release_date='2024-04-27' languages=None loader=None n_parameters=17389824 memory_usage_mb=66.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Mihaiii/Bulbasaur' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='Mihaiii/dwsdwass' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Mihaiii/Ivysaur | Value : name='Mihaiii/Ivysaur' revision='65914d976f45beb4bda7485c39d88865b4ce6554' release_date='2024-04-27' languages=None loader=None n_parameters=22713216 memory_usage_mb=87.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Mihaiii/Ivysaur' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='Mihaiii/jhjghjgh' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Mihaiii/Squirtle | Value : name='Mihaiii/Squirtle' revision='5b991da48a9286637a256d4a35aab87a1a57b78a' release_date='2024-04-30' languages=None loader=None n_parameters=15615360 memory_usage_mb=60.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Mihaiii/Squirtle' similarity_fn_name='cosine' use_instructions=None training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from='Mihaiii/test21' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Mihaiii/Venusaur | Value : name='Mihaiii/Venusaur' revision='0dc817f0addbb7bab8feeeeaded538f9ffeb3419' release_date='2024-04-29' languages=None loader=None n_parameters=15615360 memory_usage_mb=60.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Mihaiii/Venusaur' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='Mihaiii/test14' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Mihaiii/Wartortle | Value : name='Mihaiii/Wartortle' revision='14caca5253414d38a7d28b62d1b7c30ef3293a87' release_date='2024-04-30' languages=None loader=None n_parameters=17389824 memory_usage_mb=66.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Mihaiii/Wartortle' similarity_fn_name='cosine' use_instructions=None training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from='Mihaiii/test22' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Mihaiii/gte-micro | Value : name='Mihaiii/gte-micro' revision='6fd2397cb9dfa7c901aedf9a2a44d3c888ccafdd' release_date='2024-04-21' languages=None loader=None n_parameters=17389824 memory_usage_mb=66.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Mihaiii/gte-micro' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Mihaiii/gte-micro-v4 | Value : name='Mihaiii/gte-micro-v4' revision='78e1a4b348f8524c3ab2e3e3475788f5adb8c98f' release_date='2024-04-22' languages=None loader=None n_parameters=19164288 memory_usage_mb=73.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Mihaiii/gte-micro-v4' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : OrdalieTech/Solon-embeddings-large-0.1 | Value : name='OrdalieTech/Solon-embeddings-large-0.1' revision='9f6465f6ea2f6d10c6294bc15d84edf87d47cdef' release_date='2023-12-09' languages=['fra_Latn'] loader=None n_parameters=559890432 memory_usage_mb=2136.0 max_tokens=514.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/OrdalieTech/Solon-embeddings-large-0.1' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='solon-large-06-BIG' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Omartificial-Intelligence-Space/Arabert-all-nli-triplet-Matryoshka | Value : name='Omartificial-Intelligence-Space/Arabert-all-nli-triplet-Matryoshka' revision='d0361a36f6fe69febfc8550d0918abab174f6f30' release_date='2024-06-16' languages=['ara_Arab'] loader=None n_parameters=135193344 memory_usage_mb=516.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Omartificial-Intelligence-Space/Arabert-all-nli-triplet-Matryoshka' similarity_fn_name='cosine' use_instructions=None training_datasets={} adapted_from='aubmindlab/bert-base-arabertv02' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Omartificial-Intelligence-Space/Arabic-MiniLM-L12-v2-all-nli-triplet | Value : name='Omartificial-Intelligence-Space/Arabic-MiniLM-L12-v2-all-nli-triplet' revision='6916465c43b984e955aa6dc72851474f0128f428' release_date='2024-06-25' languages=['ara_Arab'] loader=None n_parameters=117653760 memory_usage_mb=449.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Omartificial-Intelligence-Space/Arabic-MiniLM-L12-v2-all-nli-triplet' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Omartificial-Intelligence-Space/Arabic-all-nli-triplet-Matryoshka | Value : name='Omartificial-Intelligence-Space/Arabic-all-nli-triplet-Matryoshka' revision='1ca467cc576bd76666a4d21b24ee43afa914dd10' release_date='2024-06-14' languages=['ara_Arab'] loader=None n_parameters=278043648 memory_usage_mb=1061.0 max_tokens=514.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Omartificial-Intelligence-Space/Arabic-all-nli-triplet-Matryoshka' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='sentence-transformers/paraphrase-multilingual-mpnet-base-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Omartificial-Intelligence-Space/Arabic-labse-Matryoshka | Value : name='Omartificial-Intelligence-Space/Arabic-labse-Matryoshka' revision='ee6d5e33c78ed582ade47fd452a74ea52aa5bfe2' release_date='2024-06-16' languages=['ara_Arab'] loader=None n_parameters=470926848 memory_usage_mb=1796.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Omartificial-Intelligence-Space/Arabic-labse-Matryoshka' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='sentence-transformers/LaBSE' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Omartificial-Intelligence-Space/Arabic-mpnet-base-all-nli-triplet | Value : name='Omartificial-Intelligence-Space/Arabic-mpnet-base-all-nli-triplet' revision='2628cb641e040f44328195fadcdfb58e6d5cffa7' release_date='2024-06-15' languages=['ara_Arab'] loader=None n_parameters=109486464 memory_usage_mb=418.0 max_tokens=514.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Omartificial-Intelligence-Space/Arabic-mpnet-base-all-nli-triplet' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='tomaarsen/mpnet-base-all-nli-triplet' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Omartificial-Intelligence-Space/Marbert-all-nli-triplet-Matryoshka | Value : name='Omartificial-Intelligence-Space/Marbert-all-nli-triplet-Matryoshka' revision='ecf3274e164f057c4a3dd70691cae0265d87a9d0' release_date='2024-06-17' languages=['ara_Arab'] loader=None n_parameters=162841344 memory_usage_mb=621.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Omartificial-Intelligence-Space/Marbert-all-nli-triplet-Matryoshka' similarity_fn_name='cosine' use_instructions=None training_datasets={} adapted_from='UBC-NLP/MARBERTv2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : consciousAI/cai-lunaris-text-embeddings | Value : name='consciousAI/cai-lunaris-text-embeddings' revision='8332c464d13505968ff7a6e2213f36fd8730b4c7' release_date='2023-06-22' languages=None loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/consciousAI/cai-lunaris-text-embeddings' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='/root/.cache/torch/sentence_transformers/intfloat_e5-large-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : consciousAI/cai-stellaris-text-embeddings | Value : name='consciousAI/cai-stellaris-text-embeddings' revision='c000ec4b29588daf0f4a0b2ad4e72ee807d8efc0' release_date='2023-06-23' languages=None loader=None n_parameters=None memory_usage_mb=None max_tokens=514.0 embed_dim=768 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/consciousAI/cai-stellaris-text-embeddings' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='/root/.cache/torch/sentence_transformers/sentence-transformers_all-mpnet-base-v1/' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : manu/sentence_croissant_alpha_v0.2 | Value : name='manu/sentence_croissant_alpha_v0.2' revision='4610b8cea65d7dd59e0b04af50753933fe5b29b2' release_date='2024-03-15' languages=None loader=None n_parameters=1279887360 memory_usage_mb=2441.0 max_tokens=2048.0 embed_dim=2048 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/manu/sentence_croissant_alpha_v0.2' similarity_fn_name='cosine' use_instructions=None training_datasets={'STS12': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'QuoraRetrieval': ['train'], 'MSMARCO': ['train'], 'STSB': ['train']} adapted_from='croissantllm/CroissantCool' superseded_by='manu/sentence_croissant_alpha_v0.3' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : manu/sentence_croissant_alpha_v0.3 | Value : name='manu/sentence_croissant_alpha_v0.3' revision='4ac16754f3d81aba76cc32955dc9ee4122df96eb' release_date='2024-04-26' languages=None loader=None n_parameters=1279887360 memory_usage_mb=2441.0 max_tokens=2048.0 embed_dim=2048 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/manu/sentence_croissant_alpha_v0.3' similarity_fn_name='cosine' use_instructions=None training_datasets={'STS12': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'QuoraRetrieval': ['train'], 'MSMARCO': ['train'], 'STSB': ['train']} adapted_from='croissantllm/CroissantCool-v0.2' superseded_by='manu/sentence_croissant_alpha_v0.4' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : manu/sentence_croissant_alpha_v0.4 | Value : name='manu/sentence_croissant_alpha_v0.4' revision='0ce6372e6a3c21134dcf26dcde13cca869c767fc' release_date='2024-04-27' languages=['fra_Latn', 'eng_Latn'] loader=None n_parameters=1279887360 memory_usage_mb=2441.0 max_tokens=2048.0 embed_dim=2048 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/manu/sentence_croissant_alpha_v0.4' similarity_fn_name='cosine' use_instructions=None training_datasets={'STS12': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'QuoraRetrieval': ['train'], 'MSMARCO': ['train'], 'STSB': ['train']} adapted_from='croissantllm/CroissantCool-v0.2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : thenlper/gte-base | Value : name='thenlper/gte-base' revision='c078288308d8dee004ab72c6191778064285ec0c' release_date='2023-07-27' languages=['eng_Latn'] loader=None n_parameters=109482752 memory_usage_mb=209.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/thenlper/gte-base' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : thenlper/gte-large | Value : name='thenlper/gte-large' revision='4bef63f39fcc5e2d6b0aae83089f307af4970164' release_date='2023-07-27' languages=['eng_Latn'] loader=None n_parameters=335142400 memory_usage_mb=639.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/thenlper/gte-large' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : thenlper/gte-small | Value : name='thenlper/gte-small' revision='17e1f347d17fe144873b1201da91788898c639cd' release_date='2023-07-27' languages=['eng_Latn'] loader=None n_parameters=33360512 memory_usage_mb=64.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/thenlper/gte-small' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : OrlikB/KartonBERT-USE-base-v1 | Value : name='OrlikB/KartonBERT-USE-base-v1' revision='1f59dd58fe57995c0e867d5e29f03763eae99645' release_date='2024-09-30' languages=['pol_Latn'] loader=None n_parameters=103705344 memory_usage_mb=396.0 max_tokens=512.0 embed_dim=768 license='gpl-3.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/OrlikB/KartonBERT-USE-base-v1' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='KartonBERT-USE-base-v1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : OrlikB/st-polish-kartonberta-base-alpha-v1 | Value : name='OrlikB/st-polish-kartonberta-base-alpha-v1' revision='5590a0e2d7bb43674e44d7076b3ff157f7d4a1cb' release_date='2023-11-12' languages=['pol_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=514.0 embed_dim=768 license='lgpl' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/OrlikB/st-polish-kartonberta-base-alpha-v1' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='st-polish-kartonberta-base-alpha-v1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sdadas/mmlw-e5-base | Value : name='sdadas/mmlw-e5-base' revision='f10628ed55b5ec400502aff439bd714a6da0af30' release_date='2023-11-17' languages=['pol_Latn'] loader=None n_parameters=278043648 memory_usage_mb=1061.0 max_tokens=514.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/sdadas/mmlw-e5-base' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='intfloat/multilingual-e5-base' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : dwzhu/e5-base-4k | Value : name='dwzhu/e5-base-4k' revision='1b5664b8cb2bccd8c309429b7bfe5864402e8fbc' release_date='2024-03-28' languages=['eng_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=4096.0 embed_dim=None license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/dwzhu/e5-base-4k' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='intfloat/e5-base-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sdadas/mmlw-e5-large | Value : name='sdadas/mmlw-e5-large' revision='5c143fb045ebed664fd85b43fc45155999eb110f' release_date='2023-11-17' languages=['pol_Latn'] loader=None n_parameters=559890432 memory_usage_mb=2136.0 max_tokens=514.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/sdadas/mmlw-e5-large' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='intfloat/multilingual-e5-large' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sdadas/mmlw-e5-small | Value : name='sdadas/mmlw-e5-small' revision='ff1298cb6d997f18b794d2f3d73cad2ba2ad739a' release_date='2023-11-17' languages=['pol_Latn'] loader=None n_parameters=117653760 memory_usage_mb=449.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/sdadas/mmlw-e5-small' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='intfloat/multilingual-e5-small' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sdadas/mmlw-roberta-base | Value : name='sdadas/mmlw-roberta-base' revision='0ac7f23f6c96af601fa6a17852bd08d5136d6365' release_date='2023-11-17' languages=['pol_Latn'] loader=None n_parameters=124442880 memory_usage_mb=475.0 max_tokens=514.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/sdadas/mmlw-roberta-base' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train']} adapted_from='sdadas/polish-roberta-base-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sdadas/mmlw-roberta-large | Value : name='sdadas/mmlw-roberta-large' revision='b8058066a8de32d0737b3cd82d8b4f4108745af9' release_date='2023-11-17' languages=['pol_Latn'] loader=None n_parameters=434961408 memory_usage_mb=1659.0 max_tokens=514.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/sdadas/mmlw-roberta-large' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': ['train']} adapted_from='sdadas/polish-roberta-large-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : izhx/udever-bloom-1b1 | Value : name='izhx/udever-bloom-1b1' revision='7bf1ee29878cb040b2708a691aa4b61f27eaa252' release_date='2023-10-24' languages=['aka_Latn', 'ara_Arab', 'asm_Beng', 'bam_Latn', 'ben_Beng', 'cat_Latn', 'eng_Latn', 'spa_Latn', 'eus_Latn', 'fon_Latn', 'fra_Latn', 'guj_Gujr', 'hin_Deva', 'ind_Latn', 'ibo_Latn', 'kik_Latn', 'kan_Knda', 'lug_Latn', 'lin_Latn', 'mal_Mlym', 'mar_Deva', 'nep_Deva', 'nso_Latn', 'nya_Latn', 'ori_Orya', 'pan_Guru', 'por_Latn', 'run_Latn', 'kin_Latn', 'sna_Latn', 'sot_Latn', 'swa_Latn', 'tam_Taml', 'tel_Telu', 'tsn_Latn', 'tso_Latn', 'tum_Latn', 'twi_Latn', 'urd_Arab', 'vie_Latn', 'wol_Latn', 'xho_Latn', 'yor_Latn', 'zho_Hans', 'zul_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license='bigscience-bloom-rail-1.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/izhx/udever-bloom-1b1' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': []} adapted_from='bigscience/bloom-1b1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : izhx/udever-bloom-3b | Value : name='izhx/udever-bloom-3b' revision='4edd8affe80ca89ba0f6b6ba4103fc7f25fc57b2' release_date='2023-10-24' languages=['aka_Latn', 'ara_Arab', 'asm_Beng', 'bam_Latn', 'ben_Beng', 'cat_Latn', 'eng_Latn', 'spa_Latn', 'eus_Latn', 'fon_Latn', 'fra_Latn', 'guj_Gujr', 'hin_Deva', 'ind_Latn', 'ibo_Latn', 'kik_Latn', 'kan_Knda', 'lug_Latn', 'lin_Latn', 'mal_Mlym', 'mar_Deva', 'nep_Deva', 'nso_Latn', 'nya_Latn', 'ori_Orya', 'pan_Guru', 'por_Latn', 'run_Latn', 'kin_Latn', 'sna_Latn', 'sot_Latn', 'swa_Latn', 'tam_Taml', 'tel_Telu', 'tsn_Latn', 'tso_Latn', 'tum_Latn', 'twi_Latn', 'urd_Arab', 'vie_Latn', 'wol_Latn', 'xho_Latn', 'yor_Latn', 'zho_Hans', 'zul_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license='bigscience-bloom-rail-1.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/izhx/udever-bloom-3b' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': []} adapted_from='bigscience/bloom-3b' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : izhx/udever-bloom-560m | Value : name='izhx/udever-bloom-560m' revision='b2a723e355946ec5a5c5fbed3459766627ded2bb' release_date='2023-10-24' languages=['aka_Latn', 'ara_Arab', 'asm_Beng', 'bam_Latn', 'ben_Beng', 'cat_Latn', 'eng_Latn', 'spa_Latn', 'eus_Latn', 'fon_Latn', 'fra_Latn', 'guj_Gujr', 'hin_Deva', 'ind_Latn', 'ibo_Latn', 'kik_Latn', 'kan_Knda', 'lug_Latn', 'lin_Latn', 'mal_Mlym', 'mar_Deva', 'nep_Deva', 'nso_Latn', 'nya_Latn', 'ori_Orya', 'pan_Guru', 'por_Latn', 'run_Latn', 'kin_Latn', 'sna_Latn', 'sot_Latn', 'swa_Latn', 'tam_Taml', 'tel_Telu', 'tsn_Latn', 'tso_Latn', 'tum_Latn', 'twi_Latn', 'urd_Arab', 'vie_Latn', 'wol_Latn', 'xho_Latn', 'yor_Latn', 'zho_Hans', 'zul_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license='bigscience-bloom-rail-1.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/izhx/udever-bloom-560m' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': []} adapted_from='bigscience/bloom-560m' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : izhx/udever-bloom-7b1 | Value : name='izhx/udever-bloom-7b1' revision='18e8d3e6dbd94868584877f2e72a105a17df22ef' release_date='2023-10-24' languages=['aka_Latn', 'ara_Arab', 'asm_Beng', 'bam_Latn', 'ben_Beng', 'cat_Latn', 'eng_Latn', 'spa_Latn', 'eus_Latn', 'fon_Latn', 'fra_Latn', 'guj_Gujr', 'hin_Deva', 'ind_Latn', 'ibo_Latn', 'kik_Latn', 'kan_Knda', 'lug_Latn', 'lin_Latn', 'mal_Mlym', 'mar_Deva', 'nep_Deva', 'nso_Latn', 'nya_Latn', 'ori_Orya', 'pan_Guru', 'por_Latn', 'run_Latn', 'kin_Latn', 'sna_Latn', 'sot_Latn', 'swa_Latn', 'tam_Taml', 'tel_Telu', 'tsn_Latn', 'tso_Latn', 'tum_Latn', 'twi_Latn', 'urd_Arab', 'vie_Latn', 'wol_Latn', 'xho_Latn', 'yor_Latn', 'zho_Hans', 'zul_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license='bigscience-bloom-rail-1.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/izhx/udever-bloom-7b1' similarity_fn_name='cosine' use_instructions=None training_datasets={'MSMARCO': []} adapted_from='bigscience/bloom-7b1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : avsolatorio/GIST-Embedding-v0 | Value : name='avsolatorio/GIST-Embedding-v0' revision='bf6b2e55e92f510a570ad4d7d2da2ec8cd22590c' release_date='2024-01-31' languages=['eng_Latn'] loader=None n_parameters=109482240 memory_usage_mb=418.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/avsolatorio/GIST-Embedding-v0' similarity_fn_name='cosine' use_instructions=None training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['train'], 'MLQARetrieval': ['validation', 'test'], 'AmazonPolarityClassification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'Banking77Classification': ['train'], 'AmazonCounterfactualClassification': ['train']} adapted_from='BAAI/bge-large-en-v1.5' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : avsolatorio/GIST-all-MiniLM-L6-v2 | Value : name='avsolatorio/GIST-all-MiniLM-L6-v2' revision='ea89dfad053bba14677bb784a4269898abbdce44' release_date='2024-02-03' languages=['eng_Latn'] loader=None n_parameters=22713216 memory_usage_mb=87.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/avsolatorio/GIST-all-MiniLM-L6-v2' similarity_fn_name='cosine' use_instructions=None training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['train'], 'MLQARetrieval': ['validation', 'test'], 'AmazonPolarityClassification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'Banking77Classification': ['train'], 'AmazonCounterfactualClassification': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : avsolatorio/GIST-large-Embedding-v0 | Value : name='avsolatorio/GIST-large-Embedding-v0' revision='7831200e2f7819b994490c091cf3258a2b821f0c' release_date='2024-02-14' languages=['eng_Latn'] loader=None n_parameters=335141888 memory_usage_mb=1278.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/avsolatorio/GIST-large-Embedding-v0' similarity_fn_name='cosine' use_instructions=None training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['train'], 'MLQARetrieval': ['validation', 'test'], 'AmazonPolarityClassification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'Banking77Classification': ['train'], 'AmazonCounterfactualClassification': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : avsolatorio/GIST-small-Embedding-v0 | Value : name='avsolatorio/GIST-small-Embedding-v0' revision='d6c4190f9e01b9994dc7cac99cf2f2b85cfb57bc' release_date='2024-02-03' languages=['eng_Latn'] loader=None n_parameters=33360000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/avsolatorio/GIST-small-Embedding-v0' similarity_fn_name='cosine' use_instructions=None training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['train'], 'MLQARetrieval': ['validation', 'test'], 'AmazonPolarityClassification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'Banking77Classification': ['train'], 'AmazonCounterfactualClassification': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : bigscience/sgpt-bloom-7b1-msmarco | Value : name='bigscience/sgpt-bloom-7b1-msmarco' revision='dc579f3d2d5a0795eba2049e16c3e36c74007ad3' release_date='2022-08-26' languages=None loader=None n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=4096 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/bigscience/sgpt-bloom-7b1-msmarco' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='/gpfsscratch/rech/six/commun/commun/experiments/muennighoff/bloomckpt/6b3/bloom-7b1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : aari1995/German_Semantic_STS_V2 | Value : name='aari1995/German_Semantic_STS_V2' revision='22912542b0ec7a7ef369837e28ffe6352a27afc9' release_date='2022-11-17' languages=['deu_Latn'] loader=None n_parameters=335736320 memory_usage_mb=1281.0 max_tokens=512.0 embed_dim=1024 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/aari1995/German_Semantic_STS_V2' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='/content/drive/MyDrive/Stanford_NLU/Project/false_friends/gbert_large_sts_only' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : abhinand/MedEmbed-small-v0.1 | Value : name='abhinand/MedEmbed-small-v0.1' revision='40a5850d046cfdb56154e332b4d7099b63e8d50e' release_date='2024-10-20' languages=['eng_Latn'] loader=None n_parameters=33360000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/abhinand/MedEmbed-small-v0.1' similarity_fn_name='cosine' use_instructions=None training_datasets={'MedicalQARetrieval': ['train'], 'NFCorpus': ['train'], 'NFCorpus-NL': ['train'], 'PublicHealthQA': ['train'], 'TRECCOVID': ['train'], 'ArguAna': ['train'], 'TRECCOVID-NL': ['train'], 'ArguAna-NL': ['train']} adapted_from='./medical-bge-small-v1-mix1' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : avsolatorio/NoInstruct-small-Embedding-v0 | Value : name='avsolatorio/NoInstruct-small-Embedding-v0' revision='b38747000553d8268915c95a55fc87e707c9aadd' release_date='2024-05-01' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.no_instruct_sentence_models.NoInstructWrapper'>, model_name='avsolatorio/NoInstruct-small-Embedding-v0', revision='b38747000553d8268915c95a55fc87e707c9aadd') n_parameters=33400000 memory_usage_mb=127.0 max_tokens=512.0 embed_dim=384 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/avsolatorio/NoInstruct-small-Embedding-v0' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : brahmairesearch/slx-v0.1 | Value : name='brahmairesearch/slx-v0.1' revision='688c83fd1a7f34b25575a2bc26cfd87c11b4ce71' release_date='2024-08-13' languages=['eng_Latn'] loader=None n_parameters=22713216 memory_usage_mb=87.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/brahmairesearch/slx-v0.1' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : deepfile/embedder-100p | Value : name='deepfile/embedder-100p' revision='aa02f08f11517977fbcdc94dc9dbf9a1ca152d9b' release_date='2023-07-24' languages=None loader=None n_parameters=None memory_usage_mb=1061.0 max_tokens=514.0 embed_dim=768 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/deepfile/embedder-100p' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='sentence-transformers/paraphrase-multilingual-mpnet-base-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : deepvk/USER-bge-m3 | Value : name='deepvk/USER-bge-m3' revision='0cc6cfe48e260fb0474c753087a69369e88709ae' release_date='2024-07-05' languages=['rus_Cyrl'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='deepvk/USER-bge-m3', revision='0cc6cfe48e260fb0474c753087a69369e88709ae') n_parameters=359026688 memory_usage_mb=1370.0 max_tokens=8194.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/deepvk/USER-base' similarity_fn_name='cosine' use_instructions=False training_datasets={'BibleNLPBitextMining': ['train'], 'MLSUMClusteringP2P': ['train'], 'MLSUMClusteringP2P.v2': ['train'], 'MLSUMClusteringS2S': ['train'], 'MLSUMClusteringS2S.v2': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'LeCaRDv2': ['train'], 'CMedQAv1-reranking': ['train'], 'CMedQAv2-reranking': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CodeSearchNet': ['train']} adapted_from='https://huggingface.co/BAAI/bge-m3' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : infgrad/stella-base-en-v2 | Value : name='infgrad/stella-base-en-v2' revision='c9e80ff9892d80b39dc54e30a7873f91ea161034' release_date='2023-10-19' languages=['eng_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=None license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/infgrad/stella-base-en-v2' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : malenia1/ternary-weight-embedding | Value : name='malenia1/ternary-weight-embedding' revision='a1208fb7f646647bb62639fd2e1eb6cc2ef3738e' release_date='2024-10-23' languages=None loader=None n_parameters=98688000 memory_usage_mb=158.0 max_tokens=512.0 embed_dim=1024 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/malenia1/ternary-weight-embedding' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='ternary-weight-embedding' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : omarelshehy/arabic-english-sts-matryoshka | Value : name='omarelshehy/arabic-english-sts-matryoshka' revision='763d116fbe8bf7883c64635c862feeaa3768bb64' release_date='2024-10-13' languages=['ara_Arab', 'eng_Latn'] loader=None n_parameters=559890432 memory_usage_mb=2136.0 max_tokens=514.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/omarelshehy/arabic-english-sts-matryoshka' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='FacebookAI/xlm-roberta-large' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : openbmb/MiniCPM-Embedding | Value : name='openbmb/MiniCPM-Embedding' revision='c0cb2de33fb366e17c30f9d53142ff11bc18e049' release_date='2024-09-04' languages=['zho_Hans', 'eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='openbmb/MiniCPM-Embedding', revision='c0cb2de33fb366e17c30f9d53142ff11bc18e049', model_kwargs={'torch_dtype': torch.float16}, trust_remote_code=True) n_parameters=2724880896 memory_usage_mb=5197.0 max_tokens=512.0 embed_dim=2304 license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/openbmb/MiniCPM-Embedding' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : shibing624/text2vec-base-multilingual | Value : name='shibing624/text2vec-base-multilingual' revision='6633dc49e554de7105458f8f2e96445c6598e9d1' release_date='2023-06-22' languages=['deu-Latn', 'eng-Latn', 'spa-Latn', 'fra-Latn', 'ita-Latn', 'nld-Latn', 'pol-Latn', 'por-Latn', 'rus-Cyrl', 'zho-Hans'] loader=None n_parameters=118000000 memory_usage_mb=449.0 max_tokens=256.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/shibing624/text2vec-base-chinese-paraphrase' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : silma-ai/silma-embeddding-matryoshka-v0.1 | Value : name='silma-ai/silma-embeddding-matryoshka-v0.1' revision='a520977a9542ebdb8a7206df6b7ff6977f1886ea' release_date='2024-10-12' languages=['ara_Arab', 'eng_Latn'] loader=None n_parameters=135193344 memory_usage_mb=516.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/silma-ai/silma-embeddding-matryoshka-v0.1' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='/workspace/v3-matryoshka_aubmindlab-bert-base-arabertv02-2024-10-12_13-55-06/checkpoint-26250' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : DMetaSoul/sbert-chinese-general-v1 | Value : name='DMetaSoul/sbert-chinese-general-v1' revision='bd27765956bcc2fcf682de0097819947ac10037e' release_date='2022-03-25' languages=['zho_Hans'] loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=128 license='apache-2' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/DMetaSoul/sbert-chinese-general-v1' similarity_fn_name='cosine' use_instructions=None training_datasets={'PAWSX': ['train'], 'PawsXPairClassification': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : DMetaSoul/Dmeta-embedding-zh-small | Value : name='DMetaSoul/Dmeta-embedding-zh-small' revision='2050d3439a2f68999dd648c1697471acaac37a29' release_date='2024-03-25' languages=['zho_Hans'] loader=None n_parameters=74200000 memory_usage_mb=283.0 max_tokens=1024.0 embed_dim=768 license='apache-2' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/DMetaSoul/Dmeta-embedding-zh-small/' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : lier007/xiaobu-embedding | Value : name='lier007/xiaobu-embedding' revision='59c79d82eb5223cd9895f6eb8e825c7fa10e4e92' release_date='2024-01-09' languages=['zho_Hans'] loader=None n_parameters=326000000 memory_usage_mb=1244.0 max_tokens=512.0 embed_dim=1024 license='not specified' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/lier007/xiaobu-embedding' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='thenlper/gte-large-zh' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : lier007/xiaobu-embedding-v2 | Value : name='lier007/xiaobu-embedding-v2' revision='1912f2e59a5c2ef802a471d735a38702a5c9485e' release_date='2024-06-30' languages=['zho_Hans'] loader=None n_parameters=326000000 memory_usage_mb=1242.0 max_tokens=512.0 embed_dim=768 license='not specified' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/lier007/xiaobu-embedding-v2' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='sensenova/piccolo-base-zh' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Classical/Yinka | Value : name='Classical/Yinka' revision='59c79d82eb5223cd9895f6eb8e825c7fa10e4e92' release_date='2024-01-09' languages=['zho_Hans'] loader=None n_parameters=326000000 memory_usage_mb=1244.0 max_tokens=512.0 embed_dim=1024 license='not specified' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Classical/Yinka' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from='dunzhang/stella-mrl-large-zh-v3.5-1792d' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : TencentBAC/Conan-embedding-v1 | Value : name='TencentBAC/Conan-embedding-v1' revision='bb9749a57d4f02fd71722386f8d0f5a9398d7eeb' release_date='2024-08-22' languages=['zho_Hans'] loader=None n_parameters=326000000 memory_usage_mb=1242.0 max_tokens=512.0 embed_dim=768 license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/Classical/Yinka' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : llmrails/ember-v1 | Value : name='llmrails/ember-v1' revision='5e5ce5904901f6ce1c353a95020f17f09e5d021d' release_date='2023-10-10' languages=['eng_Latn'] loader=None n_parameters=335000000 memory_usage_mb=1278.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Sentence Transformers'] reference='https://huggingface.co/llmrails/ember-v1' similarity_fn_name='cosine' use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : amazon/Titan-text-embeddings-v2 | Value : name='amazon/Titan-text-embeddings-v2' revision='1' release_date='2024-04-30' languages=['eng_Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license='proprietary' open_weights=False public_training_code=None public_training_data=None framework=[] reference='https://huggingface.co/amazon/Titan-text-embeddings-v2' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : minishlab/M2V_base_glove_subword | Value : name='minishlab/M2V_base_glove_subword' revision='5f4f5ca159b7321a8b39739bba0794fa0debddf4' release_date='2024-09-21' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.model2vec_models.Model2VecWrapper'>, model_name='minishlab/M2V_base_glove_subword') n_parameters=103000000 memory_usage_mb=391.0 max_tokens=inf embed_dim=256 license='mit' open_weights=True public_training_code='https://github.com/MinishLab/model2vec' public_training_data=None framework=['NumPy'] reference='https://huggingface.co/minishlab/M2V_base_glove_subword' similarity_fn_name='cosine' use_instructions=False training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from='BAAI/bge-base-en-v1.5' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : minishlab/M2V_base_glove | Value : name='minishlab/M2V_base_glove' revision='38ebd7f10f71e67fa8db898290f92b82e9cfff2b' release_date='2024-09-21' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.model2vec_models.Model2VecWrapper'>, model_name='minishlab/M2V_base_glove') n_parameters=102000000 memory_usage_mb=391.0 max_tokens=inf embed_dim=256 license='mit' open_weights=True public_training_code='https://github.com/MinishLab/model2vec' public_training_data=None framework=['NumPy'] reference='https://huggingface.co/minishlab/M2V_base_glove' similarity_fn_name='cosine' use_instructions=False training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from='BAAI/bge-base-en-v1.5' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : minishlab/M2V_base_output | Value : name='minishlab/M2V_base_output' revision='02460ae401a22b09d2c6652e23371398329551e2' release_date='2024-09-21' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.model2vec_models.Model2VecWrapper'>, model_name='minishlab/M2V_base_output') n_parameters=7560000 memory_usage_mb=29.0 max_tokens=inf embed_dim=256 license='mit' open_weights=True public_training_code='https://github.com/MinishLab/model2vec' public_training_data=None framework=['NumPy'] reference='https://huggingface.co/minishlab/M2V_base_output' similarity_fn_name='cosine' use_instructions=False training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from='BAAI/bge-base-en-v1.5' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : minishlab/M2V_multilingual_output | Value : name='minishlab/M2V_multilingual_output' revision='2cf4ec4e1f51aeca6c55cf9b93097d00711a6305' release_date='2024-09-21' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.model2vec_models.Model2VecWrapper'>, model_name='minishlab/M2V_multilingual_output') n_parameters=128000000 memory_usage_mb=489.0 max_tokens=inf embed_dim=256 license='mit' open_weights=True public_training_code='https://github.com/MinishLab/model2vec' public_training_data=None framework=['NumPy'] reference='https://huggingface.co/minishlab/M2V_multilingual_output' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from='sentence-transformers/LaBSE' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : minishlab/potion-base-2M | Value : name='minishlab/potion-base-2M' revision='86db093558fbced2072b929eb1690bce5272bd4b' release_date='2024-10-29' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.model2vec_models.Model2VecWrapper'>, model_name='minishlab/potion-base-2M') n_parameters=2000000 memory_usage_mb=7.0 max_tokens=inf embed_dim=64 license='mit' open_weights=True public_training_code='https://github.com/MinishLab/model2vec' public_training_data=None framework=['NumPy'] reference='https://huggingface.co/minishlab/potion-base-2M' similarity_fn_name='cosine' use_instructions=False training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from='BAAI/bge-base-en-v1.5' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : minishlab/potion-base-4M | Value : name='minishlab/potion-base-4M' revision='81b1802ada41afcd0987a37dc15e569c9fa76f04' release_date='2024-10-29' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.model2vec_models.Model2VecWrapper'>, model_name='minishlab/potion-base-4M') n_parameters=3780000 memory_usage_mb=14.0 max_tokens=inf embed_dim=128 license='mit' open_weights=True public_training_code='https://github.com/MinishLab/model2vec' public_training_data=None framework=['NumPy'] reference='https://huggingface.co/minishlab/potion-base-4M' similarity_fn_name='cosine' use_instructions=False training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from='BAAI/bge-base-en-v1.5' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : minishlab/potion-base-8M | Value : name='minishlab/potion-base-8M' revision='dcbec7aa2d52fc76754ac6291803feedd8c619ce' release_date='2024-10-29' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.model2vec_models.Model2VecWrapper'>, model_name='minishlab/potion-base-8M') n_parameters=7560000 memory_usage_mb=29.0 max_tokens=inf embed_dim=256 license='mit' open_weights=True public_training_code='https://github.com/MinishLab/model2vec' public_training_data=None framework=['NumPy'] reference='https://huggingface.co/minishlab/potion-base-8M' similarity_fn_name='cosine' use_instructions=False training_datasets={'NQ': ['test'], 'NQ-NL': ['test'], 'NQHardNegatives': ['test'], 'AmazonReviewsClassification': ['validation', 'test'], 'MLQARetrieval': ['validation', 'test']} adapted_from='BAAI/bge-base-en-v1.5' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : moka-ai/m3e-base | Value : name='moka-ai/m3e-base' revision='764b537a0e50e5c7d64db883f2d2e051cbe3c64c' release_date='2023-06-06' languages=['zho_Hans', 'eng-Latn'] loader=None n_parameters=102000000 memory_usage_mb=390.0 max_tokens=512.0 embed_dim=768 license='unspecified-noncommercial' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/moka-ai/m3e-base' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'AmazonReviewsClassification': ['train'], 'Ocnli': ['train'], 'BQ': ['train'], 'LCQMC': ['train'], 'MIRACLReranking': ['train'], 'PAWSX': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : moka-ai/m3e-small | Value : name='moka-ai/m3e-small' revision='44c696631b2a8c200220aaaad5f987f096e986df' release_date='2023-06-02' languages=['zho_Hans', 'eng-Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=512 license='unspecified-noncommercial' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/moka-ai/m3e-small' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'AmazonReviewsClassification': ['train'], 'Ocnli': ['train'], 'BQ': ['train'], 'LCQMC': ['train'], 'MIRACLReranking': ['train'], 'PAWSX': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : moka-ai/m3e-large | Value : name='moka-ai/m3e-large' revision='12900375086c37ba5d83d1e417b21dc7d1d1f388' release_date='2023-06-21' languages=['zho_Hans', 'eng-Latn'] loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=768 license='unspecified-noncommercial' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/moka-ai/m3e-large' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'AmazonReviewsClassification': ['train'], 'Ocnli': ['train'], 'BQ': ['train'], 'LCQMC': ['train'], 'MIRACLReranking': ['train'], 'PAWSX': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : nyu-visionx/moco-v3-vit-b | Value : name='nyu-visionx/moco-v3-vit-b' revision='7d091cd70772c5c0ecf7f00b5f12ca609a99d69d' release_date='2024-06-03' languages=['eng_Latn'] loader=functools.partial(<function mocov3_loader at 0x7f5a64e3d6c0>, model_name='nyu-visionx/moco-v3-vit-b') n_parameters=86600000 memory_usage_mb=330.0 max_tokens=None embed_dim=768 license='cc-by-nc-4.0' open_weights=True public_training_code='https://github.com/facebookresearch/moco-v3' public_training_data=None framework=['PyTorch'] reference='https://github.com/facebookresearch/moco-v3' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image']\n",
      "\n",
      "Model Name : nyu-visionx/moco-v3-vit-l | Value : name='nyu-visionx/moco-v3-vit-l' revision='7bf75358d616f39b9716148bf4e3425f3bd35b47' release_date='2024-06-03' languages=['eng_Latn'] loader=functools.partial(<function mocov3_loader at 0x7f5a64e3d6c0>, model_name='nyu-visionx/moco-v3-vit-l') n_parameters=304000000 memory_usage_mb=1161.0 max_tokens=None embed_dim=1024 license='cc-by-nc-4.0' open_weights=True public_training_code='https://github.com/facebookresearch/moco-v3' public_training_data=None framework=['PyTorch'] reference='https://github.com/facebookresearch/moco-v3' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image']\n",
      "\n",
      "Model Name : mixedbread-ai/mxbai-embed-large-v1 | Value : name='mixedbread-ai/mxbai-embed-large-v1' revision='990580e27d329c7408b3741ecff85876e128e203' release_date='2024-03-07' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='mixedbread-ai/mxbai-embed-large-v1', revision='990580e27d329c7408b3741ecff85876e128e203', model_prompts={'query': 'Represent this sentence for searching relevant passages: '}) n_parameters=335000000 memory_usage_mb=639.0 max_tokens=512.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': []} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : mixedbread-ai/mxbai-embed-2d-large-v1 | Value : name='mixedbread-ai/mxbai-embed-2d-large-v1' revision='7e639ca8e344af398876ead3b19ec3c0b9068f49' release_date='2024-03-04' languages=['eng_Latn'] loader=None n_parameters=335000000 memory_usage_mb=None max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/mixedbread-ai/mxbai-embed-2d-large-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': []} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : mixedbread-ai/mxbai-embed-xsmall-v1 | Value : name='mixedbread-ai/mxbai-embed-xsmall-v1' revision='2f741ec33328bb57e4704e1238fc59a4a5745705' release_date='2024-08-13' languages=['eng_Latn'] loader=None n_parameters=24100000 memory_usage_mb=None max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/mixedbread-ai/mxbai-embed-xsmall-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': []} adapted_from='sentence-transformers/all-MiniLM-L6-v2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : nomic-ai/nomic-embed-text-v1.5 | Value : name='nomic-ai/nomic-embed-text-v1.5' revision='b0753ae76394dd36bcfb912a46018088bca48be0' release_date='2024-02-10' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.nomic_models.NomicWrapper'>, trust_remote_code=True, model_name='nomic-ai/nomic-embed-text-v1.5', revision='b0753ae76394dd36bcfb912a46018088bca48be0', model_prompts={'Classification': 'classification: ', 'MultilabelClassification': 'classification: ', 'Clustering': 'clustering: ', 'PairClassification': 'classification: ', 'Reranking': 'classification: ', 'STS': 'classification: ', 'Summarization': 'classification: ', 'query': 'search_query: ', 'passage': 'search_document: '}) n_parameters=137000000 memory_usage_mb=522.0 max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/nomic-ai/contrastors/blob/5f7b461e5a13b5636692d1c9f1141b27232fe966/src/contrastors/configs/train/contrastive_finetune.yaml' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/nomic-ai/nomic-embed-text-v1.5' similarity_fn_name='cosine' use_instructions=True training_datasets={'RedditClustering': [], 'RedditClusteringP2P': [], 'RedditClustering.v2': [], 'RedditClusteringP2P.v2': [], 'AmazonPolarityClassification': [], 'AmazonReviewsClassification': [], 'AmazonCounterfactualClassification': [], 'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'CodeSearchNetCCRetrieval': [], 'COIRCodeSearchNetRetrieval': [], 'YahooAnswersTopicsClassification': [], 'StackExchangeClustering.v2': [], 'StackExchangeClusteringP2P.v2': [], 'QuoraRetrieval': [], 'Quora-NL': [], 'NanoQuoraRetrieval': [], 'FQuADRetrieval': [], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : nomic-ai/nomic-embed-text-v1 | Value : name='nomic-ai/nomic-embed-text-v1' revision='0759316f275aa0cb93a5b830973843ca66babcf5' release_date='2024-01-31' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.nomic_models.NomicWrapper'>, trust_remote_code=True, model_name='nomic-ai/nomic-embed-text-v1', revision='0759316f275aa0cb93a5b830973843ca66babcf5', model_prompts={'Classification': 'classification: ', 'MultilabelClassification': 'classification: ', 'Clustering': 'clustering: ', 'PairClassification': 'classification: ', 'Reranking': 'classification: ', 'STS': 'classification: ', 'Summarization': 'classification: ', 'query': 'search_query: ', 'passage': 'search_document: '}) n_parameters=None memory_usage_mb=522.0 max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/nomic-ai/contrastors/blob/5f7b461e5a13b5636692d1c9f1141b27232fe966/src/contrastors/configs/train/contrastive_finetune.yaml' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/nomic-ai/nomic-embed-text-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'RedditClustering': [], 'RedditClusteringP2P': [], 'RedditClustering.v2': [], 'RedditClusteringP2P.v2': [], 'AmazonPolarityClassification': [], 'AmazonReviewsClassification': [], 'AmazonCounterfactualClassification': [], 'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'CodeSearchNetCCRetrieval': [], 'COIRCodeSearchNetRetrieval': [], 'YahooAnswersTopicsClassification': [], 'StackExchangeClustering.v2': [], 'StackExchangeClusteringP2P.v2': [], 'QuoraRetrieval': [], 'Quora-NL': [], 'NanoQuoraRetrieval': [], 'FQuADRetrieval': [], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test']} adapted_from=None superseded_by='nomic-ai/nomic-embed-text-v1.5' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : nomic-ai/nomic-embed-text-v1-ablated | Value : name='nomic-ai/nomic-embed-text-v1-ablated' revision='7d948905c5d5d3874fa55a925d68e49dbf411e5f' release_date='2024-01-15' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.nomic_models.NomicWrapper'>, trust_remote_code=True, model_name='nomic-ai/nomic-embed-text-v1-ablated', revision='7d948905c5d5d3874fa55a925d68e49dbf411e5f', model_prompts={'Classification': 'classification: ', 'MultilabelClassification': 'classification: ', 'Clustering': 'clustering: ', 'PairClassification': 'classification: ', 'Reranking': 'classification: ', 'STS': 'classification: ', 'Summarization': 'classification: ', 'query': 'search_query: ', 'passage': 'search_document: '}) n_parameters=None memory_usage_mb=None max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/nomic-ai/contrastors/blob/5f7b461e5a13b5636692d1c9f1141b27232fe966/src/contrastors/configs/train/contrastive_finetune.yaml' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/nomic-ai/nomic-embed-text-v1-ablated' similarity_fn_name='cosine' use_instructions=True training_datasets={'RedditClustering': [], 'RedditClusteringP2P': [], 'RedditClustering.v2': [], 'RedditClusteringP2P.v2': [], 'AmazonPolarityClassification': [], 'AmazonReviewsClassification': [], 'AmazonCounterfactualClassification': [], 'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'CodeSearchNetCCRetrieval': [], 'COIRCodeSearchNetRetrieval': [], 'YahooAnswersTopicsClassification': [], 'StackExchangeClustering.v2': [], 'StackExchangeClusteringP2P.v2': [], 'QuoraRetrieval': [], 'Quora-NL': [], 'NanoQuoraRetrieval': [], 'FQuADRetrieval': [], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : nomic-ai/nomic-embed-text-v1-unsupervised | Value : name='nomic-ai/nomic-embed-text-v1-unsupervised' revision='b53d557b15ae63852847c222d336c1609eced93c' release_date='2024-01-15' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.nomic_models.NomicWrapper'>, trust_remote_code=True, model_name='nomic-ai/nomic-embed-text-v1-unsupervised', revision='b53d557b15ae63852847c222d336c1609eced93c', model_prompts={'Classification': 'classification: ', 'MultilabelClassification': 'classification: ', 'Clustering': 'clustering: ', 'PairClassification': 'classification: ', 'Reranking': 'classification: ', 'STS': 'classification: ', 'Summarization': 'classification: ', 'query': 'search_query: ', 'passage': 'search_document: '}) n_parameters=None memory_usage_mb=None max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/nomic-ai/contrastors/blob/5f7b461e5a13b5636692d1c9f1141b27232fe966/src/contrastors/configs/train/contrastive_finetune.yaml' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/nomic-ai/nomic-embed-text-v1-unsupervised' similarity_fn_name='cosine' use_instructions=True training_datasets={'RedditClustering': [], 'RedditClusteringP2P': [], 'RedditClustering.v2': [], 'RedditClusteringP2P.v2': [], 'AmazonPolarityClassification': [], 'AmazonReviewsClassification': [], 'AmazonCounterfactualClassification': [], 'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'CodeSearchNetCCRetrieval': [], 'COIRCodeSearchNetRetrieval': [], 'YahooAnswersTopicsClassification': [], 'StackExchangeClustering.v2': [], 'StackExchangeClusteringP2P.v2': [], 'QuoraRetrieval': [], 'Quora-NL': [], 'NanoQuoraRetrieval': [], 'FQuADRetrieval': [], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : nomic-ai/modernbert-embed-base | Value : name='nomic-ai/modernbert-embed-base' revision='5960f1566fb7cb1adf1eb6e816639cf4646d9b12' release_date='2024-12-29' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.nomic_models.NomicWrapper'>, model_name='nomic-ai/modernbert-embed-base', revision='5960f1566fb7cb1adf1eb6e816639cf4646d9b12', model_prompts={'Classification': 'classification: ', 'MultilabelClassification': 'classification: ', 'Clustering': 'clustering: ', 'PairClassification': 'classification: ', 'Reranking': 'classification: ', 'STS': 'classification: ', 'Summarization': 'classification: ', 'query': 'search_query: ', 'passage': 'search_document: '}, model_kwargs={'torch_dtype': torch.float16}) n_parameters=149000000 memory_usage_mb=568.0 max_tokens=8192.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/nomic-ai/contrastors/blob/5f7b461e5a13b5636692d1c9f1141b27232fe966/src/contrastors/configs/train/contrastive_pretrain_modernbert.yaml' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/nomic-ai/modernbert-embed-base' similarity_fn_name='cosine' use_instructions=True training_datasets={'RedditClustering': [], 'RedditClusteringP2P': [], 'RedditClustering.v2': [], 'RedditClusteringP2P.v2': [], 'AmazonPolarityClassification': [], 'AmazonReviewsClassification': [], 'AmazonCounterfactualClassification': [], 'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'CodeSearchNetCCRetrieval': [], 'COIRCodeSearchNetRetrieval': [], 'YahooAnswersTopicsClassification': [], 'StackExchangeClustering.v2': [], 'StackExchangeClusteringP2P.v2': [], 'QuoraRetrieval': [], 'Quora-NL': [], 'NanoQuoraRetrieval': [], 'FQuADRetrieval': [], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'HotPotQA': ['test'], 'HotPotQAHardNegatives': ['test'], 'HotPotQA-PL': ['test'], 'HotpotQA-NL': ['test'], 'FEVER': ['test'], 'FEVERHardNegatives': ['test'], 'FEVER-NL': ['test']} adapted_from='answerdotai/ModernBERT-base' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : nomic-ai/nomic-embed-vision-v1.5 | Value : name='nomic-ai/nomic-embed-vision-v1.5' revision='af2246fffdab78d8458418480e4886a8e48b70a7' release_date='2024-06-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.nomic_models_vision.NomicVisionModelWrapper'>, vision_model_name='nomic-ai/nomic-embed-vision-v1.5', text_model_name='nomic-ai/nomic-embed-text-v1.5') n_parameters=92900000 memory_usage_mb=355.0 max_tokens=2048.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/nomic-ai/contrastors' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/nomic-ai/nomic-embed-vision-v1.5' similarity_fn_name=None use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : nvidia/NV-Embed-v2 | Value : name='nvidia/NV-Embed-v2' revision='7604d305b621f14095a1aa23d351674c2859553a' release_date='2024-09-09' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.instruct_wrapper.InstructSentenceTransformerWrapper'>, model_name='nvidia/NV-Embed-v2', revision='7604d305b621f14095a1aa23d351674c2859553a', instruction_template=<function instruction_template at 0x7f5a64def6a0>, trust_remote_code=True, max_seq_length=32768, padding_side='right', add_eos_token=True) n_parameters=7850000000 memory_usage_mb=14975.0 max_tokens=32768.0 embed_dim=4096 license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/nvidia/NV-Embed-v2' similarity_fn_name='cosine' use_instructions=True training_datasets={'ArguAna': ['train'], 'ArguAna-PL': ['train'], 'ArguAna-NL': ['train'], 'NanoArguAnaRetrieval': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'ArxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'StackExchangeClustering': ['train'], 'StackExchangeClustering.v2': ['train'], 'StackExchangeClusteringP2P': ['train'], 'StackExchangeClusteringP2P.v2': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClusteringP2P.v2': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : nvidia/NV-Embed-v1 | Value : name='nvidia/NV-Embed-v1' revision='570834afd5fef5bf3a3c2311a2b6e0a66f6f4f2c' release_date='2024-09-13' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.instruct_wrapper.InstructSentenceTransformerWrapper'>, model_name='nvidia/NV-Embed-v1', revision='7604d305b621f14095a1aa23d351674c2859553a', instruction_template=<function instruction_template at 0x7f5a64def6a0>, trust_remote_code=True, max_seq_length=32768, padding_side='right', add_eos_token=True) n_parameters=7850000000 memory_usage_mb=29945.0 max_tokens=32768.0 embed_dim=4096 license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/nvidia/NV-Embed-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'ArguAna': ['train'], 'ArguAna-PL': ['train'], 'ArguAna-NL': ['train'], 'NanoArguAnaRetrieval': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'ArxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'StackExchangeClustering': ['train'], 'StackExchangeClustering.v2': ['train'], 'StackExchangeClusteringP2P': ['train'], 'StackExchangeClusteringP2P.v2': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClusteringP2P.v2': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : openai/text-embedding-3-small | Value : name='openai/text-embedding-3-small' revision='2' release_date='2024-01-25' languages=None loader=functools.partial(<class 'mteb.models.openai_models.OpenAIWrapper'>, model_name='text-embedding-3-small', tokenizer_name='cl100k_base', max_tokens=8191) n_parameters=None memory_usage_mb=None max_tokens=8191.0 embed_dim=1536 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://openai.com/index/new-embedding-models-and-api-updates/' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : openai/text-embedding-3-large | Value : name='openai/text-embedding-3-large' revision='2' release_date='2024-01-25' languages=None loader=functools.partial(<class 'mteb.models.openai_models.OpenAIWrapper'>, model_name='text-embedding-3-large', tokenizer_name='cl100k_base', max_tokens=8191) n_parameters=None memory_usage_mb=None max_tokens=8191.0 embed_dim=3072 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://openai.com/index/new-embedding-models-and-api-updates/' similarity_fn_name=None use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : openai/text-embedding-ada-002 | Value : name='openai/text-embedding-ada-002' revision='2' release_date='2022-12-15' languages=None loader=functools.partial(<class 'mteb.models.openai_models.OpenAIWrapper'>, model_name='text-embedding-ada-002', tokenizer_name='cl100k_base', max_tokens=8191) n_parameters=None memory_usage_mb=None max_tokens=8191.0 embed_dim=1536 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://openai.com/index/new-and-improved-embedding-model/' similarity_fn_name=None use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K | Value : name='laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K' revision='84c9828e63dc9a9351d1fe637c346d4c1c4db341' release_date='2023-04-26' languages=['eng_Latn'] loader=functools.partial(<function openclip_loader at 0x7f5a64e3eb60>, model_name='laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K') n_parameters=428000000 memory_usage_mb=1633.0 max_tokens=77.0 embed_dim=768 license='mit' open_weights=True public_training_code='https://github.com/mlfoundations/open_clip' public_training_data='https://huggingface.co/datasets/mlfoundations/datacomp_1b' framework=['PyTorch'] reference='https://huggingface.co/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K | Value : name='laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K' revision='f0e2ffa09cbadab3db6a261ec1ec56407ce42912' release_date='2023-04-26' languages=['eng_Latn'] loader=functools.partial(<function openclip_loader at 0x7f5a64e3eb60>, model_name='laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K') n_parameters=151000000 memory_usage_mb=576.0 max_tokens=77.0 embed_dim=512 license='mit' open_weights=True public_training_code='https://github.com/mlfoundations/open_clip' public_training_data='https://huggingface.co/datasets/mlfoundations/datacomp_1b' framework=['PyTorch'] reference='https://huggingface.co/laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K | Value : name='laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K' revision='d110532e8d4ff91c574ee60a342323f28468b287' release_date='2023-04-26' languages=['eng_Latn'] loader=functools.partial(<function openclip_loader at 0x7f5a64e3eb60>, model_name='laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K') n_parameters=150000000 memory_usage_mb=572.0 max_tokens=77.0 embed_dim=512 license='mit' open_weights=True public_training_code='https://github.com/mlfoundations/open_clip' public_training_data='https://huggingface.co/datasets/mlfoundations/datacomp_1b' framework=['PyTorch'] reference='https://huggingface.co/laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : laion/CLIP-ViT-bigG-14-laion2B-39B-b160k | Value : name='laion/CLIP-ViT-bigG-14-laion2B-39B-b160k' revision='bc7788f151930d91b58474715fdce5524ad9a189' release_date='2023-01-23' languages=['eng_Latn'] loader=functools.partial(<function openclip_loader at 0x7f5a64e3eb60>, model_name='laion/CLIP-ViT-bigG-14-laion2B-39B-b160k') n_parameters=2540000000 memory_usage_mb=9689.0 max_tokens=77.0 embed_dim=1280 license='mit' open_weights=True public_training_code='https://github.com/mlfoundations/open_clip' public_training_data='https://laion.ai/blog/laion-5b/' framework=['PyTorch'] reference='https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : laion/CLIP-ViT-g-14-laion2B-s34B-b88K | Value : name='laion/CLIP-ViT-g-14-laion2B-s34B-b88K' revision='15efd0f6ac0c40c0f9da7becca03c974d7012604' release_date='2023-03-06' languages=['eng_Latn'] loader=functools.partial(<function openclip_loader at 0x7f5a64e3eb60>, model_name='laion/CLIP-ViT-g-14-laion2B-s34B-b88K') n_parameters=1367000000 memory_usage_mb=5215.0 max_tokens=77.0 embed_dim=1024 license='mit' open_weights=True public_training_code='https://github.com/mlfoundations/open_clip' public_training_data='https://laion.ai/blog/laion-5b/' framework=['PyTorch'] reference='https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s34B-b88K' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : laion/CLIP-ViT-H-14-laion2B-s32B-b79K | Value : name='laion/CLIP-ViT-H-14-laion2B-s32B-b79K' revision='de081ac0a0ca8dc9d1533eed1ae884bb8ae1404b' release_date='2022-09-15' languages=['eng_Latn'] loader=functools.partial(<function openclip_loader at 0x7f5a64e3eb60>, model_name='laion/CLIP-ViT-H-14-laion2B-s32B-b79K') n_parameters=986000000 memory_usage_mb=3762.0 max_tokens=77.0 embed_dim=1024 license='mit' open_weights=True public_training_code='https://github.com/mlfoundations/open_clip' public_training_data='https://laion.ai/blog/laion-5b/' framework=['PyTorch'] reference='https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : laion/CLIP-ViT-L-14-laion2B-s32B-b82K | Value : name='laion/CLIP-ViT-L-14-laion2B-s32B-b82K' revision='1627032197142fbe2a7cfec626f4ced3ae60d07a' release_date='2022-09-15' languages=['eng_Latn'] loader=functools.partial(<function openclip_loader at 0x7f5a64e3eb60>, model_name='laion/CLIP-ViT-L-14-laion2B-s32B-b82K') n_parameters=428000000 memory_usage_mb=1631.0 max_tokens=77.0 embed_dim=768 license='mit' open_weights=True public_training_code='https://github.com/mlfoundations/open_clip' public_training_data='https://laion.ai/blog/laion-5b/' framework=['PyTorch'] reference='https://huggingface.co/laion/CLIP-ViT-L-14-laion2B-s32B-b82K' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : laion/CLIP-ViT-B-32-laion2B-s34B-b79K | Value : name='laion/CLIP-ViT-B-32-laion2B-s34B-b79K' revision='08f73555f1b2fb7c82058aebbd492887a94968ef' release_date='2022-09-15' languages=['eng_Latn'] loader=functools.partial(<function openclip_loader at 0x7f5a64e3eb60>, model_name='laion/CLIP-ViT-B-32-laion2B-s34B-b79K') n_parameters=151000000 memory_usage_mb=577.0 max_tokens=77.0 embed_dim=512 license='mit' open_weights=True public_training_code='https://github.com/mlfoundations/open_clip' public_training_data='https://laion.ai/blog/laion-5b/' framework=['PyTorch'] reference='https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : sensenova/piccolo-base-zh | Value : name='sensenova/piccolo-base-zh' revision='47c0a63b8f667c3482e05b2fd45577bb19252196' release_date='2023-09-04' languages=['zho_Hans'] loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sensenova/piccolo-base-zh' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sensenova/piccolo-large-zh-v2 | Value : name='sensenova/piccolo-large-zh-v2' revision='05948c1d889355936bdf9db7d30df57dd78d25a3' release_date='2024-04-22' languages=['zho_Hans'] loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=1024 license='not specified' open_weights=False public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sensenova/piccolo-large-zh-v2' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Alibaba-NLP/gme-Qwen2-VL-2B-Instruct | Value : name='Alibaba-NLP/gme-Qwen2-VL-2B-Instruct' revision='ce765ae71b8cdb208203cd8fb64a170b1b84293a' release_date='2024-12-24' languages=['eng_Latn', 'cmn-Hans'] loader=functools.partial(<class 'mteb.models.gme_v_models.GmeQwen2VL'>, model_name='Alibaba-NLP/gme-Qwen2-VL-2B-Instruct') n_parameters=2210000000 memory_usage_mb=8427.0 max_tokens=32768.0 embed_dim=1536 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/Alibaba-NLP/gme-Qwen2-VL-2B-Instruct' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'FEVER': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : Alibaba-NLP/gme-Qwen2-VL-7B-Instruct | Value : name='Alibaba-NLP/gme-Qwen2-VL-7B-Instruct' revision='477027a6480f8630363be77751f169cc3434b673' release_date='2024-12-24' languages=['eng_Latn', 'cmn-Hans'] loader=functools.partial(<class 'mteb.models.gme_v_models.GmeQwen2VL'>, model_name='Alibaba-NLP/gme-Qwen2-VL-7B-Instruct') n_parameters=8290000000 memory_usage_mb=31629.0 max_tokens=32768.0 embed_dim=3584 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/Alibaba-NLP/gme-Qwen2-VL-2B-Instruct' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQAHardNegatives': ['train'], 'FEVER': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : samaya-ai/promptriever-llama2-7b-v1 | Value : name='samaya-ai/promptriever-llama2-7b-v1' revision='01c7f73d771dfac7d292323805ebc428287df4f9-30b14e3813c0fa45facfd01a594580c3fe5ecf23' release_date='2024-09-15' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3f240> n_parameters=7000000000 memory_usage_mb=27.0 max_tokens=4096.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Tevatron'] reference='https://huggingface.co/samaya-ai/promptriever-llama2-7b-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'samaya-ai/msmarco-w-instructions': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : samaya-ai/promptriever-llama3.1-8b-v1 | Value : name='samaya-ai/promptriever-llama3.1-8b-v1' revision='48d6d0fc4e02fb1269b36940650a1b7233035cbb-2ead22cfb1b0e0c519c371c63c2ab90ffc511b8a' release_date='2024-09-15' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3f2e0> n_parameters=8000000000 memory_usage_mb=31.0 max_tokens=8192.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Tevatron'] reference='https://huggingface.co/samaya-ai/promptriever-llama3.1-8b-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'samaya-ai/msmarco-w-instructions': ['train'], 'mMARCO-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : samaya-ai/promptriever-llama3.1-8b-instruct-v1 | Value : name='samaya-ai/promptriever-llama3.1-8b-instruct-v1' revision='5206a32e0bd3067aef1ce90f5528ade7d866253f-8b677258615625122c2eb7329292b8c402612c21' release_date='2024-09-15' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3f380> n_parameters=8000000000 memory_usage_mb=31.0 max_tokens=8192.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Tevatron'] reference='https://huggingface.co/samaya-ai/promptriever-llama3.1-8b-instruct-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'samaya-ai/msmarco-w-instructions': ['train'], 'mMARCO-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : samaya-ai/promptriever-mistral-v0.1-7b-v1 | Value : name='samaya-ai/promptriever-mistral-v0.1-7b-v1' revision='7231864981174d9bee8c7687c24c8344414eae6b-876d63e49b6115ecb6839893a56298fadee7e8f5' release_date='2024-09-15' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3f420> n_parameters=7000000000 memory_usage_mb=27.0 max_tokens=4096.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Tevatron'] reference='https://huggingface.co/samaya-ai/promptriever-mistral-v0.1-7b-v1' similarity_fn_name='cosine' use_instructions=True training_datasets={'samaya-ai/msmarco-w-instructions': ['train'], 'mMARCO-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Qodo/Qodo-Embed-1-1.5B | Value : name='Qodo/Qodo-Embed-1-1.5B' revision='84bbef079b32e8823ec226d4e9e92902706b0eb6' release_date='2025-02-19' languages=['python-Code', 'c++-Code', 'c#-Code', 'go-Code', 'java-Code', 'Javascript-Code', 'php-Code', 'ruby-Code', 'typescript-Code'] loader=None n_parameters=1780000000 memory_usage_mb=6776.0 max_tokens=32768.0 embed_dim=1536 license='QodoAI-Open-RAIL-M' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Qodo/Qodo-Embed-1-1.5B' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from='Alibaba-NLP/gte-Qwen2-1.5B-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Qodo/Qodo-Embed-1-7B | Value : name='Qodo/Qodo-Embed-1-7B' revision='f9edd9bf7f687c0e832424058e265120f603cd81' release_date='2025-02-24' languages=['python-Code', 'c++-Code', 'c#-Code', 'go-Code', 'java-Code', 'Javascript-Code', 'php-Code', 'ruby-Code', 'typescript-Code'] loader=None n_parameters=7613000000 memory_usage_mb=29040.0 max_tokens=32768.0 embed_dim=3584 license='Qodo-Model' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Qodo/Qodo-Embed-1-7B' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from='Alibaba-NLP/gte-Qwen2-7B-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : prdev/mini-gte | Value : name='prdev/mini-gte' revision='7fbe6f9b4cc42615e0747299f837ad7769025492' release_date='2025-01-28' languages=['eng_Latn'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='prdev/mini-gte', revision='7fbe6f9b4cc42615e0747299f837ad7769025492') n_parameters=66300000 memory_usage_mb=253.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/prdev/mini-gte' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'HotPotQA': ['train'], 'HotPotQAHardNegatives': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train']} adapted_from='distilbert/distilbert-base-uncased' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : castorini/repllama-v1-7b-lora-passage | Value : name='castorini/repllama-v1-7b-lora-passage' revision='01c7f73d771dfac7d292323805ebc428287df4f9-6097554dfe6e7d93e92f55010b678bcca1e233a8' release_date='2023-10-11' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3f060> n_parameters=7000000 memory_usage_mb=27.0 max_tokens=4096.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Tevatron'] reference='https://huggingface.co/samaya-ai/castorini/repllama-v1-7b-lora-passage' similarity_fn_name='cosine' use_instructions=True training_datasets={'Tevatron/msmarco-passage-aug': ['train'], 'mMARCO-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : samaya-ai/RepLLaMA-reproduced | Value : name='samaya-ai/RepLLaMA-reproduced' revision='01c7f73d771dfac7d292323805ebc428287df4f9-ad5c1d0938a1e02954bcafb4d811ba2f34052e71' release_date='2024-09-15' languages=['eng_Latn'] loader=<function _loader.<locals>.loader_inner at 0x7f5a64e3f100> n_parameters=7000000 memory_usage_mb=27.0 max_tokens=4096.0 embed_dim=4096 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch', 'Tevatron'] reference='https://huggingface.co/samaya-ai/RepLLaMA-reproduced' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : castorini/monobert-large-msmarco | Value : name='castorini/monobert-large-msmarco' revision='0a97706f3827389da43b83348d5d18c9d53876fa' release_date='2020-05-28' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_custom.MonoBERTReranker'>, model_name_or_path='castorini/monobert-large-msmarco', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : jinaai/jina-reranker-v2-base-multilingual | Value : name='jinaai/jina-reranker-v2-base-multilingual' revision='126747772a932960028d9f4dc93bd5d9c4869be4' release_date='2024-09-26' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_custom.JinaReranker'>, model_name_or_path='jinaai/jina-reranker-v2-base-multilingual', fp_options='float16') n_parameters=None memory_usage_mb=531.0 max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : BAAI/bge-reranker-v2-m3 | Value : name='BAAI/bge-reranker-v2-m3' revision='953dc6f6f85a1b2dbfca4c34a2796e7dde08d41e' release_date='2024-06-24' languages=['eng_Latn', 'ara_Arab', 'ben_Beng', 'spa_Latn', 'fas_Arab', 'fin_Latn', 'fra_Latn', 'hin_Deva', 'ind_Latn', 'jpn_Jpan', 'kor_Hang', 'rus_Cyrl', 'swa_Latn', 'tel_Telu', 'tha_Thai', 'zho_Hans', 'deu_Latn', 'yor_Latn', 'dan_Latn', 'heb_Hebr', 'hun_Latn', 'ita_Latn', 'khm_Khmr', 'msa_Latn', 'nld_Latn', 'nob_Latn', 'pol_Latn', 'por_Latn', 'swe_Latn', 'tur_Latn', 'vie_Latn', 'zho_Hant'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_custom.BGEReranker'>, model_name_or_path='BAAI/bge-reranker-v2-m3', fp_options='float16') n_parameters=None memory_usage_mb=2166.0 max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets={'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'LeCaRDv2': ['train'], 'CMedQAv1-reranking': ['train'], 'CMedQAv2-reranking': ['train'], 'MrTidyRetrieval': ['train'], 'T2Reranking': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'T2Retrieval': ['train'], 'DuReader': ['train'], 'MMarcoReranking': ['train'], 'CodeSearchNet': ['train']} adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : castorini/monot5-small-msmarco-10k | Value : name='castorini/monot5-small-msmarco-10k' revision='77f8e3f7b1eb1afe353aa21a7c3a2fc8feca702e' release_date='2022-03-28' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.MonoT5Reranker'>, model_name_or_path='castorini/monot5-small-msmarco-10k', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : castorini/monot5-base-msmarco-10k | Value : name='castorini/monot5-base-msmarco-10k' revision='f15657ab3d2a5dd0b9a30c8c0b6a0a73c9cb5884' release_date='2022-03-28' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.MonoT5Reranker'>, model_name_or_path='castorini/monot5-base-msmarco-10k', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : castorini/monot5-large-msmarco-10k | Value : name='castorini/monot5-large-msmarco-10k' revision='48cfad1d8dd587670393f27ee8ec41fde63e3d98' release_date='2022-03-28' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.MonoT5Reranker'>, model_name_or_path='castorini/monot5-large-msmarco-10k', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : castorini/monot5-3b-msmarco-10k | Value : name='castorini/monot5-3b-msmarco-10k' revision='bc0c419a438c81f592f878ce32430a1823f5db6c' release_date='2022-03-28' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.MonoT5Reranker'>, model_name_or_path='castorini/monot5-3b-msmarco-10k', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : google/flan-t5-base | Value : name='google/flan-t5-base' revision='7bcac572ce56db69c1ea7c8af255c5d7c9672fc2' release_date='2022-10-21' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.FLANT5Reranker'>, model_name_or_path='google/flan-t5-base', fp_options='float16') n_parameters=248000000 memory_usage_mb=944.0 max_tokens=None embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=True training_datasets={'svakulenk0/qrecc': ['train'], 'taskmaster2': ['train'], 'djaym7/wiki_dialog': ['train'], 'deepmind/code_contests': ['train'], 'lambada': ['train'], 'gsm8k': ['train'], 'aqua_rat': ['train'], 'esnli': ['train'], 'quasc': ['train'], 'qed': ['train']} adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : google/flan-t5-large | Value : name='google/flan-t5-large' revision='0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a' release_date='2022-10-21' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.FLANT5Reranker'>, model_name_or_path='google/flan-t5-large', fp_options='float16') n_parameters=783000000 memory_usage_mb=2987.0 max_tokens=1024.0 embed_dim=None license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets={'svakulenk0/qrecc': ['train'], 'taskmaster2': ['train'], 'djaym7/wiki_dialog': ['train'], 'deepmind/code_contests': ['train'], 'lambada': ['train'], 'gsm8k': ['train'], 'aqua_rat': ['train'], 'esnli': ['train'], 'quasc': ['train'], 'qed': ['train']} adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : google/flan-t5-xl | Value : name='google/flan-t5-xl' revision='7d6315df2c2fb742f0f5b556879d730926ca9001' release_date='2022-10-21' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.FLANT5Reranker'>, model_name_or_path='google/flan-t5-xl', fp_options='float16') n_parameters=2850000000 memory_usage_mb=10871.0 max_tokens=None embed_dim=2048 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets={'svakulenk0/qrecc': ['train'], 'taskmaster2': ['train'], 'djaym7/wiki_dialog': ['train'], 'deepmind/code_contests': ['train'], 'lambada': ['train'], 'gsm8k': ['train'], 'aqua_rat': ['train'], 'esnli': ['train'], 'quasc': ['train'], 'qed': ['train']} adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : google/flan-t5-xxl | Value : name='google/flan-t5-xxl' revision='ae7c9136adc7555eeccc78cdd960dfd60fb346ce' release_date='2022-10-21' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.FLANT5Reranker'>, model_name_or_path='google/flan-t5-xxl', fp_options='float16') n_parameters=11300000000 memory_usage_mb=42980.0 max_tokens=None embed_dim=4096 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets={'svakulenk0/qrecc': ['train'], 'taskmaster2': ['train'], 'djaym7/wiki_dialog': ['train'], 'deepmind/code_contests': ['train'], 'lambada': ['train'], 'gsm8k': ['train'], 'aqua_rat': ['train'], 'esnli': ['train'], 'quasc': ['train'], 'qed': ['train']} adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : meta-llama/Llama-2-7b-hf | Value : name='meta-llama/Llama-2-7b-hf' revision='01c7f73d771dfac7d292323805ebc428287df4f9' release_date='2023-07-18' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.LlamaReranker'>, model_name_or_path='meta-llama/Llama-2-7b-hf', fp_options='float16') n_parameters=6740000000 memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : meta-llama/Llama-2-7b-chat-hf | Value : name='meta-llama/Llama-2-7b-chat-hf' revision='f5db02db724555f92da89c216ac04704f23d4590' release_date='2023-07-18' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.LlamaReranker'>, model_name_or_path='meta-llama/Llama-2-7b-chat-hf', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : mistralai/Mistral-7B-Instruct-v0.2 | Value : name='mistralai/Mistral-7B-Instruct-v0.2' revision='3ad372fc79158a2148299e3318516c786aeded6c' release_date='2023-12-11' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.MistralReranker'>, model_name_or_path='mistralai/Mistral-7B-Instruct-v0.2', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : jhu-clsp/FollowIR-7B | Value : name='jhu-clsp/FollowIR-7B' revision='4d25d437e38b510c01852070c0731e8f6e1875d1' release_date='2024-04-29' languages=['eng_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.FollowIRReranker'>, model_name_or_path='jhu-clsp/FollowIR-7B', fp_options='float16') n_parameters=7240000000 memory_usage_mb=13813.0 max_tokens=None embed_dim=None license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets={'jhu-clsp/FollowIR-train': ['train']} adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : unicamp-dl/mt5-base-mmarco-v2 | Value : name='unicamp-dl/mt5-base-mmarco-v2' revision='cc0a949b9f21efcaba45c8cabb998ad02ce8d4e7' release_date='2022-01-05' languages=['afr_Latn', 'sqi_Latn', 'amh_Ethi', 'ara_Arab', 'hye_Armn', 'aze_Latn', 'eus_Latn', 'bel_Cyrl', 'ben_Beng', 'bul_Cyrl', 'mya_Mymr', 'cat_Latn', 'ceb_Latn', 'nya_Latn', 'zho_Hans', 'cos_Latn', 'ces_Latn', 'dan_Latn', 'nld_Latn', 'eng_Latn', 'epo_Latn', 'est_Latn', 'fil_Latn', 'fin_Latn', 'fra_Latn', 'glg_Latn', 'kat_Geor', 'deu_Latn', 'ell_Grek', 'guj_Gujr', 'hat_Latn', 'hau_Latn', 'haw_Latn', 'heb_Hebr', 'hin_Deva', 'hmn_Latn', 'hun_Latn', 'isl_Latn', 'ibo_Latn', 'ind_Latn', 'gle_Latn', 'ita_Latn', 'jpn_Jpan', 'jav_Latn', 'kan_Knda', 'kaz_Cyrl', 'khm_Khmr', 'kor_Hang', 'kur_Latn', 'kir_Cyrl', 'lao_Laoo', 'lat_Latn', 'lav_Latn', 'lit_Latn', 'ltz_Latn', 'mkd_Cyrl', 'mlg_Latn', 'msa_Latn', 'mal_Mlym', 'mlt_Latn', 'mri_Latn', 'mar_Deva', 'mon_Cyrl', 'nep_Deva', 'nor_Latn', 'pus_Arab', 'fas_Arab', 'pol_Latn', 'por_Latn', 'pan_Guru', 'ron_Latn', 'rus_Cyrl', 'smo_Latn', 'gla_Latn', 'srp_Cyrl', 'sna_Latn', 'snd_Arab', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sot_Latn', 'spa_Latn', 'sun_Latn', 'swa_Latn', 'swe_Latn', 'tgk_Cyrl', 'tam_Taml', 'tel_Telu', 'tha_Thai', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'uzb_Latn', 'vie_Latn', 'cym_Latn', 'fry_Latn', 'xho_Latn', 'yid_Hebr', 'yor_Latn', 'zul_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.MonoT5Reranker'>, model_name_or_path='unicamp-dl/mt5-base-mmarco-v2', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license='mit' open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets={'msmarco': ['train']} adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : unicamp-dl/mt5-13b-mmarco-100k | Value : name='unicamp-dl/mt5-13b-mmarco-100k' revision='e1a4317e102a525ea9e16745ad21394a4f1bffbc' release_date='2022-11-04' languages=['afr_Latn', 'sqi_Latn', 'amh_Ethi', 'ara_Arab', 'hye_Armn', 'aze_Latn', 'eus_Latn', 'bel_Cyrl', 'ben_Beng', 'bul_Cyrl', 'mya_Mymr', 'cat_Latn', 'ceb_Latn', 'nya_Latn', 'zho_Hans', 'cos_Latn', 'ces_Latn', 'dan_Latn', 'nld_Latn', 'eng_Latn', 'epo_Latn', 'est_Latn', 'fil_Latn', 'fin_Latn', 'fra_Latn', 'glg_Latn', 'kat_Geor', 'deu_Latn', 'ell_Grek', 'guj_Gujr', 'hat_Latn', 'hau_Latn', 'haw_Latn', 'heb_Hebr', 'hin_Deva', 'hmn_Latn', 'hun_Latn', 'isl_Latn', 'ibo_Latn', 'ind_Latn', 'gle_Latn', 'ita_Latn', 'jpn_Jpan', 'jav_Latn', 'kan_Knda', 'kaz_Cyrl', 'khm_Khmr', 'kor_Hang', 'kur_Latn', 'kir_Cyrl', 'lao_Laoo', 'lat_Latn', 'lav_Latn', 'lit_Latn', 'ltz_Latn', 'mkd_Cyrl', 'mlg_Latn', 'msa_Latn', 'mal_Mlym', 'mlt_Latn', 'mri_Latn', 'mar_Deva', 'mon_Cyrl', 'nep_Deva', 'nor_Latn', 'pus_Arab', 'fas_Arab', 'pol_Latn', 'por_Latn', 'pan_Guru', 'ron_Latn', 'rus_Cyrl', 'smo_Latn', 'gla_Latn', 'srp_Cyrl', 'sna_Latn', 'snd_Arab', 'sin_Sinh', 'slk_Latn', 'slv_Latn', 'som_Latn', 'sot_Latn', 'spa_Latn', 'sun_Latn', 'swa_Latn', 'swe_Latn', 'tgk_Cyrl', 'tam_Taml', 'tel_Telu', 'tha_Thai', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'uzb_Latn', 'vie_Latn', 'cym_Latn', 'fry_Latn', 'xho_Latn', 'yid_Hebr', 'yor_Latn', 'zul_Latn'] loader=functools.partial(<function _loader at 0x7f5a64e3f740>, wrapper=<class 'mteb.models.rerankers_monot5_based.MonoT5Reranker'>, model_name_or_path='unicamp-dl/mt5-13b-mmarco-100k', fp_options='float16') n_parameters=None memory_usage_mb=None max_tokens=None embed_dim=None license=None open_weights=True public_training_code=None public_training_data=None framework=['PyTorch'] reference=None similarity_fn_name=None use_instructions=None training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=True modalities=['text']\n",
      "\n",
      "Model Name : cointegrated/rubert-tiny | Value : name='cointegrated/rubert-tiny' revision='5441c5ea8026d4f6d7505ec004845409f1259fb1' release_date='2021-05-24' languages=['rus_Cyrl'] loader=None n_parameters=11900000 memory_usage_mb=45.0 max_tokens=512.0 embed_dim=312 license='mit' open_weights=True public_training_code='https://gist.github.com/avidale/7bc6350f26196918bf339c01261f5c60' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/cointegrated/rubert-tiny' similarity_fn_name='cosine' use_instructions=False training_datasets={'Tatoeba': ['train']} adapted_from='google-bert/bert-base-multilingual-cased' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : cointegrated/rubert-tiny2 | Value : name='cointegrated/rubert-tiny2' revision='dad72b8f77c5eef6995dd3e4691b758ba56b90c3' release_date='2021-10-28' languages=['rus_Cyrl'] loader=None n_parameters=29400000 memory_usage_mb=112.0 max_tokens=2048.0 embed_dim=312 license='mit' open_weights=True public_training_code='https://colab.research.google.com/drive/1mSWfIQ6PIlteLVZ9DKKpcorycgLIKZLf?usp=sharing' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/cointegrated/rubert-tiny2' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from='cointegrated/rubert-tiny' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ai-forever/sbert_large_nlu_ru | Value : name='ai-forever/sbert_large_nlu_ru' revision='af977d5dfa46a3635e29bf0ef383f2df2a08d47a' release_date='2020-11-20' languages=['rus_Cyrl'] loader=None n_parameters=427000000 memory_usage_mb=1629.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ai-forever/sbert_large_nlu_ru' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from='google/bert_uncased_L-12_H-768_A-12' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ai-forever/sbert_large_mt_nlu_ru | Value : name='ai-forever/sbert_large_mt_nlu_ru' revision='05300876c2b83f46d3ddd422a7f17e45cf633bb0' release_date='2021-05-18' languages=['rus_Cyrl'] loader=None n_parameters=427000000 memory_usage_mb=1629.0 max_tokens=512.0 embed_dim=1024 license='Not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ai-forever/sbert_large_mt_nlu_ru' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : deepvk/USER-base | Value : name='deepvk/USER-base' revision='436a489a2087d61aa670b3496a9915f84e46c861' release_date='2024-06-10' languages=['rus_Cyrl'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='deepvk/USER-base', revision='436a489a2087d61aa670b3496a9915f84e46c861', model_prompts={'query': 'query: ', 'passage': 'passage: '}) n_parameters=427000000 memory_usage_mb=473.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/deepvk/USER-base' similarity_fn_name='cosine' use_instructions=True training_datasets={'BibleNLPBitextMining': ['train'], 'TERRa': ['train'], 'MIRACL': ['train'], 'MLSUMClusteringP2P': ['train'], 'MLSUMClusteringP2P.v2': ['train'], 'MLSUMClusteringS2S': ['train'], 'MLSUMClusteringS2S.v2': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='https://huggingface.co/deepvk/deberta-v1-base' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : deepvk/deberta-v1-base | Value : name='deepvk/deberta-v1-base' revision='bdd30b0e19757e6940c92c7aff19e8fc0a60dff4' release_date='2023-02-07' languages=['rus_Cyrl'] loader=None n_parameters=124000000 memory_usage_mb=473.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/deepvk/deberta-v1-base' similarity_fn_name='cosine' use_instructions=False training_datasets={'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'RiaNewsRetrieval': []} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : DeepPavlov/rubert-base-cased | Value : name='DeepPavlov/rubert-base-cased' revision='4036cab694767a299f2b9e6492909664d9414229' release_date='2020-03-04' languages=['rus_Cyrl'] loader=None n_parameters=1280000000 memory_usage_mb=4883.0 max_tokens=512.0 embed_dim=768 license='Not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/DeepPavlov/rubert-base-cased' similarity_fn_name='cosine' use_instructions=False training_datasets={'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': []} adapted_from='google/bert_uncased_L-12_H-768_A-12' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : DeepPavlov/distilrubert-small-cased-conversational | Value : name='DeepPavlov/distilrubert-small-cased-conversational' revision='e348066b4a7279b97138038299bddc6580a9169a' release_date='2022-06-28' languages=['rus_Cyrl'] loader=None n_parameters=107000000 memory_usage_mb=408.0 max_tokens=512.0 embed_dim=768 license='Not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/DeepPavlov/distilrubert-small-cased-conversational' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from='DeepPavlov/distilrubert-base-cased-conversational' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : DeepPavlov/rubert-base-cased-sentence | Value : name='DeepPavlov/rubert-base-cased-sentence' revision='78b5122d6365337dd4114281b0d08cd1edbb3bc8' release_date='2020-03-04' languages=['rus_Cyrl'] loader=None n_parameters=107000000 memory_usage_mb=408.0 max_tokens=512.0 embed_dim=768 license='Not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/DeepPavlov/rubert-base-cased-sentence' similarity_fn_name='cosine' use_instructions=False training_datasets={'XNLI': ['dev']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : cointegrated/LaBSE-en-ru | Value : name='cointegrated/LaBSE-en-ru' revision='cf0714e606d4af551e14ad69a7929cd6b0da7f7e' release_date='2021-06-10' languages=['rus_Cyrl'] loader=None n_parameters=129000000 memory_usage_mb=492.0 max_tokens=512.0 embed_dim=768 license='Not specified' open_weights=True public_training_code='https://colab.research.google.com/drive/1dnPRn0-ugj3vZgSpyCC9sgslM2SuSfHy?usp=sharing' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/cointegrated/LaBSE-en-ru' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from='sentence-transformers/LaBSE' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sergeyzh/rubert-tiny-turbo | Value : name='sergeyzh/rubert-tiny-turbo' revision='8ce0cf757446ce9bb2d5f5a4ac8103c7a1049054' release_date='2024-06-21' languages=['rus_Cyrl'] loader=None n_parameters=29200000 memory_usage_mb=111.0 max_tokens=2048.0 embed_dim=312 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sergeyzh/rubert-tiny-turbo' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from='cointegrated/rubert-tiny2' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sergeyzh/LaBSE-ru-turbo | Value : name='sergeyzh/LaBSE-ru-turbo' revision='1940b046c6b5e125df11722b899130329d0a46da' release_date='2024-06-27' languages=['rus_Cyrl'] loader=None n_parameters=129000000 memory_usage_mb=490.0 max_tokens=512.0 embed_dim=768 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sergeyzh/LaBSE-ru-turbo' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from='cointegrated/LaBSE-en-ru' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ai-forever/ru-en-RoSBERTa | Value : name='ai-forever/ru-en-RoSBERTa' revision='89fb1651989adbb1cfcfdedafd7d102951ad0555' release_date='2024-07-29' languages=['rus_Cyrl'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='ai-forever/ru-en-RoSBERTa', revision='89fb1651989adbb1cfcfdedafd7d102951ad0555', model_prompts={'Classification': 'classification: ', 'MultilabelClassification': 'classification: ', 'Clustering': 'clustering: ', 'PairClassification': 'classification: ', 'Reranking': 'classification: ', 'Reranking-query': 'search_query: ', 'Reranking-passage': 'search_document: ', 'STS': 'classification: ', 'Summarization': 'classification: ', 'query': 'search_query: ', 'passage': 'search_document: ', 'HeadlineClassification': 'clustering: ', 'InappropriatenessClassification': 'clustering: ', 'MassiveScenarioClassification': 'clustering: ', 'RuSciBenchGRNTIClassification': 'clustering: ', 'RuSciBenchOECDClassification': 'clustering: ', 'SensitiveTopicsClassification': 'clustering: ', 'STS22': 'clustering: '}) n_parameters=404000000 memory_usage_mb=1540.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ai-forever/ru-en-RoSBERTa' similarity_fn_name='cosine' use_instructions=True training_datasets={'XNLI': [], 'XNLIV2': [], 'LanguageClassification': [], 'MIRACLReranking': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MrTidyRetrieval': ['train']} adapted_from='ai-forever/ruRoberta-large' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ai-forever/FRIDA | Value : name='ai-forever/FRIDA' revision='7292217af9a9e6dbf07048f76b434ad1e2aa8b76' release_date='2024-12-29' languages=['rus_Cyrl'] loader=functools.partial(<function sentence_transformers_loader at 0x7f5a67997920>, model_name='ai-forever/FRIDA', revision='7292217af9a9e6dbf07048f76b434ad1e2aa8b76', model_prompts={'Classification': 'categorize: ', 'MultilabelClassification': 'categorize: ', 'Clustering': 'categorize_topic: ', 'PairClassification': 'paraphrase: ', 'Reranking': 'paraphrase: ', 'Reranking-query': 'search_query: ', 'Reranking-passage': 'search_document: ', 'STS': 'paraphrase: ', 'Summarization': 'categorize: ', 'query': 'search_query: ', 'passage': 'search_document: ', 'CEDRClassification': 'categorize_sentiment: ', 'GeoreviewClassification': 'categorize_sentiment: ', 'HeadlineClassification': 'categorize_topic: ', 'InappropriatenessClassification': 'categorize_topic: ', 'KinopoiskClassification': 'categorize_sentiment: ', 'MassiveIntentClassification': 'paraphrase: ', 'MassiveScenarioClassification': 'paraphrase: ', 'RuReviewsClassification': 'categorize_sentiment: ', 'RuSciBenchGRNTIClassification': 'categorize_topic: ', 'RuSciBenchOECDClassification': 'categorize_topic: ', 'SensitiveTopicsClassification': 'categorize_topic: ', 'TERRa': 'categorize_entailment: ', 'RiaNewsRetrieval': 'categorize: '}) n_parameters=823000000 memory_usage_mb=3141.0 max_tokens=512.0 embed_dim=1536 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ai-forever/FRIDA' similarity_fn_name='cosine' use_instructions=True training_datasets={'MIRACLReranking': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MrTidyRetrieval': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'RUParaPhraserSTS': ['train'], 'AmazonCounterfactualClassification': ['train'], 'AmazonPolarityClassification': ['train'], 'AmazonReviewsClassification': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'ArxivClusteringP2P': ['train'], 'Banking77Classification': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringP2P': ['train'], 'CEDRClassification': ['train'], 'DBpediaClassification': ['train'], 'EmotionClassification': ['train'], 'FinancialPhrasebankClassification': ['train'], 'FrenkEnClassification': ['train'], 'GeoreviewClassification': ['train'], 'GeoreviewClusteringP2P': ['train'], 'HeadlineClassification': ['train'], 'ImdbClassification': ['train'], 'InappropriatenessClassification': ['train'], 'KinopoiskClassification': ['train'], 'MasakhaNEWSClassification': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringP2P': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train'], 'MultiHateClassification': ['train'], 'MultilingualSentimentClassification': ['train'], 'NewsClassification': ['train'], 'NusaX-senti': ['train'], 'PoemSentimentClassification': ['train'], 'RuReviewsClassification': ['train'], 'RuSciBenchGRNTIClassification': ['train'], 'RuSciBenchOECDClassification': ['train'], 'SensitiveTopicsClassification': ['train'], 'SIB200Classification': ['train'], 'ToxicChatClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'TweetTopicSingleClassification': ['train'], 'YahooAnswersTopicsClassification': ['train'], 'YelpReviewFullClassification': ['train'], 'RedditClustering': [], 'RedditClusteringP2P': [], 'RedditClustering.v2': [], 'CodeSearchNetCCRetrieval': [], 'COIRCodeSearchNetRetrieval': [], 'StackExchangeClustering.v2': [], 'StackExchangeClusteringP2P.v2': [], 'WikipediaRetrievalMultilingual': [], 'WikipediaRerankingMultilingual': [], 'QuoraRetrieval': [], 'NanoQuoraRetrieval': [], 'Quora-NL': []} adapted_from='ai-forever/FRED-T5-1.7B' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : ai-sage/Giga-Embeddings-instruct | Value : name='ai-sage/Giga-Embeddings-instruct' revision='646f5ff3587e74a18141c8d6b60d1cffd5897b92' release_date='2024-12-13' languages=['eng_Latn', 'rus_Cyrl'] loader=functools.partial(<class 'mteb.models.instruct_wrapper.InstructSentenceTransformerWrapper'>, model_name='ai-sage/Giga-Embeddings-instruct', revision='646f5ff3587e74a18141c8d6b60d1cffd5897b92', trust_remote_code=True, instruction_template='Instruct: {instruction}\\nQuery: ', apply_instruction_to_passages=False, model_kwargs={'torch_dtype': torch.bfloat16}) n_parameters=2530000000 memory_usage_mb=9649.0 max_tokens=32768.0 embed_dim=2048 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/ai-sage/Giga-Embeddings-instruct' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Salesforce/SFR-Embedding-2_R | Value : name='Salesforce/SFR-Embedding-2_R' revision='91762139d94ed4371a9fa31db5551272e0b83818' release_date='2024-06-14' languages=['eng_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='Salesforce/SFR-Embedding-2_R', instruction_template=<function instruction_template at 0x7f5a64a38400>, attn='cccc', pooling_method='lasttoken', mode='embedding', torch_dtype='auto', normalized=True) n_parameters=7110000000 memory_usage_mb=13563.0 max_tokens=32768.0 embed_dim=4096 license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Salesforce/SFR-Embedding-2_R' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'STSBenchmark': ['train']} adapted_from='intfloat/e5-mistral-7b-instruct' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Salesforce/SFR-Embedding-Code-2B_R | Value : name='Salesforce/SFR-Embedding-Code-2B_R' revision='c73d8631a005876ed5abde34db514b1fb6566973' release_date='2025-01-17' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.instruct_wrapper.InstructSentenceTransformerWrapper'>, model_name='Salesforce/SFR-Embedding-Code-2B_R', instruction_template=<function instruction_template at 0x7f5a64a38400>, attn='cccc', pooling_method='lasttoken', mode='embedding', torch_dtype='auto', normalized=True) n_parameters=2610000000 memory_usage_mb=4986.0 max_tokens=8192.0 embed_dim=2304 license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Salesforce/SFR-Embedding-Code-2B_R' similarity_fn_name='cosine' use_instructions=True training_datasets=None adapted_from='google/gemma-2-2b-it' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : Salesforce/SFR-Embedding-Mistral | Value : name='Salesforce/SFR-Embedding-Mistral' revision='938c560d1c236aa563b2dbdf084f28ab28bccb11' release_date='2024-01-24' languages=['eng_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='Salesforce/SFR-Embedding-Mistral', instruction_template=<function instruction_template at 0x7f5a64a38400>, attn='cccc', pooling_method='lasttoken', mode='embedding', torch_dtype='auto', normalized=True) n_parameters=7110000000 memory_usage_mb=13563.0 max_tokens=32768.0 embed_dim=4096 license='cc-by-nc-4.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/Salesforce/SFR-Embedding-Mistral' similarity_fn_name='cosine' use_instructions=True training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVERHardNegatives': ['train'], 'FEVER-NL': ['train'], 'HotpotQA': ['train'], 'HotpotQAHardNegatives': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'STSBenchmark': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/all-MiniLM-L6-v2 | Value : name='sentence-transformers/all-MiniLM-L6-v2' revision='8b3219a92973c328a8e22fadcfa821b5dc75636a' release_date='2021-08-30' languages=['eng-Latn'] loader=None n_parameters=22700000 memory_usage_mb=87.0 max_tokens=256.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/all-MiniLM-L12-v2 | Value : name='sentence-transformers/all-MiniLM-L12-v2' revision='364dd28d28dcd3359b537f3cf1f5348ba679da62' release_date='2021-08-30' languages=['eng-Latn'] loader=None n_parameters=33400000 memory_usage_mb=127.0 max_tokens=256.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 | Value : name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2' revision='bf3bf13ab40c3157080a7ab344c831b9ad18b5eb' release_date='2019-11-01' languages=['ara_Arab', 'bul_Cyrl', 'cat_Latn', 'ces_Latn', 'dan_Latn', 'deu_Latn', 'ell_Grek', 'eng_Latn', 'spa_Latn', 'est_Latn', 'fas_Arab', 'fin_Latn', 'fra_Latn', 'fra_Latn', 'glg_Latn', 'guj_Gujr', 'heb_Hebr', 'hin_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Armn', 'ind_Latn', 'ita_Latn', 'jpn_Jpan', 'kat_Geor', 'kor_Hang', 'kur_Arab', 'lit_Latn', 'lav_Latn', 'mkd_Cyrl', 'mon_Cyrl', 'mar_Deva', 'msa_Latn', 'mya_Mymr', 'nob_Latn', 'nld_Latn', 'pol_Latn', 'por_Latn', 'por_Latn', 'ron_Latn', 'rus_Cyrl', 'slk_Latn', 'slv_Latn', 'sqi_Latn', 'srp_Cyrl', 'swe_Latn', 'tha_Thai', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'vie_Latn', 'zho_Hans', 'zho_Hant'] loader=None n_parameters=118000000 memory_usage_mb=449.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/paraphrase-multilingual-mpnet-base-v2 | Value : name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2' revision='79f2382ceacceacdf38563d7c5d16b9ff8d725d6' release_date='2019-11-01' languages=['ara_Arab', 'bul_Cyrl', 'cat_Latn', 'ces_Latn', 'dan_Latn', 'deu_Latn', 'ell_Grek', 'eng_Latn', 'spa_Latn', 'est_Latn', 'fas_Arab', 'fin_Latn', 'fra_Latn', 'fra_Latn', 'glg_Latn', 'guj_Gujr', 'heb_Hebr', 'hin_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Armn', 'ind_Latn', 'ita_Latn', 'jpn_Jpan', 'kat_Geor', 'kor_Hang', 'kur_Arab', 'lit_Latn', 'lav_Latn', 'mkd_Cyrl', 'mon_Cyrl', 'mar_Deva', 'msa_Latn', 'mya_Mymr', 'nob_Latn', 'nld_Latn', 'pol_Latn', 'por_Latn', 'por_Latn', 'ron_Latn', 'rus_Cyrl', 'slk_Latn', 'slv_Latn', 'sqi_Latn', 'srp_Cyrl', 'swe_Latn', 'tha_Thai', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'vie_Latn', 'zho_Hans', 'zho_Hant'] loader=None n_parameters=278000000 memory_usage_mb=1061.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/LaBSE | Value : name='sentence-transformers/LaBSE' revision='e34fab64a3011d2176c99545a93d5cbddc9a91b7' release_date='2019-11-01' languages=['ara_Arab', 'bul_Cyrl', 'cat_Latn', 'ces_Latn', 'dan_Latn', 'deu_Latn', 'ell_Grek', 'eng_Latn', 'spa_Latn', 'est_Latn', 'fas_Arab', 'fin_Latn', 'fra_Latn', 'fra_Latn', 'glg_Latn', 'guj_Gujr', 'heb_Hebr', 'hin_Deva', 'hrv_Latn', 'hun_Latn', 'hye_Armn', 'ind_Latn', 'ita_Latn', 'jpn_Jpan', 'kat_Geor', 'kor_Hang', 'kur_Arab', 'lit_Latn', 'lav_Latn', 'mkd_Cyrl', 'mon_Cyrl', 'mar_Deva', 'msa_Latn', 'mya_Mymr', 'nob_Latn', 'nld_Latn', 'pol_Latn', 'por_Latn', 'por_Latn', 'ron_Latn', 'rus_Cyrl', 'slk_Latn', 'slv_Latn', 'sqi_Latn', 'srp_Cyrl', 'swe_Latn', 'tha_Thai', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'vie_Latn', 'zho_Hans', 'zho_Hant'] loader=None n_parameters=471000000 memory_usage_mb=1796.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://www.kaggle.com/models/google/labse/tensorFlow2/labse/2?tfhub-redirect=true' public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/LaBSE' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformer/multi-qa-MiniLM-L6-cos-v1 | Value : name='sentence-transformer/multi-qa-MiniLM-L6-cos-v1' revision='b207367332321f8e44f96e224ef15bc607f4dbf0' release_date='2021-08-30' languages=['eng-Latn'] loader=None n_parameters=22700000 memory_usage_mb=87.0 max_tokens=512.0 embed_dim=384 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from='nreimers/MiniLM-L6-H384-uncased' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/all-mpnet-base-v2 | Value : name='sentence-transformers/all-mpnet-base-v2' revision='9a3225965996d404b775526de6dbfe85d3368642' release_date='2021-08-30' languages=['eng-Latn'] loader=None n_parameters=109000000 memory_usage_mb=418.0 max_tokens=384.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/all-mpnet-base-v2' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/static-similarity-mrl-multilingual-v1 | Value : name='sentence-transformers/static-similarity-mrl-multilingual-v1' revision='7264ea07c5365a11d7e6d87dbb6195889a13054f' release_date='2025-01-15' languages=['eng_Latn', 'ara_Arab', 'bul_Cyrl', 'cat_Latn', 'ces_Latn', 'dan_Latn', 'deu_Latn', 'ell_Grek', 'spa_Latn', 'est_Latn', 'fas_Arab', 'fin_Latn', 'fra_Latn', 'glg_Latn', 'guj_Gujr', 'heb_Hebr', 'hin_Deva', 'hun_Latn', 'hye_Armn', 'ind_Latn', 'ita_Latn', 'jpn_Jpan', 'kat_Geor', 'kor_Hang', 'kur_Latn', 'lit_Latn', 'lav_Latn', 'mkd_Cyrl', 'mon_Cyrl', 'mar_Deva', 'mal_Mlym', 'mya_Mymr', 'nob_Latn', 'nld_Latn', 'pol_Latn', 'por_Latn', 'ron_Latn', 'rus_Cyrl', 'slk_Latn', 'slv_Latn', 'sqi_Latn', 'srp_Cyrl', 'swe_Latn', 'tha_Thai', 'tur_Latn', 'ukr_Cyrl', 'urd_Arab', 'vie_Latn', 'zho_Hans'] loader=functools.partial(<class 'mteb.models.sentence_transformer_wrapper.SentenceTransformerWrapper'>, model='sentence-transformers/static-similarity-mrl-multilingual-v1', revision='7264ea07c5365a11d7e6d87dbb6195889a13054f', device='cpu') n_parameters=108420096 memory_usage_mb=413.0 max_tokens=None embed_dim=1024 license='apache-2.0' open_weights=True public_training_code='https://huggingface.co/blog/static-embeddings' public_training_data='https://huggingface.co/collections/sentence-transformers/embedding-model-datasets-6644d7a3673a511914aa7552' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/static-similarity-mrl-multilingual-v1' similarity_fn_name='cosine' use_instructions=False training_datasets={'TatoebaBitextMining': [], 'StackExchangeClustering.v2': [], 'StackExchangeClusteringP2P.v2': [], 'QuoraRetrieval': [], 'NanoQuoraRetrieval': [], 'Quora-NL': []} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/static-retrieval-mrl-en-v1 | Value : name='sentence-transformers/static-retrieval-mrl-en-v1' revision='f60985c706f192d45d218078e49e5a8b6f15283a' release_date='2025-01-15' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.sentence_transformer_wrapper.SentenceTransformerWrapper'>, model='sentence-transformers/static-retrieval-mrl-en-v1', revision='f60985c706f192d45d218078e49e5a8b6f15283a', device='cpu') n_parameters=31254528 memory_usage_mb=119.0 max_tokens=None embed_dim=1024 license='apache-2.0' open_weights=True public_training_code='https://huggingface.co/blog/static-embeddings' public_training_data='https://huggingface.co/collections/sentence-transformers/embedding-model-datasets-6644d7a3673a511914aa7552' framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/static-retrieval-mrl-en-v1' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MultiLongDocRetrieval': ['train'], 'MrTidyRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : keeeeenw/MicroLlama-text-embedding | Value : name='keeeeenw/MicroLlama-text-embedding' revision='98f70f14cdf12d7ea217ed2fd4e808b0195f1e7e' release_date='2024-11-10' languages=['eng-Latn'] loader=None n_parameters=272000000 memory_usage_mb=1037.0 max_tokens=2048.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/keeeeenw/MicroLlama-text-embedding' similarity_fn_name='cosine' use_instructions=False training_datasets={'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/sentence-t5-base | Value : name='sentence-transformers/sentence-t5-base' revision='50c53e206f8b01c9621484a3c0aafce4e55efebf' release_date='2022-02-09' languages=['eng-Latn'] loader=None n_parameters=110000000 memory_usage_mb=209.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/sentence-t5-base' similarity_fn_name='cosine' use_instructions=False training_datasets={'SNLI': ['train'], 'Community QA': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/sentence-t5-large | Value : name='sentence-transformers/sentence-t5-large' revision='1fc08ea477205aa54a3e5b13f0971ae16b86410a' release_date='2022-02-09' languages=['eng-Latn'] loader=None n_parameters=335000000 memory_usage_mb=639.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/sentence-t5-large' similarity_fn_name='cosine' use_instructions=False training_datasets={'SNLI': ['train'], 'Community QA': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/sentence-t5-xl | Value : name='sentence-transformers/sentence-t5-xl' revision='2965d31b368fb14117688e0bde77cbd720e91f53' release_date='2024-03-27' languages=['eng-Latn'] loader=None n_parameters=3000000000 memory_usage_mb=2367.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/sentence-t5-xl' similarity_fn_name='cosine' use_instructions=False training_datasets={'SNLI': ['train'], 'Community QA': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/sentence-t5-xxl | Value : name='sentence-transformers/sentence-t5-xxl' revision='4d122282ba80e807e9e6eb8c358269e92796365d' release_date='2024-03-27' languages=['eng-Latn'] loader=None n_parameters=11000000000 memory_usage_mb=9279.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/sentence-t5-xxl' similarity_fn_name='cosine' use_instructions=False training_datasets={'SNLI': ['train'], 'Community QA': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/gtr-t5-large | Value : name='sentence-transformers/gtr-t5-large' revision='a2c8ac47f998531948d4cbe32a0b577a7037a5e3' release_date='2022-02-09' languages=['eng-Latn'] loader=None n_parameters=335000000 memory_usage_mb=639.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/gtr-t5-large' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'Community QA': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/gtr-t5-xl | Value : name='sentence-transformers/gtr-t5-xl' revision='23a8d667a1ad2578af181ce762867003c498d1bf' release_date='2022-02-09' languages=['eng-Latn'] loader=None n_parameters=1240000000 memory_usage_mb=2367.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/gtr-t5-xl' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'Community QA': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/gtr-t5-xxl | Value : name='sentence-transformers/gtr-t5-xxl' revision='73f2a9156a3dcc2194dfdb2bf201cd7d17e17884' release_date='2022-02-09' languages=['eng-Latn'] loader=None n_parameters=4860000000 memory_usage_mb=9279.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/gtr-t5-xxl' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'Community QA': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sentence-transformers/gtr-t5-base | Value : name='sentence-transformers/gtr-t5-base' revision='7027e9594267928589816394bdd295273ddc0739' release_date='2022-02-09' languages=['eng-Latn'] loader=None n_parameters=110000000 memory_usage_mb=209.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sentence-transformers/gtr-t5-base' similarity_fn_name='cosine' use_instructions=False training_datasets={'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQ-NL': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'Community QA': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : google/siglip-so400m-patch14-224 | Value : name='google/siglip-so400m-patch14-224' revision='d04cf29fca7b6374f74d8bea1969314492266b5e' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-so400m-patch14-224') n_parameters=877000000 memory_usage_mb=3347.0 max_tokens=16.0 embed_dim=1152 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-so400m-patch14-224' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-so400m-patch14-384 | Value : name='google/siglip-so400m-patch14-384' revision='9fdffc58afc957d1a03a25b10dba0329ab15c2a3' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-so400m-patch14-384') n_parameters=878000000 memory_usage_mb=3349.0 max_tokens=64.0 embed_dim=1152 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-so400m-patch14-384' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-so400m-patch16-256-i18n | Value : name='google/siglip-so400m-patch16-256-i18n' revision='365d321c0cfdea96bc28e3a29787a11a062681a1' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-so400m-patch16-256-i18n') n_parameters=1130000000 memory_usage_mb=4306.0 max_tokens=64.0 embed_dim=1152 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-so400m-patch16-256-i18n' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-base-patch16-256-multilingual | Value : name='google/siglip-base-patch16-256-multilingual' revision='8952a4eafcde3cb7ab46b1dd629b33f8784ca9c6' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-base-patch16-256-multilingual') n_parameters=371000000 memory_usage_mb=1414.0 max_tokens=64.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-base-patch16-256-multilingual' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-base-patch16-256 | Value : name='google/siglip-base-patch16-256' revision='b078df89e446d623010d890864d4207fe6399f61' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-base-patch16-256') n_parameters=203000000 memory_usage_mb=775.0 max_tokens=64.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-base-patch16-256' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-base-patch16-512 | Value : name='google/siglip-base-patch16-512' revision='753a949581523b60257d93e18391e8c27f72eb22' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-base-patch16-512') n_parameters=204000000 memory_usage_mb=777.0 max_tokens=64.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-base-patch16-512' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-base-patch16-384 | Value : name='google/siglip-base-patch16-384' revision='41aec1c83b32e0a6fca20ad88ba058aa5b5ea394' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-base-patch16-384') n_parameters=203000000 memory_usage_mb=776.0 max_tokens=64.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-base-patch16-384' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-base-patch16-224 | Value : name='google/siglip-base-patch16-224' revision='7fd15f0689c79d79e38b1c2e2e2370a7bf2761ed' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-base-patch16-224') n_parameters=203000000 memory_usage_mb=775.0 max_tokens=64.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-base-patch16-224' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-large-patch16-256 | Value : name='google/siglip-large-patch16-256' revision='d0da9f876e7d66b4e250cd2450c3ba2ce735e447' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-large-patch16-256') n_parameters=652000000 memory_usage_mb=2488.0 max_tokens=64.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-large-patch16-256' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : google/siglip-large-patch16-384 | Value : name='google/siglip-large-patch16-384' revision='ce005573a40965dfd21fd937fbdeeebf2439fc35' release_date='2024-01-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.siglip_models.SiglipModelWrapper'>, model_name='google/siglip-large-patch16-384') n_parameters=652000000 memory_usage_mb=2489.0 max_tokens=64.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code='https://github.com/google-research/big_vision/blob/main/big_vision/trainers/proj/image_text/siglip.py' public_training_data=None framework=['PyTorch'] reference='https://huggingface.co/google/siglip-large-patch16-384' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : BAAI/bge-visualized-base | Value : name='BAAI/bge-visualized-base' revision='98db10b10d22620010d06f11733346e1c98c34aa' release_date='2024-06-06' languages=['eng_Latn'] loader=functools.partial(<function vista_loader at 0x7f5a64a39440>, model_name_bge='BAAI/bge-base-en-v1.5', model_weight='visualized_base_en_V1.5.pth', image_tokens_num=196) n_parameters=196000000 memory_usage_mb=748.0 max_tokens=77.0 embed_dim=768 license=None open_weights=True public_training_code=None public_training_data='https://huggingface.co/datasets/JUNJIE99/VISTA_S2' framework=['PyTorch'] reference='https://huggingface.co/BAAI/bge-visualized' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : BAAI/bge-visualized-m3 | Value : name='BAAI/bge-visualized-m3' revision='98db10b10d22620010d06f11733346e1c98c34aa' release_date='2024-06-06' languages=['eng_Latn'] loader=functools.partial(<function vista_loader at 0x7f5a64a39440>, model_name_bge='BAAI/bge-m3', model_weight='visualized_m3.pth', image_tokens_num=256) n_parameters=None memory_usage_mb=None max_tokens=77.0 embed_dim=1024 license=None open_weights=True public_training_code=None public_training_data='https://huggingface.co/datasets/JUNJIE99/VISTA_S2' framework=['PyTorch'] reference='https://huggingface.co/BAAI/bge-visualized' similarity_fn_name=None use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : TIGER-Lab/VLM2Vec-LoRA | Value : name='TIGER-Lab/VLM2Vec-LoRA' revision='7403b6327958071c1e33c822c7453adadccc7298' release_date='2024-10-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.vlm2vec_models.VLM2VecWrapper'>, model_name='TIGER-Lab/VLM2Vec-LoRA') n_parameters=None memory_usage_mb=None max_tokens=131072.0 embed_dim=3072 license='apache-2.0' open_weights=True public_training_code='https://github.com/TIGER-AI-Lab/VLM2Vec' public_training_data='https://huggingface.co/datasets/TIGER-Lab/MMEB-train' framework=['PyTorch'] reference='https://huggingface.co/TIGER-Lab/VLM2Vec-LoRA' similarity_fn_name=None use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : TIGER-Lab/VLM2Vec-Full | Value : name='TIGER-Lab/VLM2Vec-Full' revision='e9afa98002097ac2471827ba23ea1f2ddd229480' release_date='2024-10-08' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.vlm2vec_models.VLM2VecWrapper'>, model_name='TIGER-Lab/VLM2Vec-Full') n_parameters=4150000000 memory_usage_mb=7909.0 max_tokens=131072.0 embed_dim=3072 license='apache-2.0' open_weights=True public_training_code='https://github.com/TIGER-AI-Lab/VLM2Vec' public_training_data='https://huggingface.co/TIGER-Lab/VLM2Vec-Full' framework=['PyTorch'] reference='https://huggingface.co/TIGER-Lab/VLM2Vec-Full' similarity_fn_name=None use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : voyageai/voyage-multimodal-3 | Value : name='voyageai/voyage-multimodal-3' revision='1' release_date='2024-11-10' languages=[] loader=functools.partial(<function voyage_v_loader at 0x7f5a64a3a2a0>, model_name='voyage-multimodal-3') n_parameters=None memory_usage_mb=None max_tokens=32768.0 embed_dim=1024 license='mit' open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://huggingface.co/voyageai/voyage-multimodal-3' similarity_fn_name='cosine' use_instructions=None training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['image', 'text']\n",
      "\n",
      "Model Name : dunzhang/stella_en_400M_v5 | Value : name='dunzhang/stella_en_400M_v5' revision='1bb50bc7bb726810eac2140e62155b88b0df198f' release_date='2024-07-12' languages=['eng_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='dunzhang/stella_en_400M_v5', attn='cccc', pooling_method='lasttoken', mode='embedding', torch_dtype='auto') n_parameters=435000000 memory_usage_mb=1660.0 max_tokens=8192.0 embed_dim=4096 license='mit' open_weights=True public_training_code='https://github.com/NovaSearch-Team/RAG-Retrieval/blob/c40f4638b705eb77d88305d2056901ed550f9f4b/rag_retrieval/train/embedding/README.md' public_training_data=None framework=['Sentence Transformers', 'PyTorch', 'GritLM'] reference='https://huggingface.co/dunzhang/stella_en_400M_v5' similarity_fn_name='cosine' use_instructions=True training_datasets={'ArguAna': ['train'], 'ArguAna-PL': ['train'], 'ArguAna-NL': ['train'], 'NanoArguAnaRetrieval': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'ArxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'StackExchangeClustering': ['train'], 'StackExchangeClustering.v2': ['train'], 'StackExchangeClusteringP2P': ['train'], 'StackExchangeClusteringP2P.v2': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClusteringP2P.v2': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : dunzhang/stella_en_1.5B_v5 | Value : name='dunzhang/stella_en_1.5B_v5' revision='d03be74b361d4eb24f42a2fe5bd2e29917df4604' release_date='2024-07-12' languages=['eng_Latn'] loader=functools.partial(<function instruct_wrapper at 0x7f5a67852980>, model_name_or_path='dunzhang/stella_en_1.5B_v5', attn='cccc', pooling_method='lasttoken', mode='embedding', torch_dtype='auto') n_parameters=1540000000 memory_usage_mb=5887.0 max_tokens=131072.0 embed_dim=8960 license='mit' open_weights=True public_training_code='https://github.com/NovaSearch-Team/RAG-Retrieval/blob/c40f4638b705eb77d88305d2056901ed550f9f4b/rag_retrieval/train/embedding/README.md' public_training_data=None framework=['Sentence Transformers', 'PyTorch', 'GritLM'] reference='https://huggingface.co/dunzhang/stella_en_1.5B_v5' similarity_fn_name='cosine' use_instructions=True training_datasets={'ArguAna': ['train'], 'ArguAna-PL': ['train'], 'ArguAna-NL': ['train'], 'NanoArguAnaRetrieval': ['train'], 'HotpotQA': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'NQ': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'FEVER': ['train'], 'FEVER-NL': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FiQA2018': ['train'], 'FiQA2018-NL': ['train'], 'STS12': ['train'], 'STS22': ['train'], 'AmazonReviewsClassification': ['train'], 'AmazonCounterfactualClassification': ['train'], 'Banking77Classification': ['train'], 'EmotionClassification': ['train'], 'ImdbClassification': ['train'], 'MTOPIntentClassification': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'ArxivClusteringS2S': ['train'], 'BiorxivClusteringP2P': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringS2S': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'TwentyNewsgroupsClustering': ['train'], 'TwentyNewsgroupsClustering.v2': ['train'], 'StackExchangeClustering': ['train'], 'StackExchangeClustering.v2': ['train'], 'StackExchangeClusteringP2P': ['train'], 'StackExchangeClusteringP2P.v2': ['train'], 'RedditClustering': ['train'], 'RedditClustering.v2': ['train'], 'RedditClusteringP2P': ['train'], 'RedditClusteringP2P.v2': ['train'], 'STSBenchmark': ['train'], 'STSBenchmarkMultilingualSTS': ['train'], 'MIRACLRetrieval': ['train'], 'MIRACLRetrievalHardNegatives': ['train'], 'MIRACLReranking': ['train'], 'MrTidyRetrieval': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : dunzhang/stella-large-zh-v3-1792d | Value : name='dunzhang/stella-large-zh-v3-1792d' revision='d5d39eb8cd11c80a63df53314e59997074469f09' release_date='2024-02-17' languages=['zho_Hans'] loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=1792 license='not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/dunzhang/stella-large-zh-v3-1792d' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by='dunzhang/stella-mrl-large-zh-v3.5-1792d' is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : infgrad/stella-base-zh-v3-1792d | Value : name='infgrad/stella-base-zh-v3-1792d' revision='82254892a0fba125aa2abf3a4800d2dd12821343' release_date='2024-02-17' languages=['zho_Hans'] loader=None n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=1792 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/infgrad/stella-base-zh-v3-1792d' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : dunzhang/stella-mrl-large-zh-v3.5-1792d | Value : name='dunzhang/stella-mrl-large-zh-v3.5-1792d' revision='17bb1c32a93a8fc5f6fc9e91d5ea86da99983cfe' release_date='2024-02-27' languages=['zho_Hans'] loader=None n_parameters=326000000 memory_usage_mb=1242.0 max_tokens=512.0 embed_dim=1792 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/dunzhang/stella-large-zh-v3-1792d' similarity_fn_name='cosine' use_instructions=False training_datasets=None adapted_from='dunzhang/stella-large-zh-v3-1792d' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : iampanda/zpoint_large_embedding_zh | Value : name='iampanda/zpoint_large_embedding_zh' revision='b1075144f440ab4409c05622c1179130ebd57d03' release_date='2024-06-04' languages=['zho_Hans'] loader=None n_parameters=326000000 memory_usage_mb=1242.0 max_tokens=512.0 embed_dim=1792 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/iampanda/zpoint_large_embedding_zh' similarity_fn_name='cosine' use_instructions=False training_datasets={'MIRACLRetrieval': ['train'], 'MIRACLReranking': ['train'], 'DuRetrieval': ['train'], 'T2Retrieval': ['train'], 'MultiLongDocRetrieval': ['train']} adapted_from='dunzhang/stella-mrl-large-zh-v3.5-1792d' superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : facebook/SONAR | Value : name='facebook/SONAR' revision='a551c586dcf4a49c8fd847de369412d556a7f2f2' release_date='2021-05-21' languages=['ace-Arab', 'ace-Latn', 'acm-Arab', 'acq-Arab', 'aeb-Arab', 'afr-Latn', 'ajp-Arab', 'aka-Latn', 'als-Latn', 'amh-Ethi', 'apc-Arab', 'arb-Arab', 'arb-Latn', 'ars-Arab', 'ary-Arab', 'arz-Arab', 'asm-Beng', 'ast-Latn', 'awa-Deva', 'ayr-Latn', 'azb-Arab', 'azj-Latn', 'bak-Cyrl', 'bam-Latn', 'ban-Latn', 'bel-Cyrl', 'bem-Latn', 'ben-Beng', 'bho-Deva', 'bjn-Arab', 'bjn-Latn', 'bod-Tibt', 'bos-Latn', 'bug-Latn', 'bul-Cyrl', 'cat-Latn', 'ceb-Latn', 'ces-Latn', 'cjk-Latn', 'ckb-Arab', 'crh-Latn', 'cym-Latn', 'dan-Latn', 'deu-Latn', 'dik-Latn', 'dyu-Latn', 'dzo-Tibt', 'ell-Grek', 'eng-Latn', 'epo-Latn', 'est-Latn', 'eus-Latn', 'ewe-Latn', 'fao-Latn', 'fij-Latn', 'fin-Latn', 'fon-Latn', 'fra-Latn', 'fur-Latn', 'fuv-Latn', 'gaz-Latn', 'gla-Latn', 'gle-Latn', 'glg-Latn', 'grn-Latn', 'guj-Gujr', 'hat-Latn', 'hau-Latn', 'heb-Hebr', 'hin-Deva', 'hne-Deva', 'hrv-Latn', 'hun-Latn', 'hye-Armn', 'ibo-Latn', 'ilo-Latn', 'ind-Latn', 'isl-Latn', 'ita-Latn', 'jav-Latn', 'jpn-Jpan', 'kab-Latn', 'kac-Latn', 'kam-Latn', 'kan-Knda', 'kas-Arab', 'kas-Deva', 'kat-Geor', 'kaz-Cyrl', 'kbp-Latn', 'kea-Latn', 'khk-Cyrl', 'khm-Khmr', 'kik-Latn', 'kin-Latn', 'kir-Cyrl', 'kmb-Latn', 'kmr-Latn', 'knc-Arab', 'knc-Latn', 'kon-Latn', 'kor-Hang', 'lao-Laoo', 'lij-Latn', 'lim-Latn', 'lin-Latn', 'lit-Latn', 'lmo-Latn', 'ltg-Latn', 'ltz-Latn', 'lua-Latn', 'lug-Latn', 'luo-Latn', 'lus-Latn', 'lvs-Latn', 'mag-Deva', 'mai-Deva', 'mal-Mlym', 'mar-Deva', 'min-Arab', 'min-Latn', 'mkd-Cyrl', 'mlt-Latn', 'mni-Beng', 'mos-Latn', 'mri-Latn', 'mya-Mymr', 'nld-Latn', 'nno-Latn', 'nob-Latn', 'npi-Deva', 'nso-Latn', 'nus-Latn', 'nya-Latn', 'oci-Latn', 'ory-Orya', 'pag-Latn', 'pan-Guru', 'pap-Latn', 'pbt-Arab', 'pes-Arab', 'plt-Latn', 'pol-Latn', 'por-Latn', 'prs-Arab', 'quy-Latn', 'ron-Latn', 'run-Latn', 'rus-Cyrl', 'sag-Latn', 'san-Deva', 'sat-Olck', 'scn-Latn', 'shn-Mymr', 'sin-Sinh', 'slk-Latn', 'slv-Latn', 'smo-Latn', 'sna-Latn', 'snd-Arab', 'som-Latn', 'sot-Latn', 'spa-Latn', 'srd-Latn', 'srp-Cyrl', 'ssw-Latn', 'sun-Latn', 'swe-Latn', 'swh-Latn', 'szl-Latn', 'tam-Taml', 'taq-Latn', 'taq-Tfng', 'tat-Cyrl', 'tel-Telu', 'tgk-Cyrl', 'tgl-Latn', 'tha-Thai', 'tir-Ethi', 'tpi-Latn', 'tsn-Latn', 'tso-Latn', 'tuk-Latn', 'tum-Latn', 'tur-Latn', 'twi-Latn', 'tzm-Tfng', 'uig-Arab', 'ukr-Cyrl', 'umb-Latn', 'urd-Arab', 'uzn-Latn', 'vec-Latn', 'vie-Latn', 'war-Latn', 'wol-Latn', 'xho-Latn', 'ydd-Hebr', 'yor-Latn', 'yue-Hant', 'zho-Hans', 'zho-Hant', 'zsm-Latn', 'zul-Latn'] loader=<function no_model_implementation_available at 0x7f5a64dc3380> n_parameters=None memory_usage_mb=None max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code='https://github.com/facebookresearch/SONAR' public_training_data=None framework=['PyTorch'] reference='https://ai.meta.com/research/publications/sonar-sentence-level-multimodal-and-language-agnostic-representations/' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : shibing624/text2vec-base-chinese | Value : name='shibing624/text2vec-base-chinese' revision='183bb99aa7af74355fb58d16edf8c13ae7c5433e' release_date='2022-01-23' languages=['zho-Hans'] loader=None n_parameters=102000000 memory_usage_mb=390.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/shibing624/text2vec-base-chinese' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : shibing624/text2vec-base-chinese-paraphrase | Value : name='shibing624/text2vec-base-chinese-paraphrase' revision='e90c150a9c7fb55a67712a766d6820c55fb83cdd' release_date='2023-06-19' languages=['zho-Hans'] loader=None n_parameters=118000000 memory_usage_mb=450.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/shibing624/text2vec-base-chinese-paraphrase' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : WhereIsAI/UAE-Large-V1 | Value : name='WhereIsAI/UAE-Large-V1' revision='369c368f70f16a613f19f5598d4f12d9f44235d4' release_date='2023-12-04' languages=['eng_Latn'] loader=functools.partial(<class 'mteb.models.uae_models.UAEWrapper'>, model='WhereIsAI/UAE-Large-V1', revision='369c368f70f16a613f19f5598d4f12d9f44235d4', model_prompts={'query': 'Represent this sentence for searching relevant passages: {text}', 'Summarization': 'Summarize sentence \"{text}\" in one word:\"'}) n_parameters=335000000 memory_usage_mb=1278.0 max_tokens=512.0 embed_dim=1024 license='mit' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/WhereIsAI/UAE-Large-V1' similarity_fn_name='cosine' use_instructions=True training_datasets={'MNLI': [], 'NLI': [], 'SNLI': []} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-large-2-instruct | Value : name='voyageai/voyage-large-2-instruct' revision='1' release_date='2024-05-05' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-large-2-instruct', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=16000.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2024/05/05/voyage-large-2-instruct-instruction-tuned-and-rank-1-on-mteb/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-finance-2 | Value : name='voyageai/voyage-finance-2' revision='1' release_date='2024-05-30' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-finance-2', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=32000.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2024/06/03/domain-specific-embeddings-finance-edition-voyage-finance-2/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-law-2 | Value : name='voyageai/voyage-law-2' revision='1' release_date='2024-04-15' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-law-2', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=16000.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2024/04/15/domain-specific-embeddings-and-retrieval-legal-edition-voyage-law-2/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-code-2 | Value : name='voyageai/voyage-code-2' revision='1' release_date='2024-01-23' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-code-2', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=16000.0 embed_dim=1536 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2024/01/23/voyage-code-2-elevate-your-code-retrieval/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-code-3 | Value : name='voyageai/voyage-code-3' revision='1' release_date='2024-12-04' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-code-3', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=32000.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2024/12/04/voyage-code-3/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyage-large-2 | Value : name='voyage-large-2' revision='1' release_date='2023-10-29' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-large-2', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=16000.0 embed_dim=1536 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2023/10/29/voyage-embeddings/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-2 | Value : name='voyageai/voyage-2' revision='1' release_date='2023-10-29' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-2', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=4000.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2023/10/29/voyage-embeddings/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-multilingual-2 | Value : name='voyageai/voyage-multilingual-2' revision='1' release_date='2024-06-10' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-multilingual-2', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=32000.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2024/06/10/voyage-multilingual-2-multilingual-embedding-model/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-3 | Value : name='voyageai/voyage-3' revision='1' release_date='2024-09-18' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-3', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=32000.0 embed_dim=1024 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2024/09/18/voyage-3/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-3-lite | Value : name='voyageai/voyage-3-lite' revision='1' release_date='2024-09-18' languages=None loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-3-lite', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=None memory_usage_mb=None max_tokens=32000.0 embed_dim=512 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://blog.voyageai.com/2024/09/18/voyage-3/' similarity_fn_name='cosine' use_instructions=True training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : voyageai/voyage-3-m-exp | Value : name='voyageai/voyage-3-m-exp' revision='1' release_date='2025-01-08' languages=['eng-Latn'] loader=functools.partial(<class 'mteb.models.voyage_models.VoyageWrapper'>, model_name='voyage-3-m-exp', model_prompts={'query': 'query', 'passage': 'document'}) n_parameters=6918000000 memory_usage_mb=None max_tokens=32000.0 embed_dim=2048 license=None open_weights=False public_training_code=None public_training_data=None framework=['API'] reference='https://huggingface.co/voyageai/voyage-3-m-exp' similarity_fn_name='cosine' use_instructions=True training_datasets={'AmazonPolarityClassification': ['train'], 'AmazonReviewsClassification': ['train'], 'EmotionClassification': ['train'], 'HotpotQA': ['train'], 'ImdbClassification': ['train'], 'MTOPDomainClassification': ['train'], 'MTOPIntentClassification': ['train'], 'MindSmallReranking': ['train'], 'MassiveIntentClassification': ['train'], 'MassiveScenarioClassification': ['train'], 'MedrxivClusteringP2P': ['train'], 'MedrxivClusteringS2S': ['train'], 'STS12': ['train'], 'STSBenchmark': ['train'], 'StackOverflowDupQuestions': ['train'], 'ToxicConversationsClassification': ['train'], 'TweetSentimentExtractionClassification': ['train'], 'BiorxivClusteringP2P': ['train'], 'BiorxivClusteringS2S': ['train'], 'Banking77Classification': ['train'], 'ArguAna': ['train'], 'ArguAna-PL': ['train'], 'ArguAna-NL': ['train'], 'NanoArguAnaRetrieval': ['train'], 'STS22': ['train'], 'AmazonCounterfactualClassification': ['train'], 'ArxivClusteringP2P': ['train'], 'ArxivClusteringS2S': ['train'], 'NQ': ['train'], 'SciFact': ['train'], 'QuoraRetrieval': ['train'], 'NanoQuoraRetrieval': ['train'], 'NQHardNegatives': ['train'], 'NanoNQRetrieval': ['train'], 'NQ-PL': ['train'], 'NQ-NL': ['train'], 'NFCorpus': ['train'], 'FEVERHardNegatives': ['train'], 'NanoFEVERRetrieval': ['train'], 'FEVER-NL': ['train'], 'FiQA2018-NL': ['train'], 'BiorxivClusteringP2P.v2': ['train'], 'BiorxivClusteringS2S.v2': ['train'], 'MedrxivClusteringP2P.v2': ['train'], 'MedrxivClusteringS2S.v2': ['train'], 'MSMARCO': ['train'], 'MSMARCOHardNegatives': ['train'], 'NanoMSMARCORetrieval': ['train'], 'MSMARCO-PL': ['train'], 'mMARCO-NL': ['train'], 'HotpotQA-PL': ['train'], 'HotpotQA-NL': ['train'], 'HotpotQAHardNegatives': ['train'], 'FEVER': ['train'], 'FiQA2018': ['train'], 'DBPedia': ['train'], 'TRECCOVID': ['train'], 'ArxivClusteringP2P.v2': ['train'], 'STSBenchmarkMultilingualSTS': ['train']} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : HooshvareLab/bert-base-parsbert-uncased | Value : name='HooshvareLab/bert-base-parsbert-uncased' revision='d73a0e2c7492c33bd5819bcdb23eba207404dd19' release_date='2021-05-19' languages=['fas-Arab'] loader=None n_parameters=162841344 memory_usage_mb=621.0 max_tokens=512.0 embed_dim=768 license='not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : m3hrdadfi/bert-zwnj-wnli-mean-tokens | Value : name='m3hrdadfi/bert-zwnj-wnli-mean-tokens' revision='b9506ddc579ac8c398ae6dae680401ae0a1a5b23' release_date='2021-06-28' languages=['fas-Arab'] loader=None n_parameters=118297344 memory_usage_mb=451.0 max_tokens=512.0 embed_dim=768 license='not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/m3hrdadfi/bert-zwnj-wnli-mean-tokens' similarity_fn_name='cosine' use_instructions=False training_datasets={'FarsTail': []} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : m3hrdadfi/roberta-zwnj-wnli-mean-tokens | Value : name='m3hrdadfi/roberta-zwnj-wnli-mean-tokens' revision='36f912ac44e22250aee16ea533a4ff8cd848c1a1' release_date='2021-06-28' languages=['fas-Arab'] loader=None n_parameters=118298112 memory_usage_mb=451.0 max_tokens=514.0 embed_dim=768 license='not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/m3hrdadfi/roberta-zwnj-wnli-mean-tokens' similarity_fn_name='cosine' use_instructions=False training_datasets={'FarsTail': []} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : myrkur/sentence-transformer-parsbert-fa | Value : name='myrkur/sentence-transformer-parsbert-fa' revision='72bd0a3557622f0ae08a092f4643609e0b950cdd' release_date='2024-12-10' languages=['fas-Arab'] loader=None n_parameters=162841344 memory_usage_mb=621.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/myrkur/sentence-transformer-parsbert-fa' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : PartAI/TookaBERT-Base | Value : name='PartAI/TookaBERT-Base' revision='fa5ca89df5670700d9325b8872ac65c17cb24582' release_date='2024-12-08' languages=['fas-Arab'] loader=None n_parameters=122905344 memory_usage_mb=469.0 max_tokens=512.0 embed_dim=768 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/PartAI/TookaBERT-Base' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : PartAI/Tooka-SBERT | Value : name='PartAI/Tooka-SBERT' revision='5d07f0c543aca654373b931ae07cd197769110fd' release_date='2024-12-07' languages=['fas-Arab'] loader=None n_parameters=353039360 memory_usage_mb=1347.0 max_tokens=512.0 embed_dim=1024 license='apache-2.0' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/PartAI/Tooka-SBERT' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n",
      "Model Name : sbunlp/fabert | Value : name='sbunlp/fabert' revision='a0e3973064c97768e121b9b95f21adc94e0ca3fb' release_date='2024-10-07' languages=['fas-Arab'] loader=None n_parameters=124441344 memory_usage_mb=475.0 max_tokens=512.0 embed_dim=768 license='not specified' open_weights=True public_training_code=None public_training_data=None framework=['Sentence Transformers', 'PyTorch'] reference='https://huggingface.co/sbunlp/fabert' similarity_fn_name='cosine' use_instructions=False training_datasets={} adapted_from=None superseded_by=None is_cross_encoder=None modalities=['text']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in MODEL_REGISTRY.items():\n",
    "    print(f\"Model Name : {key} | Value : {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8db95416-a6ac-44e6-a1e8-4de3abd2f710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Name : CQADupstack-NL | Value : <class 'mteb.tasks.aggregated_tasks.CQADupStackNLRetrieval.CQADupstackNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackRetrieval | Value : <class 'mteb.tasks.aggregated_tasks.CQADupStackRetrieval.CQADupstackRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackRetrieval-Fa | Value : <class 'mteb.tasks.aggregated_tasks.CQADupStackRetrievalFa.CQADupstackRetrievalFa'>\n",
      "\n",
      "Task Name : VisualSTS17Eng | Value : <class 'mteb.tasks.aggregated_tasks.STS17MultilingualVisualSTS.STS17MultilingualVisualSTSEng'>\n",
      "\n",
      "Task Name : VisualSTS17Multilingual | Value : <class 'mteb.tasks.aggregated_tasks.STS17MultilingualVisualSTS.STS17MultilingualVisualSTSMultilingual'>\n",
      "\n",
      "Task Name : VisualSTS-b-Eng | Value : <class 'mteb.tasks.aggregated_tasks.STSBenchmarkMultilingualVisualSTS.STSBenchmarkMultilingualVisualSTSEng'>\n",
      "\n",
      "Task Name : VisualSTS-b-Multilingual | Value : <class 'mteb.tasks.aggregated_tasks.STSBenchmarkMultilingualVisualSTS.STSBenchmarkMultilingualVisualSTSMultilingual'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSAClassification | Value : <class 'mteb.tasks.aggregated_tasks.SynPerChatbotConvSAClassification.SynPerChatbotConvSAClassification'>\n",
      "\n",
      "Task Name : SadeemQuestionRetrieval | Value : <class 'mteb.tasks.Retrieval.ara.SadeemQuestionRetrieval.SadeemQuestionRetrieval'>\n",
      "\n",
      "Task Name : AppsRetrieval | Value : <class 'mteb.tasks.Retrieval.code.AppsRetrieval.AppsRetrieval'>\n",
      "\n",
      "Task Name : CodeEditSearchRetrieval | Value : <class 'mteb.tasks.Retrieval.code.CodeEditSearchRetrieval.CodeEditSearchRetrieval'>\n",
      "\n",
      "Task Name : CodeFeedbackMT | Value : <class 'mteb.tasks.Retrieval.code.CodeFeedbackMTRetrieval.CodeFeedbackMT'>\n",
      "\n",
      "Task Name : CodeFeedbackST | Value : <class 'mteb.tasks.Retrieval.code.CodeFeedbackSTRetrieval.CodeFeedbackST'>\n",
      "\n",
      "Task Name : CodeRAGProgrammingSolutions | Value : <class 'mteb.tasks.Retrieval.code.CodeRAG.CodeRAGProgrammingSolutionsRetrieval'>\n",
      "\n",
      "Task Name : CodeRAGOnlineTutorials | Value : <class 'mteb.tasks.Retrieval.code.CodeRAG.CodeRAGOnlineTutorialsRetrieval'>\n",
      "\n",
      "Task Name : CodeRAGLibraryDocumentationSolutions | Value : <class 'mteb.tasks.Retrieval.code.CodeRAG.CodeRAGLibraryDocumentationSolutionsRetrieval'>\n",
      "\n",
      "Task Name : CodeRAGStackoverflowPosts | Value : <class 'mteb.tasks.Retrieval.code.CodeRAG.CodeRAGStackoverflowPostsRetrieval'>\n",
      "\n",
      "Task Name : CodeSearchNetCCRetrieval | Value : <class 'mteb.tasks.Retrieval.code.CodeSearchNetCCRetrieval.CodeSearchNetCCRetrieval'>\n",
      "\n",
      "Task Name : CodeSearchNetRetrieval | Value : <class 'mteb.tasks.Retrieval.code.CodeSearchNetRetrieval.CodeSearchNetRetrieval'>\n",
      "\n",
      "Task Name : CodeTransOceanContest | Value : <class 'mteb.tasks.Retrieval.code.CodeTransOceanContestRetrieval.CodeTransOceanContestRetrieval'>\n",
      "\n",
      "Task Name : CodeTransOceanDL | Value : <class 'mteb.tasks.Retrieval.code.CodeTransOceanDLRetrieval.CodeTransOceanDLRetrieval'>\n",
      "\n",
      "Task Name : COIRCodeSearchNetRetrieval | Value : <class 'mteb.tasks.Retrieval.code.COIRCodeSearchNetRetrieval.COIRCodeSearchNetRetrieval'>\n",
      "\n",
      "Task Name : CosQA | Value : <class 'mteb.tasks.Retrieval.code.CosQARetrieval.CosQARetrieval'>\n",
      "\n",
      "Task Name : StackOverflowQA | Value : <class 'mteb.tasks.Retrieval.code.StackOverflowQARetrieval.StackOverflowQARetrieval'>\n",
      "\n",
      "Task Name : SyntheticText2SQL | Value : <class 'mteb.tasks.Retrieval.code.SyntheticText2SqlRetrieval.SyntheticText2SQLRetrieval'>\n",
      "\n",
      "Task Name : DanFeverRetrieval | Value : <class 'mteb.tasks.Retrieval.dan.DanFeverRetrieval.DanFeverRetrieval'>\n",
      "\n",
      "Task Name : DanFEVER | Value : <class 'mteb.tasks.Retrieval.dan.DanFeverRetrieval.DanFever'>\n",
      "\n",
      "Task Name : TV2Nordretrieval | Value : <class 'mteb.tasks.Retrieval.dan.TV2Nordretrieval.TV2Nordretrieval'>\n",
      "\n",
      "Task Name : TwitterHjerneRetrieval | Value : <class 'mteb.tasks.Retrieval.dan.TwitterHjerneRetrieval.TwitterHjerneRetrieval'>\n",
      "\n",
      "Task Name : GerDaLIR | Value : <class 'mteb.tasks.Retrieval.deu.GerDaLIRRetrieval.GerDaLIR'>\n",
      "\n",
      "Task Name : GerDaLIRSmall | Value : <class 'mteb.tasks.Retrieval.deu.GerDaLIRSmallRetrieval.GerDaLIRSmall'>\n",
      "\n",
      "Task Name : GermanDPR | Value : <class 'mteb.tasks.Retrieval.deu.GermanDPRRetrieval.GermanDPR'>\n",
      "\n",
      "Task Name : GermanGovServiceRetrieval | Value : <class 'mteb.tasks.Retrieval.deu.GermanGovServiceRetrieval.GermanGovServiceRetrieval'>\n",
      "\n",
      "Task Name : GermanQuAD-Retrieval | Value : <class 'mteb.tasks.Retrieval.deu.GermanQuADRetrieval.GermanQuADRetrieval'>\n",
      "\n",
      "Task Name : LegalQuAD | Value : <class 'mteb.tasks.Retrieval.deu.LegalQuADRetrieval.LegalQuAD'>\n",
      "\n",
      "Task Name : GreekCivicsQA | Value : <class 'mteb.tasks.Retrieval.ell.GreekCivicsQA.GreekCivicsQA'>\n",
      "\n",
      "Task Name : AILACasedocs | Value : <class 'mteb.tasks.Retrieval.eng.AILACasedocsRetrieval.AILACasedocs'>\n",
      "\n",
      "Task Name : AILAStatutes | Value : <class 'mteb.tasks.Retrieval.eng.AILAStatutesRetrieval.AILAStatutes'>\n",
      "\n",
      "Task Name : AlphaNLI | Value : <class 'mteb.tasks.Retrieval.eng.AlphaNLIRetrieval.AlphaNLI'>\n",
      "\n",
      "Task Name : ARCChallenge | Value : <class 'mteb.tasks.Retrieval.eng.ARCChallengeRetrieval.ARCChallenge'>\n",
      "\n",
      "Task Name : ArguAna | Value : <class 'mteb.tasks.Retrieval.eng.ArguAnaRetrieval.ArguAna'>\n",
      "\n",
      "Task Name : BrightRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.BrightRetrieval.BrightRetrieval'>\n",
      "\n",
      "Task Name : BuiltBenchRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.BuiltBenchRetrieval.BuiltBenchRetrieval'>\n",
      "\n",
      "Task Name : ChemHotpotQARetrieval | Value : <class 'mteb.tasks.Retrieval.eng.ChemHotpotQARetrieval.ChemHotpotQARetrieval'>\n",
      "\n",
      "Task Name : ChemNQRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.ChemNQRetrieval.ChemNQRetrieval'>\n",
      "\n",
      "Task Name : ClimateFEVER | Value : <class 'mteb.tasks.Retrieval.eng.ClimateFEVERRetrieval.ClimateFEVER'>\n",
      "\n",
      "Task Name : ClimateFEVERHardNegatives | Value : <class 'mteb.tasks.Retrieval.eng.ClimateFEVERRetrieval.ClimateFEVERHardNegatives'>\n",
      "\n",
      "Task Name : ClimateFEVER.v2 | Value : <class 'mteb.tasks.Retrieval.eng.ClimateFEVERRetrieval.ClimateFEVERRetrievalv2'>\n",
      "\n",
      "Task Name : CQADupstackAndroidRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackAndroidRetrieval.CQADupstackAndroidRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackEnglishRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackEnglishRetrieval.CQADupstackEnglishRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackGamingRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackGamingRetrieval.CQADupstackGamingRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackGisRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackGisRetrieval.CQADupstackGisRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackMathematicaRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackMathematicaRetrieval.CQADupstackMathematicaRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackPhysicsRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackPhysicsRetrieval.CQADupstackPhysicsRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackProgrammersRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackProgrammersRetrieval.CQADupstackProgrammersRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackStatsRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackStatsRetrieval.CQADupstackStatsRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackTexRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackTexRetrieval.CQADupstackTexRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackUnixRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackUnixRetrieval.CQADupstackUnixRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackWebmastersRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackWebmastersRetrieval.CQADupstackWebmastersRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackWordpressRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.CQADupstackWordpressRetrieval.CQADupstackWordpressRetrieval'>\n",
      "\n",
      "Task Name : DBPedia | Value : <class 'mteb.tasks.Retrieval.eng.DBPediaRetrieval.DBPedia'>\n",
      "\n",
      "Task Name : DBPediaHardNegatives | Value : <class 'mteb.tasks.Retrieval.eng.DBPediaRetrieval.DBPediaHardNegatives'>\n",
      "\n",
      "Task Name : FaithDial | Value : <class 'mteb.tasks.Retrieval.eng.FaithDialRetrieval.FaithDialRetrieval'>\n",
      "\n",
      "Task Name : FeedbackQARetrieval | Value : <class 'mteb.tasks.Retrieval.eng.FeedbackQARetrieval.FeedbackQARetrieval'>\n",
      "\n",
      "Task Name : FEVER | Value : <class 'mteb.tasks.Retrieval.eng.FEVERRetrieval.FEVER'>\n",
      "\n",
      "Task Name : FEVERHardNegatives | Value : <class 'mteb.tasks.Retrieval.eng.FEVERRetrieval.FEVERHardNegatives'>\n",
      "\n",
      "Task Name : FiQA2018 | Value : <class 'mteb.tasks.Retrieval.eng.FiQA2018Retrieval.FiQA2018'>\n",
      "\n",
      "Task Name : HagridRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.HagridRetrieval.HagridRetrieval'>\n",
      "\n",
      "Task Name : HellaSwag | Value : <class 'mteb.tasks.Retrieval.eng.HellaSwagRetrieval.HellaSwag'>\n",
      "\n",
      "Task Name : HotpotQA | Value : <class 'mteb.tasks.Retrieval.eng.HotpotQARetrieval.HotpotQA'>\n",
      "\n",
      "Task Name : HotpotQAHardNegatives | Value : <class 'mteb.tasks.Retrieval.eng.HotpotQARetrieval.HotpotQAHardNegatives'>\n",
      "\n",
      "Task Name : LegalBenchConsumerContractsQA | Value : <class 'mteb.tasks.Retrieval.eng.LegalBenchConsumerContractsQARetrieval.LegalBenchConsumerContractsQA'>\n",
      "\n",
      "Task Name : LegalBenchCorporateLobbying | Value : <class 'mteb.tasks.Retrieval.eng.LegalBenchCorporateLobbyingRetrieval.LegalBenchCorporateLobbying'>\n",
      "\n",
      "Task Name : LegalSummarization | Value : <class 'mteb.tasks.Retrieval.eng.LegalSummarizationRetrieval.LegalSummarization'>\n",
      "\n",
      "Task Name : LEMBNarrativeQARetrieval | Value : <class 'mteb.tasks.Retrieval.eng.LEMBNarrativeQARetrieval.LEMBNarrativeQARetrieval'>\n",
      "\n",
      "Task Name : LEMBNeedleRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.LEMBNeedleRetrieval.LEMBNeedleRetrieval'>\n",
      "\n",
      "Task Name : LEMBPasskeyRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.LEMBPasskeyRetrieval.LEMBPasskeyRetrieval'>\n",
      "\n",
      "Task Name : LEMBQMSumRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.LEMBQMSumRetrieval.LEMBQMSumRetrieval'>\n",
      "\n",
      "Task Name : LEMBSummScreenFDRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.LEMBSummScreenFDRetrieval.LEMBSummScreenFDRetrieval'>\n",
      "\n",
      "Task Name : LEMBWikimQARetrieval | Value : <class 'mteb.tasks.Retrieval.eng.LEMBWikimQARetrieval.LEMBWikimQARetrieval'>\n",
      "\n",
      "Task Name : LitSearchRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.LitSearchRetrieval.LitSearchRetrieval'>\n",
      "\n",
      "Task Name : MedicalQARetrieval | Value : <class 'mteb.tasks.Retrieval.eng.MedicalQARetrieval.MedicalQARetrieval'>\n",
      "\n",
      "Task Name : MLQuestions | Value : <class 'mteb.tasks.Retrieval.eng.MLQuestions.MLQuestionsRetrieval'>\n",
      "\n",
      "Task Name : MSMARCO | Value : <class 'mteb.tasks.Retrieval.eng.MSMARCORetrieval.MSMARCO'>\n",
      "\n",
      "Task Name : MSMARCOHardNegatives | Value : <class 'mteb.tasks.Retrieval.eng.MSMARCORetrieval.MSMARCOHardNegatives'>\n",
      "\n",
      "Task Name : MSMARCOv2 | Value : <class 'mteb.tasks.Retrieval.eng.MSMARCOv2Retrieval.MSMARCOv2'>\n",
      "\n",
      "Task Name : NanoArguAnaRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoArguAnaRetrieval.NanoArguAnaRetrieval'>\n",
      "\n",
      "Task Name : NanoClimateFeverRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoClimateFeverRetrieval.NanoClimateFeverRetrieval'>\n",
      "\n",
      "Task Name : NanoDBPediaRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoDBPediaRetrieval.NanoDBPediaRetrieval'>\n",
      "\n",
      "Task Name : NanoFEVERRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoFEVERRetrieval.NanoFEVERRetrieval'>\n",
      "\n",
      "Task Name : NanoFiQA2018Retrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoFiQA2018Retrieval.NanoFiQA2018Retrieval'>\n",
      "\n",
      "Task Name : NanoHotpotQARetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoHotpotQARetrieval.NanoHotpotQARetrieval'>\n",
      "\n",
      "Task Name : NanoMSMARCORetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoMSMARCORetrieval.NanoMSMARCORetrieval'>\n",
      "\n",
      "Task Name : NanoNFCorpusRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoNFCorpusRetrieval.NanoNFCorpusRetrieval'>\n",
      "\n",
      "Task Name : NanoNQRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoNQRetrieval.NanoNQRetrieval'>\n",
      "\n",
      "Task Name : NanoQuoraRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoQuoraRetrieval.NanoQuoraRetrieval'>\n",
      "\n",
      "Task Name : NanoSCIDOCSRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoSCIDOCSRetrieval.NanoSCIDOCSRetrieval'>\n",
      "\n",
      "Task Name : NanoSciFactRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoSciFactRetrieval.NanoSciFactRetrieval'>\n",
      "\n",
      "Task Name : NanoTouche2020Retrieval | Value : <class 'mteb.tasks.Retrieval.eng.NanoTouche2020Retrieval.NanoTouche2020Retrieval'>\n",
      "\n",
      "Task Name : NarrativeQARetrieval | Value : <class 'mteb.tasks.Retrieval.eng.NarrativeQARetrieval.NarrativeQARetrieval'>\n",
      "\n",
      "Task Name : NFCorpus | Value : <class 'mteb.tasks.Retrieval.eng.NFCorpusRetrieval.NFCorpus'>\n",
      "\n",
      "Task Name : NQ | Value : <class 'mteb.tasks.Retrieval.eng.NQRetrieval.NQ'>\n",
      "\n",
      "Task Name : NQHardNegatives | Value : <class 'mteb.tasks.Retrieval.eng.NQRetrieval.NQHardNegatives'>\n",
      "\n",
      "Task Name : PIQA | Value : <class 'mteb.tasks.Retrieval.eng.PiqaRetrieval.PIQA'>\n",
      "\n",
      "Task Name : Quail | Value : <class 'mteb.tasks.Retrieval.eng.QuailRetrieval.Quail'>\n",
      "\n",
      "Task Name : QuoraRetrieval | Value : <class 'mteb.tasks.Retrieval.eng.QuoraRetrieval.QuoraRetrieval'>\n",
      "\n",
      "Task Name : QuoraRetrievalHardNegatives | Value : <class 'mteb.tasks.Retrieval.eng.QuoraRetrieval.QuoraRetrievalHardNegatives'>\n",
      "\n",
      "Task Name : RARbCode | Value : <class 'mteb.tasks.Retrieval.eng.RARbCodeRetrieval.RARbCode'>\n",
      "\n",
      "Task Name : RARbMath | Value : <class 'mteb.tasks.Retrieval.eng.RARbMathRetrieval.RARbMath'>\n",
      "\n",
      "Task Name : SCIDOCS | Value : <class 'mteb.tasks.Retrieval.eng.SCIDOCSRetrieval.SCIDOCS'>\n",
      "\n",
      "Task Name : SciFact | Value : <class 'mteb.tasks.Retrieval.eng.SciFactRetrieval.SciFact'>\n",
      "\n",
      "Task Name : SIQA | Value : <class 'mteb.tasks.Retrieval.eng.SiqaRetrieval.SIQA'>\n",
      "\n",
      "Task Name : SpartQA | Value : <class 'mteb.tasks.Retrieval.eng.SpartQARetrieval.SpartQA'>\n",
      "\n",
      "Task Name : TempReasonL1 | Value : <class 'mteb.tasks.Retrieval.eng.TempReasonL1Retrieval.TempReasonL1'>\n",
      "\n",
      "Task Name : TempReasonL2Context | Value : <class 'mteb.tasks.Retrieval.eng.TempReasonL2ContextRetrieval.TempReasonL2Context'>\n",
      "\n",
      "Task Name : TempReasonL2Fact | Value : <class 'mteb.tasks.Retrieval.eng.TempReasonL2FactRetrieval.TempReasonL2Fact'>\n",
      "\n",
      "Task Name : TempReasonL2Pure | Value : <class 'mteb.tasks.Retrieval.eng.TempReasonL2PureRetrieval.TempReasonL2Pure'>\n",
      "\n",
      "Task Name : TempReasonL3Context | Value : <class 'mteb.tasks.Retrieval.eng.TempReasonL3ContextRetrieval.TempReasonL3Context'>\n",
      "\n",
      "Task Name : TempReasonL3Fact | Value : <class 'mteb.tasks.Retrieval.eng.TempReasonL3FactRetrieval.TempReasonL3Fact'>\n",
      "\n",
      "Task Name : TempReasonL3Pure | Value : <class 'mteb.tasks.Retrieval.eng.TempReasonL3PureRetrieval.TempReasonL3Pure'>\n",
      "\n",
      "Task Name : TopiOCQA | Value : <class 'mteb.tasks.Retrieval.eng.TopiOCQARetrieval.TopiOCQARetrieval'>\n",
      "\n",
      "Task Name : TopiOCQAHardNegatives | Value : <class 'mteb.tasks.Retrieval.eng.TopiOCQARetrieval.TopiOCQARetrievalHardNegatives'>\n",
      "\n",
      "Task Name : Touche2020 | Value : <class 'mteb.tasks.Retrieval.eng.Touche2020Retrieval.Touche2020'>\n",
      "\n",
      "Task Name : Touche2020Retrieval.v3 | Value : <class 'mteb.tasks.Retrieval.eng.Touche2020Retrieval.Touche2020v3Retrieval'>\n",
      "\n",
      "Task Name : TRECCOVID | Value : <class 'mteb.tasks.Retrieval.eng.TRECCOVIDRetrieval.TRECCOVID'>\n",
      "\n",
      "Task Name : WinoGrande | Value : <class 'mteb.tasks.Retrieval.eng.WinoGrandeRetrieval.WinoGrande'>\n",
      "\n",
      "Task Name : EstQA | Value : <class 'mteb.tasks.Retrieval.est.estqa.EstQA'>\n",
      "\n",
      "Task Name : ArguAna-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.ArguAnaFa'>\n",
      "\n",
      "Task Name : ClimateFEVER-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.ClimateFEVERFa'>\n",
      "\n",
      "Task Name : CQADupstackAndroidRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackAndroidRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackEnglishRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackEnglishRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackGamingRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackGamingRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackGisRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackGisRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackMathematicaRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackMathematicaRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackPhysicsRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackPhysicsRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackProgrammersRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackProgrammersRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackStatsRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackStatsRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackTexRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackTexRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackUnixRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackUnixRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackWebmastersRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackWebmastersRetrievalFa'>\n",
      "\n",
      "Task Name : CQADupstackWordpressRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.CQADupstackWordpressRetrievalFa'>\n",
      "\n",
      "Task Name : DBPedia-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.DBPediaFa'>\n",
      "\n",
      "Task Name : FiQA2018-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.FiQA2018Fa'>\n",
      "\n",
      "Task Name : HotpotQA-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.HotpotQAFa'>\n",
      "\n",
      "Task Name : MSMARCO-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.MSMARCOFa'>\n",
      "\n",
      "Task Name : NFCorpus-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.NFCorpusFa'>\n",
      "\n",
      "Task Name : NQ-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.NQFa'>\n",
      "\n",
      "Task Name : QuoraRetrieval-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.QuoraRetrievalFa'>\n",
      "\n",
      "Task Name : SCIDOCS-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.SCIDOCSFa'>\n",
      "\n",
      "Task Name : SciFact-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.SciFactFa'>\n",
      "\n",
      "Task Name : TRECCOVID-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.TRECCOVIDFa'>\n",
      "\n",
      "Task Name : Touche2020-Fa | Value : <class 'mteb.tasks.Retrieval.fas.BEIRFa.Touche2020Fa'>\n",
      "\n",
      "Task Name : SynPerQARetrieval | Value : <class 'mteb.tasks.Retrieval.fas.FaMTEBRetrieval.SynPerQARetrieval'>\n",
      "\n",
      "Task Name : SynPerChatbotTopicsRetrieval | Value : <class 'mteb.tasks.Retrieval.fas.FaMTEBRetrieval.SynPerChatbotTopicsRetrieval'>\n",
      "\n",
      "Task Name : SynPerChatbotRAGTopicsRetrieval | Value : <class 'mteb.tasks.Retrieval.fas.FaMTEBRetrieval.SynPerChatbotRAGTopicsRetrieval'>\n",
      "\n",
      "Task Name : SynPerChatbotRAGFAQRetrieval | Value : <class 'mteb.tasks.Retrieval.fas.FaMTEBRetrieval.SynPerChatbotRAGFAQRetrieval'>\n",
      "\n",
      "Task Name : PersianWebDocumentRetrieval | Value : <class 'mteb.tasks.Retrieval.fas.FaMTEBRetrieval.PersianWebDocumentRetrieval'>\n",
      "\n",
      "Task Name : AlloprofRetrieval | Value : <class 'mteb.tasks.Retrieval.fra.AlloprofRetrieval.AlloprofRetrieval'>\n",
      "\n",
      "Task Name : BSARDRetrieval | Value : <class 'mteb.tasks.Retrieval.fra.BSARDRetrieval.BSARDRetrieval'>\n",
      "\n",
      "Task Name : FQuADRetrieval | Value : <class 'mteb.tasks.Retrieval.fra.FQuADRetrieval.FQuADRetrieval'>\n",
      "\n",
      "Task Name : SyntecRetrieval | Value : <class 'mteb.tasks.Retrieval.fra.SyntecRetrieval.SyntecRetrieval'>\n",
      "\n",
      "Task Name : HunSum2AbstractiveRetrieval | Value : <class 'mteb.tasks.Retrieval.hun.HunSum2.HunSum2AbstractiveRetrieval'>\n",
      "\n",
      "Task Name : JaGovFaqsRetrieval | Value : <class 'mteb.tasks.Retrieval.jpn.JaGovFaqsRetrieval.JaGovFaqsRetrieval'>\n",
      "\n",
      "Task Name : JaqketRetrieval | Value : <class 'mteb.tasks.Retrieval.jpn.JaqketRetrieval.JaqketRetrieval'>\n",
      "\n",
      "Task Name : JaQuADRetrieval | Value : <class 'mteb.tasks.Retrieval.jpn.JaQuADRetrieval.JaQuADRetrieval'>\n",
      "\n",
      "Task Name : NLPJournalAbsIntroRetrieval | Value : <class 'mteb.tasks.Retrieval.jpn.NLPJournalAbsIntroRetrieval.NLPJournalAbsIntroRetrieval'>\n",
      "\n",
      "Task Name : NLPJournalTitleAbsRetrieval | Value : <class 'mteb.tasks.Retrieval.jpn.NLPJournalTitleAbsRetrieval.NLPJournalTitleAbsRetrieval'>\n",
      "\n",
      "Task Name : NLPJournalTitleIntroRetrieval | Value : <class 'mteb.tasks.Retrieval.jpn.NLPJournalTitleIntroRetrieval.NLPJournalTitleIntroRetrieval'>\n",
      "\n",
      "Task Name : GeorgianFAQRetrieval | Value : <class 'mteb.tasks.Retrieval.kat.GeorgianFAQRetrieval.GeorgianFAQRetrieval'>\n",
      "\n",
      "Task Name : AutoRAGRetrieval | Value : <class 'mteb.tasks.Retrieval.kor.AutoRAGRetrieval.AutoRAGRetrieval'>\n",
      "\n",
      "Task Name : Ko-StrategyQA | Value : <class 'mteb.tasks.Retrieval.kor.KoStrategyQA.KoStrategyQA'>\n",
      "\n",
      "Task Name : BelebeleRetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.BelebeleRetrieval.BelebeleRetrieval'>\n",
      "\n",
      "Task Name : CrossLingualSemanticDiscriminationWMT19 | Value : <class 'mteb.tasks.Retrieval.multilingual.CrossLingualSemanticDiscriminationWMT19.CrossLingualSemanticDiscriminationWMT19'>\n",
      "\n",
      "Task Name : CrossLingualSemanticDiscriminationWMT21 | Value : <class 'mteb.tasks.Retrieval.multilingual.CrossLingualSemanticDiscriminationWMT21.CrossLingualSemanticDiscriminationWMT21'>\n",
      "\n",
      "Task Name : CUREv1 | Value : <class 'mteb.tasks.Retrieval.multilingual.CUREv1Retrieval.CUREv1Retrieval'>\n",
      "\n",
      "Task Name : IndicQARetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.IndicQARetrieval.IndicQARetrieval'>\n",
      "\n",
      "Task Name : MintakaRetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.MintakaRetrieval.MintakaRetrieval'>\n",
      "\n",
      "Task Name : MIRACLRetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.MIRACLRetrieval.MIRACLRetrieval'>\n",
      "\n",
      "Task Name : MIRACLRetrievalHardNegatives | Value : <class 'mteb.tasks.Retrieval.multilingual.MIRACLRetrieval.MIRACLRetrievalHardNegatives'>\n",
      "\n",
      "Task Name : MLQARetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.MLQARetrieval.MLQARetrieval'>\n",
      "\n",
      "Task Name : MrTidyRetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.MrTidyRetrieval.MrTidyRetrieval'>\n",
      "\n",
      "Task Name : MultiLongDocRetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.MultiLongDocRetrieval.MultiLongDocRetrieval'>\n",
      "\n",
      "Task Name : NeuCLIR2022Retrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.NeuCLIR2022Retrieval.NeuCLIR2022Retrieval'>\n",
      "\n",
      "Task Name : NeuCLIR2022RetrievalHardNegatives | Value : <class 'mteb.tasks.Retrieval.multilingual.NeuCLIR2022Retrieval.NeuCLIR2022RetrievalHardNegatives'>\n",
      "\n",
      "Task Name : NeuCLIR2023Retrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.NeuCLIR2023Retrieval.NeuCLIR2023Retrieval'>\n",
      "\n",
      "Task Name : NeuCLIR2023RetrievalHardNegatives | Value : <class 'mteb.tasks.Retrieval.multilingual.NeuCLIR2023Retrieval.NeuCLIR2023RetrievalHardNegatives'>\n",
      "\n",
      "Task Name : PublicHealthQA | Value : <class 'mteb.tasks.Retrieval.multilingual.PublicHealthQARetrieval.PublicHealthQARetrieval'>\n",
      "\n",
      "Task Name : StatcanDialogueDatasetRetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.StatcanDialogueDatasetRetrieval.StatcanDialogueDatasetRetrieval'>\n",
      "\n",
      "Task Name : WikipediaRetrievalMultilingual | Value : <class 'mteb.tasks.Retrieval.multilingual.WikipediaRetrievalMultilingual.WikipediaRetrievalMultilingual'>\n",
      "\n",
      "Task Name : XMarket | Value : <class 'mteb.tasks.Retrieval.multilingual.XMarketRetrieval.XMarket'>\n",
      "\n",
      "Task Name : XPQARetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.XPQARetrieval.XPQARetrieval'>\n",
      "\n",
      "Task Name : XQuADRetrieval | Value : <class 'mteb.tasks.Retrieval.multilingual.XQuADRetrieval.XQuADRetrieval'>\n",
      "\n",
      "Task Name : ArguAna-NL | Value : <class 'mteb.tasks.Retrieval.nld.ArguAnaNLRetrieval.ArguAnaNL'>\n",
      "\n",
      "Task Name : ClimateFEVER-NL | Value : <class 'mteb.tasks.Retrieval.nld.ClimateFEVERNLRetrieval.ClimateFEVERNL'>\n",
      "\n",
      "Task Name : CQADupstackAndroid-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackAndroidNLRetrieval.CQADupstackAndroidNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackEnglish-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackEnglishNLRetrieval.CQADupstackEnglishNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackGaming-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackGamingNLRetrieval.CQADupstackGamingNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackGis-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackGisNLRetrieval.CQADupstackGisNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackMathematica-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackMathematicaNLRetrieval.CQADupstackMathematicaNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackPhysics-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackPhysicsNLRetrieval.CQADupstackPhysicsNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackProgrammers-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackProgrammersNLRetrieval.CQADupstackProgrammersNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackStats-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackStatsNLRetrieval.CQADupstackStatsNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackTex-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackTexNLRetrieval.CQADupstackTexNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackUnix-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackUnixNLRetrieval.CQADupstackUnixNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackWebmasters-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackWebmastersNLRetrieval.CQADupstackWebmastersNLRetrieval'>\n",
      "\n",
      "Task Name : CQADupstackWordpress-NL | Value : <class 'mteb.tasks.Retrieval.nld.CQADupstackWordpressNLRetrieval.CQADupstackWordpressNLRetrieval'>\n",
      "\n",
      "Task Name : DBPedia-NL | Value : <class 'mteb.tasks.Retrieval.nld.DBPediaNLRetrieval.DBPediaNL'>\n",
      "\n",
      "Task Name : FEVER-NL | Value : <class 'mteb.tasks.Retrieval.nld.FEVERNLRetrieval.FEVERNL'>\n",
      "\n",
      "Task Name : FiQA2018-NL | Value : <class 'mteb.tasks.Retrieval.nld.FiQA2018NLRetrieval.FiQA2018NL'>\n",
      "\n",
      "Task Name : HotpotQA-NL | Value : <class 'mteb.tasks.Retrieval.nld.HotpotQANLRetrieval.HotpotQANL'>\n",
      "\n",
      "Task Name : mMARCO-NL | Value : <class 'mteb.tasks.Retrieval.nld.MMARCONLRetrieval.MMMARCONL'>\n",
      "\n",
      "Task Name : NFCorpus-NL | Value : <class 'mteb.tasks.Retrieval.nld.NFCorpusNLRetrieval.NFCorpusNL'>\n",
      "\n",
      "Task Name : NQ-NL | Value : <class 'mteb.tasks.Retrieval.nld.NQNLRetrieval.NQNL'>\n",
      "\n",
      "Task Name : Quora-NL | Value : <class 'mteb.tasks.Retrieval.nld.QuoraNLRetrieval.QuoraNLRetrieval'>\n",
      "\n",
      "Task Name : SCIDOCS-NL | Value : <class 'mteb.tasks.Retrieval.nld.SCIDOCSNLRetrieval.SCIDOCSNL'>\n",
      "\n",
      "Task Name : SciFact-NL | Value : <class 'mteb.tasks.Retrieval.nld.SciFactNLRetrieval.SciFactNL'>\n",
      "\n",
      "Task Name : Touche2020-NL | Value : <class 'mteb.tasks.Retrieval.nld.Touche2020NLRetrieval.Touche2020NL'>\n",
      "\n",
      "Task Name : TRECCOVID-NL | Value : <class 'mteb.tasks.Retrieval.nld.TRECCOVIDNLRetrieval.TRECCOVIDNL'>\n",
      "\n",
      "Task Name : NorQuadRetrieval | Value : <class 'mteb.tasks.Retrieval.nob.norquad.NorQuadRetrieval'>\n",
      "\n",
      "Task Name : SNLRetrieval | Value : <class 'mteb.tasks.Retrieval.nob.snl_retrieval.SNLRetrieval'>\n",
      "\n",
      "Task Name : ArguAna-PL | Value : <class 'mteb.tasks.Retrieval.pol.ArguAnaPLRetrieval.ArguAnaPL'>\n",
      "\n",
      "Task Name : DBPedia-PL | Value : <class 'mteb.tasks.Retrieval.pol.DBPediaPLRetrieval.DBPediaPL'>\n",
      "\n",
      "Task Name : DBPedia-PLHardNegatives | Value : <class 'mteb.tasks.Retrieval.pol.DBPediaPLRetrieval.DBPediaPLHardNegatives'>\n",
      "\n",
      "Task Name : FiQA-PL | Value : <class 'mteb.tasks.Retrieval.pol.FiQAPLRetrieval.FiQAPLRetrieval'>\n",
      "\n",
      "Task Name : HotpotQA-PL | Value : <class 'mteb.tasks.Retrieval.pol.HotpotQAPLRetrieval.HotpotQAPL'>\n",
      "\n",
      "Task Name : HotpotQA-PLHardNegatives | Value : <class 'mteb.tasks.Retrieval.pol.HotpotQAPLRetrieval.HotpotQAPLHardNegatives'>\n",
      "\n",
      "Task Name : MSMARCO-PL | Value : <class 'mteb.tasks.Retrieval.pol.MSMARCOPLRetrieval.MSMARCOPL'>\n",
      "\n",
      "Task Name : MSMARCO-PLHardNegatives | Value : <class 'mteb.tasks.Retrieval.pol.MSMARCOPLRetrieval.MSMARCOPLHardNegatives'>\n",
      "\n",
      "Task Name : NFCorpus-PL | Value : <class 'mteb.tasks.Retrieval.pol.NFCorpusPLRetrieval.NFCorpusPL'>\n",
      "\n",
      "Task Name : NQ-PL | Value : <class 'mteb.tasks.Retrieval.pol.NQPLRetrieval.NQPL'>\n",
      "\n",
      "Task Name : NQ-PLHardNegatives | Value : <class 'mteb.tasks.Retrieval.pol.NQPLRetrieval.NQPLHardNegatives'>\n",
      "\n",
      "Task Name : Quora-PL | Value : <class 'mteb.tasks.Retrieval.pol.QuoraPLRetrieval.QuoraPLRetrieval'>\n",
      "\n",
      "Task Name : Quora-PLHardNegatives | Value : <class 'mteb.tasks.Retrieval.pol.QuoraPLRetrieval.QuoraPLRetrievalHardNegatives'>\n",
      "\n",
      "Task Name : SCIDOCS-PL | Value : <class 'mteb.tasks.Retrieval.pol.SCIDOCSPLRetrieval.SCIDOCSPL'>\n",
      "\n",
      "Task Name : SciFact-PL | Value : <class 'mteb.tasks.Retrieval.pol.SciFactPLRetrieval.SciFactPL'>\n",
      "\n",
      "Task Name : TRECCOVID-PL | Value : <class 'mteb.tasks.Retrieval.pol.TRECCOVIDPLRetrieval.TRECCOVIDPL'>\n",
      "\n",
      "Task Name : RiaNewsRetrieval | Value : <class 'mteb.tasks.Retrieval.rus.RiaNewsRetrieval.RiaNewsRetrieval'>\n",
      "\n",
      "Task Name : RiaNewsRetrievalHardNegatives | Value : <class 'mteb.tasks.Retrieval.rus.RiaNewsRetrieval.RiaNewsRetrievalHardNegatives'>\n",
      "\n",
      "Task Name : RuBQRetrieval | Value : <class 'mteb.tasks.Retrieval.rus.RuBQRetrieval.RuBQRetrieval'>\n",
      "\n",
      "Task Name : SKQuadRetrieval | Value : <class 'mteb.tasks.Retrieval.slk.SKQuadRetrieval.SKQuadRetrieval'>\n",
      "\n",
      "Task Name : SlovakSumRetrieval | Value : <class 'mteb.tasks.Retrieval.slk.SlovakSumRetrieval.SlovakSumRetrieval'>\n",
      "\n",
      "Task Name : SpanishPassageRetrievalS2P | Value : <class 'mteb.tasks.Retrieval.spa.SpanishPassageRetrievalS2P.SpanishPassageRetrievalS2P'>\n",
      "\n",
      "Task Name : SpanishPassageRetrievalS2S | Value : <class 'mteb.tasks.Retrieval.spa.SpanishPassageRetrievalS2S.SpanishPassageRetrievalS2S'>\n",
      "\n",
      "Task Name : SwednRetrieval | Value : <class 'mteb.tasks.Retrieval.swe.SwednRetrieval.SwednRetrieval'>\n",
      "\n",
      "Task Name : SweFaqRetrieval | Value : <class 'mteb.tasks.Retrieval.swe.SweFaqRetrieval.SweFaqRetrieval'>\n",
      "\n",
      "Task Name : TurHistQuadRetrieval | Value : <class 'mteb.tasks.Retrieval.tur.TurHistQuad.TurHistQuadRetrieval'>\n",
      "\n",
      "Task Name : VieQuADRetrieval | Value : <class 'mteb.tasks.Retrieval.vie.VieQuADRetrieval.VieQuADRetrieval'>\n",
      "\n",
      "Task Name : T2Retrieval | Value : <class 'mteb.tasks.Retrieval.zho.CMTEBRetrieval.T2Retrieval'>\n",
      "\n",
      "Task Name : MMarcoRetrieval | Value : <class 'mteb.tasks.Retrieval.zho.CMTEBRetrieval.MMarcoRetrieval'>\n",
      "\n",
      "Task Name : DuRetrieval | Value : <class 'mteb.tasks.Retrieval.zho.CMTEBRetrieval.DuRetrieval'>\n",
      "\n",
      "Task Name : CovidRetrieval | Value : <class 'mteb.tasks.Retrieval.zho.CMTEBRetrieval.CovidRetrieval'>\n",
      "\n",
      "Task Name : CmedqaRetrieval | Value : <class 'mteb.tasks.Retrieval.zho.CMTEBRetrieval.CmedqaRetrieval'>\n",
      "\n",
      "Task Name : EcomRetrieval | Value : <class 'mteb.tasks.Retrieval.zho.CMTEBRetrieval.EcomRetrieval'>\n",
      "\n",
      "Task Name : MedicalRetrieval | Value : <class 'mteb.tasks.Retrieval.zho.CMTEBRetrieval.MedicalRetrieval'>\n",
      "\n",
      "Task Name : VideoRetrieval | Value : <class 'mteb.tasks.Retrieval.zho.CMTEBRetrieval.VideoRetrieval'>\n",
      "\n",
      "Task Name : LeCaRDv2 | Value : <class 'mteb.tasks.Retrieval.zho.LeCaRDv2Retrieval.LeCaRDv2'>\n",
      "\n",
      "Task Name : BLINKIT2IMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.BLINKIT2IMultiChoice.BLINKIT2IMultiChoice'>\n",
      "\n",
      "Task Name : BLINKIT2TMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.BLINKIT2TMultiChoice.BLINKIT2TMultiChoice'>\n",
      "\n",
      "Task Name : ImageCoDeT2IMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.ImageCoDeT2IMultiChoice.ImageCoDeT2IMultiChoice'>\n",
      "\n",
      "Task Name : ROxfordEasyI2IMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.ROxfordI2IMultiChoice.ROxfordEasyI2IMultiChoice'>\n",
      "\n",
      "Task Name : ROxfordMediumI2IMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.ROxfordI2IMultiChoice.ROxfordMediumI2IMultiChoice'>\n",
      "\n",
      "Task Name : ROxfordHardI2IMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.ROxfordI2IMultiChoice.ROxfordHardI2IMultiChoice'>\n",
      "\n",
      "Task Name : RParisEasyI2IMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.RParisI2IMultiChoice.RParisEasyI2IMultiChoice'>\n",
      "\n",
      "Task Name : RParisMediumI2IMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.RParisI2IMultiChoice.RParisMediumI2IMultiChoice'>\n",
      "\n",
      "Task Name : RParisHardI2IMultiChoice | Value : <class 'mteb.tasks.Image.Any2AnyMultiChoice.eng.RParisI2IMultiChoice.RParisHardI2IMultiChoice'>\n",
      "\n",
      "Task Name : BLINKIT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.BLINKIT2IRetrieval.BLINKIT2IRetrieval'>\n",
      "\n",
      "Task Name : BLINKIT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.BLINKIT2TRetrieval.BLINKIT2TRetrieval'>\n",
      "\n",
      "Task Name : CIRRIT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.CIRRIT2IRetrieval.CIRRIT2IRetrieval'>\n",
      "\n",
      "Task Name : CUB200I2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.CUB200I2IRetrieval.CUB200I2I'>\n",
      "\n",
      "Task Name : EDIST2ITRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.EDIST2ITRetrieval.EDIST2ITRetrieval'>\n",
      "\n",
      "Task Name : EncyclopediaVQAIT2ITRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.EncyclopediaVQAIT2ITRetrieval.EncyclopediaVQAIT2ITRetrieval'>\n",
      "\n",
      "Task Name : Fashion200kI2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.Fashion200kI2TRetrieval.Fashion200kI2TRetrieval'>\n",
      "\n",
      "Task Name : Fashion200kT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.Fashion200kT2IRetrieval.Fashion200kT2IRetrieval'>\n",
      "\n",
      "Task Name : FashionIQIT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.FashionIQIT2IRetrieval.FashionIQIT2IRetrieval'>\n",
      "\n",
      "Task Name : Flickr30kI2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.Flickr30kI2TRetrieval.Flickr30kI2TRetrieval'>\n",
      "\n",
      "Task Name : Flickr30kT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.Flickr30kT2IRetrieval.Flickr30kT2IRetrieval'>\n",
      "\n",
      "Task Name : FORBI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.FORBI2IRetrieval.FORBI2I'>\n",
      "\n",
      "Task Name : GLDv2I2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.GLDv2I2IRetrieval.GLDv2I2IRetrieval'>\n",
      "\n",
      "Task Name : GLDv2I2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.GLDv2I2TRetrieval.GLDv2I2TRetrieval'>\n",
      "\n",
      "Task Name : HatefulMemesI2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.HatefulMemesI2TRetrieval.HatefulMemesI2TRetrieval'>\n",
      "\n",
      "Task Name : HatefulMemesT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.HatefulMemesT2IRetrieval.HatefulMemesT2IRetrieval'>\n",
      "\n",
      "Task Name : ImageCoDeT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.ImageCoDeT2IRetrieval.ImageCoDeT2IRetrieval'>\n",
      "\n",
      "Task Name : InfoSeekIT2ITRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.InfoSeekIT2ITRetrieval.InfoSeekIT2ITRetrieval'>\n",
      "\n",
      "Task Name : InfoSeekIT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.InfoSeekIT2TRetrieval.InfoSeekIT2TRetrieval'>\n",
      "\n",
      "Task Name : LLaVAIT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.LLaVAIT2TRetrieval.LLaVAIT2TRetrieval'>\n",
      "\n",
      "Task Name : MemotionI2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.MemotionI2TRetrieval.MemotionI2TRetrieval'>\n",
      "\n",
      "Task Name : MemotionT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.MemotionT2IRetrieval.MemotionT2IRetrieval'>\n",
      "\n",
      "Task Name : METI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.METI2IRetrieval.METI2IRetrieval'>\n",
      "\n",
      "Task Name : MSCOCOI2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.MSCOCOI2TRetrieval.MSCOCOI2TRetrieval'>\n",
      "\n",
      "Task Name : MSCOCOT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.MSCOCOT2IRetrieval.MSCOCOT2IRetrieval'>\n",
      "\n",
      "Task Name : NIGHTSI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.NIGHTSI2IRetrieval.NIGHTSI2IRetrieval'>\n",
      "\n",
      "Task Name : OKVQAIT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.OKVQAIT2TRetrieval.OKVQAIT2TRetrieval'>\n",
      "\n",
      "Task Name : OVENIT2ITRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.OVENIT2ITRetrieval.OVENIT2ITRetrieval'>\n",
      "\n",
      "Task Name : OVENIT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.OVENIT2TRetrieval.OVENIT2TRetrieval'>\n",
      "\n",
      "Task Name : ReMuQIT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.ReMuQIT2TRetrieval.ReMuQIT2TRetrieval'>\n",
      "\n",
      "Task Name : ROxfordEasyI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.ROxfordI2IRetrieval.ROxfordEasyI2IRetrieval'>\n",
      "\n",
      "Task Name : ROxfordMediumI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.ROxfordI2IRetrieval.ROxfordMediumI2IRetrieval'>\n",
      "\n",
      "Task Name : ROxfordHardI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.ROxfordI2IRetrieval.ROxfordHardI2IRetrieval'>\n",
      "\n",
      "Task Name : RP2kI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.RP2kI2IRetrieval.RP2kI2IRetrieval'>\n",
      "\n",
      "Task Name : RParisEasyI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.RParisI2IRetrieval.RParisEasyI2IRetrieval'>\n",
      "\n",
      "Task Name : RParisMediumI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.RParisI2IRetrieval.RParisMediumI2IRetrieval'>\n",
      "\n",
      "Task Name : RParisHardI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.RParisI2IRetrieval.RParisHardI2IRetrieval'>\n",
      "\n",
      "Task Name : SciMMIRI2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.SciMMIRI2TRetrieval.SciMMIRI2TRetrieval'>\n",
      "\n",
      "Task Name : SciMMIRT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.SciMMIRT2IRetrieval.SciMMIRT2IRetrieval'>\n",
      "\n",
      "Task Name : SketchyI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.SketchyI2IRetrieval.SketchyI2IRetrieval'>\n",
      "\n",
      "Task Name : SOPI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.SOPI2IRetrieval.SOPI2IRetrieval'>\n",
      "\n",
      "Task Name : StanfordCarsI2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.StanfordCarsI2IRetrieval.StanfordCarsI2I'>\n",
      "\n",
      "Task Name : TUBerlinT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.TUBerlinT2IRetrieval.TUBerlinT2IRetrieval'>\n",
      "\n",
      "Task Name : VidoreArxivQARetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreArxivQARetrieval'>\n",
      "\n",
      "Task Name : VidoreDocVQARetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreDocVQARetrieval'>\n",
      "\n",
      "Task Name : VidoreInfoVQARetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreInfoVQARetrieval'>\n",
      "\n",
      "Task Name : VidoreTabfquadRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreTabfquadRetrieval'>\n",
      "\n",
      "Task Name : VidoreTatdqaRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreTatdqaRetrieval'>\n",
      "\n",
      "Task Name : VidoreShiftProjectRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreShiftProjectRetrieval'>\n",
      "\n",
      "Task Name : VidoreSyntheticDocQAAIRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreSyntheticDocQAAIRetrieval'>\n",
      "\n",
      "Task Name : VidoreSyntheticDocQAEnergyRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreSyntheticDocQAEnergyRetrieval'>\n",
      "\n",
      "Task Name : VidoreSyntheticDocQAGovernmentReportsRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreSyntheticDocQAGovernmentReportsRetrieval'>\n",
      "\n",
      "Task Name : VidoreSyntheticDocQAHealthcareIndustryRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VidoreBenchRetrieval.VidoreSyntheticDocQAHealthcareIndustryRetrieval'>\n",
      "\n",
      "Task Name : VisualNewsI2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VisualNewsI2TRetrieval.VisualNewsI2TRetrieval'>\n",
      "\n",
      "Task Name : VisualNewsT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VisualNewsT2IRetrieval.VisualNewsT2IRetrieval'>\n",
      "\n",
      "Task Name : VizWizIT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VizWizIT2TRetrieval.VizWizIT2TRetrieval'>\n",
      "\n",
      "Task Name : VQA2IT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.VQA2IT2TRetrieval.VQA2IT2TRetrieval'>\n",
      "\n",
      "Task Name : WebQAT2ITRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.WebQAT2ITRetrieval.WebQAT2ITRetrieval'>\n",
      "\n",
      "Task Name : WebQAT2TRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.eng.WebQAT2TRetrieval.WebQAT2TRetrieval'>\n",
      "\n",
      "Task Name : WITT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.multilingual.WITT2IRetrieval.WITT2IRetrieval'>\n",
      "\n",
      "Task Name : XFlickr30kCoT2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.multilingual.XFlickr30kCoT2IRetrieval.XFlickr30kCoT2IRetrieval'>\n",
      "\n",
      "Task Name : XM3600T2IRetrieval | Value : <class 'mteb.tasks.Image.Any2AnyRetrieval.multilingual.XM3600T2IRetrieval.XM3600T2IRetrieval'>\n",
      "\n",
      "Task Name : CVBenchCount | Value : <class 'mteb.tasks.Image.Any2TextMultipleChoice.eng.CVBench.CVBenchCount'>\n",
      "\n",
      "Task Name : CVBenchRelation | Value : <class 'mteb.tasks.Image.Any2TextMultipleChoice.eng.CVBench.CVBenchRelation'>\n",
      "\n",
      "Task Name : CVBenchDepth | Value : <class 'mteb.tasks.Image.Any2TextMultipleChoice.eng.CVBench.CVBenchDepth'>\n",
      "\n",
      "Task Name : CVBenchDistance | Value : <class 'mteb.tasks.Image.Any2TextMultipleChoice.eng.CVBench.CVBenchDistance'>\n",
      "\n",
      "Task Name : CIFAR10Clustering | Value : <class 'mteb.tasks.Image.Clustering.eng.CIFAR.CIFAR10Clustering'>\n",
      "\n",
      "Task Name : CIFAR100Clustering | Value : <class 'mteb.tasks.Image.Clustering.eng.CIFAR.CIFAR100Clustering'>\n",
      "\n",
      "Task Name : ImageNetDog15Clustering | Value : <class 'mteb.tasks.Image.Clustering.eng.ImageNet.ImageNetDog15Clustering'>\n",
      "\n",
      "Task Name : ImageNet10Clustering | Value : <class 'mteb.tasks.Image.Clustering.eng.ImageNet.ImageNet10Clustering'>\n",
      "\n",
      "Task Name : TinyImageNetClustering | Value : <class 'mteb.tasks.Image.Clustering.eng.TinyImageNet.TinyImageNet'>\n",
      "\n",
      "Task Name : Birdsnap | Value : <class 'mteb.tasks.Image.ImageClassification.eng.BirdsnapClassification.BirdsnapClassification'>\n",
      "\n",
      "Task Name : Caltech101 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.Caltech101Classification.Caltech101Classification'>\n",
      "\n",
      "Task Name : CIFAR10 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.CIFAR.CIFAR10Classification'>\n",
      "\n",
      "Task Name : CIFAR100 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.CIFAR.CIFAR100Classification'>\n",
      "\n",
      "Task Name : Country211 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.Country211Classification.Country211Classification'>\n",
      "\n",
      "Task Name : DTD | Value : <class 'mteb.tasks.Image.ImageClassification.eng.DTDClassification.DTDClassification'>\n",
      "\n",
      "Task Name : EuroSAT | Value : <class 'mteb.tasks.Image.ImageClassification.eng.EuroSATClassification.EuroSATClassification'>\n",
      "\n",
      "Task Name : FER2013 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.FER2013Classification.FER2013Classification'>\n",
      "\n",
      "Task Name : FGVCAircraft | Value : <class 'mteb.tasks.Image.ImageClassification.eng.FGVCAircraftClassification.FGVCAircraftClassification'>\n",
      "\n",
      "Task Name : Food101Classification | Value : <class 'mteb.tasks.Image.ImageClassification.eng.Food101Classification.Food101Classification'>\n",
      "\n",
      "Task Name : GTSRB | Value : <class 'mteb.tasks.Image.ImageClassification.eng.GTSRBClassification.GTSRBClassification'>\n",
      "\n",
      "Task Name : Imagenet1k | Value : <class 'mteb.tasks.Image.ImageClassification.eng.Imagenet1k.Imagenet1kClassification'>\n",
      "\n",
      "Task Name : MNIST | Value : <class 'mteb.tasks.Image.ImageClassification.eng.MNISTClassification.MNISTClassification'>\n",
      "\n",
      "Task Name : OxfordFlowersClassification | Value : <class 'mteb.tasks.Image.ImageClassification.eng.OxfordFlowersClassification.OxfordFlowersClassification'>\n",
      "\n",
      "Task Name : OxfordPets | Value : <class 'mteb.tasks.Image.ImageClassification.eng.OxfordPetsClassification.OxfordPetsClassification'>\n",
      "\n",
      "Task Name : PatchCamelyon | Value : <class 'mteb.tasks.Image.ImageClassification.eng.PatchCamelyonClassification.PatchCamelyonClassification'>\n",
      "\n",
      "Task Name : RESISC45 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.RESISC45Classification.RESISC45Classification'>\n",
      "\n",
      "Task Name : StanfordCars | Value : <class 'mteb.tasks.Image.ImageClassification.eng.StanfordCarsClassification.StanfordCarsClassification'>\n",
      "\n",
      "Task Name : STL10 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.STL10Classification.STL10Classification'>\n",
      "\n",
      "Task Name : SUN397 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.SUN397Classification.SUN397Classification'>\n",
      "\n",
      "Task Name : UCF101 | Value : <class 'mteb.tasks.Image.ImageClassification.eng.UCF101Classification.UCF101Classification'>\n",
      "\n",
      "Task Name : VOC2007 | Value : <class 'mteb.tasks.Image.ImageMultilabelClassification.eng.PascalVOC2007.VOC2007Classification'>\n",
      "\n",
      "Task Name : AROCocoOrder | Value : <class 'mteb.tasks.Image.ImageTextPairClassification.AROCocoOrder.AROCocoOrder'>\n",
      "\n",
      "Task Name : AROFlickrOrder | Value : <class 'mteb.tasks.Image.ImageTextPairClassification.AROFlickrOrder.AROFlickrOrder'>\n",
      "\n",
      "Task Name : AROVisualAttribution | Value : <class 'mteb.tasks.Image.ImageTextPairClassification.AROVisualAttribution.AROVisualAttribution'>\n",
      "\n",
      "Task Name : AROVisualRelation | Value : <class 'mteb.tasks.Image.ImageTextPairClassification.AROVisualRelation.AROVisualRelation'>\n",
      "\n",
      "Task Name : SugarCrepe | Value : <class 'mteb.tasks.Image.ImageTextPairClassification.SugarCrepe.SugarCrepe'>\n",
      "\n",
      "Task Name : Winoground | Value : <class 'mteb.tasks.Image.ImageTextPairClassification.Winoground.Winoground'>\n",
      "\n",
      "Task Name : STS12VisualSTS | Value : <class 'mteb.tasks.Image.VisualSTS.en.STS12VisualSTS.STS12VisualSTS'>\n",
      "\n",
      "Task Name : STS13VisualSTS | Value : <class 'mteb.tasks.Image.VisualSTS.en.STS13VisualSTS.STS13VisualSTS'>\n",
      "\n",
      "Task Name : STS14VisualSTS | Value : <class 'mteb.tasks.Image.VisualSTS.en.STS14VisualSTS.STS14VisualSTS'>\n",
      "\n",
      "Task Name : STS15VisualSTS | Value : <class 'mteb.tasks.Image.VisualSTS.en.STS15VisualSTS.STS15VisualSTS'>\n",
      "\n",
      "Task Name : STS16VisualSTS | Value : <class 'mteb.tasks.Image.VisualSTS.en.STS16VisualSTS.STS16VisualSTS'>\n",
      "\n",
      "Task Name : STS17MultilingualVisualSTS | Value : <class 'mteb.tasks.Image.VisualSTS.multilingual.STS17MultilingualVisualSTS.STS17MultilingualVisualSTS'>\n",
      "\n",
      "Task Name : STSBenchmarkMultilingualVisualSTS | Value : <class 'mteb.tasks.Image.VisualSTS.multilingual.STSBenchmarkMultilingualVisualSTS.STSBenchmarkMultilingualVisualSTS'>\n",
      "\n",
      "Task Name : BirdsnapZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.Birdsnap.BirdsnapZeroshotClassification'>\n",
      "\n",
      "Task Name : Caltech101ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.Caltech101.Caltech101ZeroshotClassification'>\n",
      "\n",
      "Task Name : CIFAR10ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.CIFAR.CIFAR10ZeroShotClassification'>\n",
      "\n",
      "Task Name : CIFAR100ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.CIFAR.CIFAR100ZeroShotClassification'>\n",
      "\n",
      "Task Name : CLEVRZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.CLEVR.CLEVR'>\n",
      "\n",
      "Task Name : CLEVRCountZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.CLEVR.CLEVRCount'>\n",
      "\n",
      "Task Name : Country211ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.Country211.Country211ZeroshotClassification'>\n",
      "\n",
      "Task Name : DTDZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.DTD.DTDZeroshotClassification'>\n",
      "\n",
      "Task Name : EuroSATZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.EuroSAT.EuroSATZeroshotClassification'>\n",
      "\n",
      "Task Name : FER2013ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.FER2013.FER2013ZeroshotClassification'>\n",
      "\n",
      "Task Name : FGVCAircraftZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.FGVCAircraft.FGVCAircraftZeroShotClassification'>\n",
      "\n",
      "Task Name : Food101ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.Food101.Food101ZeroShotClassification'>\n",
      "\n",
      "Task Name : GTSRBZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.GTSRB.GTSRBZeroshotClassification'>\n",
      "\n",
      "Task Name : Imagenet1kZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.Imagenet1k.Imagenet1kZeroshotClassification'>\n",
      "\n",
      "Task Name : MNISTZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.MNIST.MNISTZeroshotClassification'>\n",
      "\n",
      "Task Name : OxfordPetsZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.OxfordPets.OxfordPetsZeroshotClassification'>\n",
      "\n",
      "Task Name : PatchCamelyonZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.PatchCamelyon.PatchCamelyonZeroshotClassification'>\n",
      "\n",
      "Task Name : RenderedSST2 | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.RenderedSST2.RenderedSST2'>\n",
      "\n",
      "Task Name : RESISC45ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.RESISC45.RESISC45ZeroshotClassification'>\n",
      "\n",
      "Task Name : SciMMIR | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.SciMMIR.SciMMIR'>\n",
      "\n",
      "Task Name : StanfordCarsZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.StanfordCars.StanfordCarsZeroshotClassification'>\n",
      "\n",
      "Task Name : STL10ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.STL10.STL10ZeroshotClassification'>\n",
      "\n",
      "Task Name : SUN397ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.SUN397.SUN397ZeroshotClassification'>\n",
      "\n",
      "Task Name : UCF101ZeroShot | Value : <class 'mteb.tasks.Image.ZeroshotClassification.eng.UCF101.UCF101ZeroshotClassification'>\n",
      "\n",
      "Task Name : AJGT | Value : <class 'mteb.tasks.Classification.ara.AJGT.AJGT'>\n",
      "\n",
      "Task Name : HotelReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.ara.HotelReviewSentimentClassification.HotelReviewSentimentClassification'>\n",
      "\n",
      "Task Name : OnlineStoreReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.ara.OnlineStoreReviewSentimentClassification.OnlineStoreReviewSentimentClassification'>\n",
      "\n",
      "Task Name : RestaurantReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.ara.RestaurantReviewSentimentClassification.RestaurantReviewSentimentClassification'>\n",
      "\n",
      "Task Name : TweetEmotionClassification | Value : <class 'mteb.tasks.Classification.ara.TweetEmotionClassification.TweetEmotionClassification'>\n",
      "\n",
      "Task Name : TweetSarcasmClassification | Value : <class 'mteb.tasks.Classification.ara.TweetSarcasmClassification.TweetSarcasmClassification'>\n",
      "\n",
      "Task Name : BengaliDocumentClassification | Value : <class 'mteb.tasks.Classification.ben.BengaliDocumentClassification.BengaliDocumentClassification'>\n",
      "\n",
      "Task Name : BengaliHateSpeechClassification | Value : <class 'mteb.tasks.Classification.ben.BengaliHateSpeechClassification.BengaliHateSpeechClassification'>\n",
      "\n",
      "Task Name : BengaliSentimentAnalysis | Value : <class 'mteb.tasks.Classification.ben.BengaliSentimentAnalysis.BengaliSentimentAnalysis'>\n",
      "\n",
      "Task Name : BulgarianStoreReviewSentimentClassfication | Value : <class 'mteb.tasks.Classification.bul.BulgarianStoreReviewSentimentClassfication.BulgarianStoreReviewSentimentClassfication'>\n",
      "\n",
      "Task Name : CSFDCZMovieReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.ces.CSFDCZMovieReviewSentimentClassification.CSFDCZMovieReviewSentimentClassification'>\n",
      "\n",
      "Task Name : CzechProductReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.ces.CzechProductReviewSentimentClassification.CzechProductReviewSentimentClassification'>\n",
      "\n",
      "Task Name : CzechSoMeSentimentClassification | Value : <class 'mteb.tasks.Classification.ces.CzechSoMeSentimentClassification.CzechSoMeSentimentClassification'>\n",
      "\n",
      "Task Name : CzechSubjectivityClassification | Value : <class 'mteb.tasks.Classification.ces.CzechSubjectivityClassification.CzechSubjectivityClassification'>\n",
      "\n",
      "Task Name : AngryTweetsClassification | Value : <class 'mteb.tasks.Classification.dan.AngryTweetsClassification.AngryTweetsClassification'>\n",
      "\n",
      "Task Name : DanishPoliticalCommentsClassification | Value : <class 'mteb.tasks.Classification.dan.DanishPoliticalCommentsClassification.DanishPoliticalCommentsClassification'>\n",
      "\n",
      "Task Name : DKHateClassification | Value : <class 'mteb.tasks.Classification.dan.DKHateClassification.DKHateClassification'>\n",
      "\n",
      "Task Name : LccSentimentClassification | Value : <class 'mteb.tasks.Classification.dan.LccSentimentClassification.LccSentimentClassification'>\n",
      "\n",
      "Task Name : GermanPoliticiansTwitterSentimentClassification | Value : <class 'mteb.tasks.Classification.deu.GermanPoliticiansTwitterSentimentClassification.GermanPoliticiansTwitterSentimentClassification'>\n",
      "\n",
      "Task Name : TenKGnadClassification | Value : <class 'mteb.tasks.Classification.deu.TenKGnadClassification.TenKGnadClassification'>\n",
      "\n",
      "Task Name : GreekLegalCodeClassification | Value : <class 'mteb.tasks.Classification.ell.GreekLegalCodeClassification.GreekLegalCodeClassification'>\n",
      "\n",
      "Task Name : AmazonPolarityClassification | Value : <class 'mteb.tasks.Classification.eng.AmazonPolarityClassification.AmazonPolarityClassification'>\n",
      "\n",
      "Task Name : ArxivClassification | Value : <class 'mteb.tasks.Classification.eng.ArxivClassification.ArxivClassification'>\n",
      "\n",
      "Task Name : Banking77Classification | Value : <class 'mteb.tasks.Classification.eng.Banking77Classification.Banking77Classification'>\n",
      "\n",
      "Task Name : DBpediaClassification | Value : <class 'mteb.tasks.Classification.eng.DBpediaClassification.DBpediaClassification'>\n",
      "\n",
      "Task Name : EmotionClassification | Value : <class 'mteb.tasks.Classification.eng.EmotionClassification.EmotionClassification'>\n",
      "\n",
      "Task Name : FinancialPhrasebankClassification | Value : <class 'mteb.tasks.Classification.eng.FinancialPhrasebankClassification.FinancialPhrasebankClassification'>\n",
      "\n",
      "Task Name : FrenkEnClassification | Value : <class 'mteb.tasks.Classification.eng.FrenkEnClassification.FrenkEnClassification'>\n",
      "\n",
      "Task Name : ImdbClassification | Value : <class 'mteb.tasks.Classification.eng.ImdbClassification.ImdbClassification'>\n",
      "\n",
      "Task Name : CanadaTaxCourtOutcomesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CanadaTaxCourtOutcomesLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLIConfidentialityOfAgreementLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLIConfidentialityOfAgreementLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLIExplicitIdentificationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLIExplicitIdentificationLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLIInclusionOfVerballyConveyedInformationLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLILimitedUseLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLILimitedUseLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLINoLicensingLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLINoLicensingLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLINoticeOnCompelledDisclosureLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLINoticeOnCompelledDisclosureLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLIPermissibleAcquirementOfSimilarInformationLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLIPermissibleCopyLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLIPermissibleCopyLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLIPermissibleDevelopmentOfSimilarInformationLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLIPermissiblePostAgreementPossessionLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLIReturnOfConfidentialInformationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLIReturnOfConfidentialInformationLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLISharingWithEmployeesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLISharingWithEmployeesLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLISharingWithThirdPartiesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLISharingWithThirdPartiesLegalBenchClassification'>\n",
      "\n",
      "Task Name : ContractNLISurvivalOfObligationsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.ContractNLISurvivalOfObligationsLegalBenchClassification'>\n",
      "\n",
      "Task Name : CorporateLobbyingLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CorporateLobbyingLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADAffiliateLicenseLicenseeLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADAffiliateLicenseLicenseeLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADAffiliateLicenseLicensorLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADAffiliateLicenseLicensorLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADAntiAssignmentLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADAntiAssignmentLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADAuditRightsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADAuditRightsLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADCapOnLiabilityLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADCapOnLiabilityLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADChangeOfControlLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADChangeOfControlLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADCompetitiveRestrictionExceptionLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADCompetitiveRestrictionExceptionLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADCovenantNotToSueLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADCovenantNotToSueLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADEffectiveDateLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADEffectiveDateLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADExclusivityLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADExclusivityLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADExpirationDateLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADExpirationDateLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADGoverningLawLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADGoverningLawLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADInsuranceLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADInsuranceLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADIPOwnershipAssignmentLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADIPOwnershipAssignmentLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADIrrevocableOrPerpetualLicenseLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADIrrevocableOrPerpetualLicenseLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADJointIPOwnershipLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADJointIPOwnershipLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADLicenseGrantLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADLicenseGrantLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADLiquidatedDamagesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADLiquidatedDamagesLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADMinimumCommitmentLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADMinimumCommitmentLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADMostFavoredNationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADMostFavoredNationLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADNoSolicitOfCustomersLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADNoSolicitOfCustomersLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADNoSolicitOfEmployeesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADNoSolicitOfEmployeesLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADNonCompeteLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADNonCompeteLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADNonDisparagementLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADNonDisparagementLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADNonTransferableLicenseLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADNonTransferableLicenseLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADNoticePeriodToTerminateRenewalLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADNoticePeriodToTerminateRenewalLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADPostTerminationServicesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADPostTerminationServicesLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADPriceRestrictionsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADPriceRestrictionsLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADRenewalTermLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADRenewalTermLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADRevenueProfitSharingLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADRevenueProfitSharingLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADRofrRofoRofnLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADRofrRofoRofnLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADSourceCodeEscrowLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADSourceCodeEscrowLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADTerminationForConvenienceLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADTerminationForConvenienceLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADThirdPartyBeneficiaryLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADThirdPartyBeneficiaryLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADUncappedLiabilityLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADUncappedLiabilityLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADUnlimitedAllYouCanEatLicenseLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADVolumeRestrictionLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADVolumeRestrictionLegalBenchClassification'>\n",
      "\n",
      "Task Name : CUADWarrantyDurationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.CUADWarrantyDurationLegalBenchClassification'>\n",
      "\n",
      "Task Name : DefinitionClassificationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.DefinitionClassificationLegalBenchClassification'>\n",
      "\n",
      "Task Name : Diversity1LegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.Diversity1LegalBenchClassification'>\n",
      "\n",
      "Task Name : Diversity2LegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.Diversity2LegalBenchClassification'>\n",
      "\n",
      "Task Name : Diversity3LegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.Diversity3LegalBenchClassification'>\n",
      "\n",
      "Task Name : Diversity4LegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.Diversity4LegalBenchClassification'>\n",
      "\n",
      "Task Name : Diversity5LegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.Diversity5LegalBenchClassification'>\n",
      "\n",
      "Task Name : Diversity6LegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.Diversity6LegalBenchClassification'>\n",
      "\n",
      "Task Name : FunctionOfDecisionSectionLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.FunctionOfDecisionSectionLegalBenchClassification'>\n",
      "\n",
      "Task Name : InsurancePolicyInterpretationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.InsurancePolicyInterpretationLegalBenchClassification'>\n",
      "\n",
      "Task Name : InternationalCitizenshipQuestionsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.InternationalCitizenshipQuestionsLegalBenchClassification'>\n",
      "\n",
      "Task Name : JCrewBlockerLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.JCrewBlockerLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsBenefitsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsBenefitsLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsBusinessLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsBusinessLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsConsumerLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsConsumerLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsCourtsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsCourtsLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsCrimeLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsCrimeLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsDivorceLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsDivorceLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsDomesticViolenceLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsDomesticViolenceLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsEducationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsEducationLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsEmploymentLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsEmploymentLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsEstatesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsEstatesLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsFamilyLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsFamilyLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsHealthLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsHealthLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsHousingLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsHousingLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsImmigrationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsImmigrationLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsTortsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsTortsLegalBenchClassification'>\n",
      "\n",
      "Task Name : LearnedHandsTrafficLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LearnedHandsTrafficLegalBenchClassification'>\n",
      "\n",
      "Task Name : LegalReasoningCausalityLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.LegalReasoningCausalityLegalBenchClassification'>\n",
      "\n",
      "Task Name : MAUDLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.MAUDLegalBenchClassification'>\n",
      "\n",
      "Task Name : NYSJudicialEthicsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.NYSJudicialEthicsLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115DataRetentionLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115DataRetentionLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115DataSecurityLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115DataSecurityLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115DoNotTrackLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115DoNotTrackLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115FirstPartyCollectionUseLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115FirstPartyCollectionUseLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115InternationalAndSpecificAudiencesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115InternationalAndSpecificAudiencesLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115PolicyChangeLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115PolicyChangeLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115ThirdPartySharingCollectionLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115ThirdPartySharingCollectionLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115UserAccessEditAndDeletionLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115UserAccessEditAndDeletionLegalBenchClassification'>\n",
      "\n",
      "Task Name : OPP115UserChoiceControlLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OPP115UserChoiceControlLegalBenchClassification'>\n",
      "\n",
      "Task Name : OralArgumentQuestionPurposeLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OralArgumentQuestionPurposeLegalBenchClassification'>\n",
      "\n",
      "Task Name : OverrulingLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.OverrulingLegalBenchClassification'>\n",
      "\n",
      "Task Name : PersonalJurisdictionLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.PersonalJurisdictionLegalBenchClassification'>\n",
      "\n",
      "Task Name : PROALegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.PROALegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDBPAccountabilityLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDBPAccountabilityLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDBPAuditsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDBPAuditsLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDBPCertificationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDBPCertificationLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDBPTrainingLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDBPTrainingLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDBPVerificationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDBPVerificationLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDDAccountabilityLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDDAccountabilityLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDDAuditsLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDDAuditsLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDDCertificationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDDCertificationLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDDTrainingLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDDTrainingLegalBenchClassification'>\n",
      "\n",
      "Task Name : SCDDVerificationLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.SCDDVerificationLegalBenchClassification'>\n",
      "\n",
      "Task Name : TelemarketingSalesRuleLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.TelemarketingSalesRuleLegalBenchClassification'>\n",
      "\n",
      "Task Name : TextualismToolDictionariesLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.TextualismToolDictionariesLegalBenchClassification'>\n",
      "\n",
      "Task Name : TextualismToolPlainLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.TextualismToolPlainLegalBenchClassification'>\n",
      "\n",
      "Task Name : UCCVCommonLawLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.UCCVCommonLawLegalBenchClassification'>\n",
      "\n",
      "Task Name : UnfairTOSLegalBenchClassification | Value : <class 'mteb.tasks.Classification.eng.LegalBenchClassification.UnfairTOSLegalBenchClassification'>\n",
      "\n",
      "Task Name : NewsClassification | Value : <class 'mteb.tasks.Classification.eng.NewsClassification.NewsClassification'>\n",
      "\n",
      "Task Name : PatentClassification | Value : <class 'mteb.tasks.Classification.eng.PatentClassification.PatentClassification'>\n",
      "\n",
      "Task Name : PoemSentimentClassification | Value : <class 'mteb.tasks.Classification.eng.PoemSentimentClassification.PoemSentimentClassification'>\n",
      "\n",
      "Task Name : SDSEyeProtectionClassification | Value : <class 'mteb.tasks.Classification.eng.SDSEyeProtectionClassification.SDSEyeProtectionClassification'>\n",
      "\n",
      "Task Name : SDSGlovesClassification | Value : <class 'mteb.tasks.Classification.eng.SDSGlovesClassification.SDSGlovesClassification'>\n",
      "\n",
      "Task Name : ToxicChatClassification | Value : <class 'mteb.tasks.Classification.eng.ToxicChatClassification.ToxicChatClassification'>\n",
      "\n",
      "Task Name : ToxicConversationsClassification | Value : <class 'mteb.tasks.Classification.eng.ToxicConversationsClassification.ToxicConversationsClassification'>\n",
      "\n",
      "Task Name : TweetSentimentExtractionClassification | Value : <class 'mteb.tasks.Classification.eng.TweetSentimentExtractionClassification.TweetSentimentExtractionClassification'>\n",
      "\n",
      "Task Name : TweetTopicSingleClassification | Value : <class 'mteb.tasks.Classification.eng.TweetTopicSingleClassification.TweetTopicSingleClassification'>\n",
      "\n",
      "Task Name : WikipediaBiolumNeurochemClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaBiolumNeurochemClassification.WikipediaBiolumNeurochemClassification'>\n",
      "\n",
      "Task Name : WikipediaBioMetChemClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaBioMetChemClassification.WikipediaBioMetChemClassification'>\n",
      "\n",
      "Task Name : WikipediaChemEngSpecialtiesClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaChemEngSpecialtiesClassification.WikipediaChemEngSpecialtiesClassification'>\n",
      "\n",
      "Task Name : WikipediaChemFieldsClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaChemFieldsClassification.WikipediaChemFieldsClassification'>\n",
      "\n",
      "Task Name : WikipediaChemistryTopicsClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaChemistryTopicsClassification.WikipediaChemistryTopicsClassification'>\n",
      "\n",
      "Task Name : WikipediaCompChemSpectroscopyClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaCompChemSpectroscopyClassification.WikipediaCompChemSpectroscopyClassification'>\n",
      "\n",
      "Task Name : WikipediaCryobiologySeparationClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaCryobiologySeparationClassification.WikipediaCryobiologySeparationClassification'>\n",
      "\n",
      "Task Name : WikipediaCrystallographyAnalyticalClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaCrystallographyAnalyticalClassification.WikipediaCrystallographyAnalyticalClassification'>\n",
      "\n",
      "Task Name : WikipediaGreenhouseEnantiopureClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaGreenhouseEnantiopureClassification.WikipediaGreenhouseEnantiopureClassification'>\n",
      "\n",
      "Task Name : WikipediaIsotopesFissionClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaIsotopesFissionClassification.WikipediaIsotopesFissionClassification'>\n",
      "\n",
      "Task Name : WikipediaLuminescenceClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaLuminescenceClassification.WikipediaLuminescenceClassification'>\n",
      "\n",
      "Task Name : WikipediaOrganicInorganicClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaOrganicInorganicClassification.WikipediaOrganicInorganicClassification'>\n",
      "\n",
      "Task Name : WikipediaSaltsSemiconductorsClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaSaltsSemiconductorsClassification.WikipediaSaltsSemiconductorsClassification'>\n",
      "\n",
      "Task Name : WikipediaSolidStateColloidalClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaSolidStateColloidalClassification.WikipediaSolidStateColloidalClassification'>\n",
      "\n",
      "Task Name : WikipediaTheoreticalAppliedClassification | Value : <class 'mteb.tasks.Classification.eng.WikipediaTheoreticalAppliedClassification.WikipediaTheoreticalAppliedClassification'>\n",
      "\n",
      "Task Name : YahooAnswersTopicsClassification | Value : <class 'mteb.tasks.Classification.eng.YahooAnswersTopicsClassification.YahooAnswersTopicsClassification'>\n",
      "\n",
      "Task Name : YelpReviewFullClassification | Value : <class 'mteb.tasks.Classification.eng.YelpReviewFullClassification.YelpReviewFullClassification'>\n",
      "\n",
      "Task Name : EstonianValenceClassification | Value : <class 'mteb.tasks.Classification.est.estonian_valence.EstonianValenceClassification'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSAAnger | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSAAnger'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSASatisfaction | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSASatisfaction'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSAFriendship | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSAFriendship'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSAFear | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSAFear'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSAJealousy | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSAJealousy'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSASurprise | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSASurprise'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSALove | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSALove'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSASadness | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSASadness'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSAHappiness | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSAHappiness'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSAToneChatbotClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSAToneChatbotClassification'>\n",
      "\n",
      "Task Name : SynPerChatbotConvSAToneUserClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotConvSAToneUserClassification'>\n",
      "\n",
      "Task Name : SynPerChatbotSatisfactionLevelClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotSatisfactionLevelClassification'>\n",
      "\n",
      "Task Name : SynPerChatbotRAGToneChatbotClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotRAGToneChatbotClassification'>\n",
      "\n",
      "Task Name : SynPerChatbotRAGToneUserClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotRAGToneUserClassification'>\n",
      "\n",
      "Task Name : SynPerChatbotToneChatbotClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotToneChatbotClassification'>\n",
      "\n",
      "Task Name : SynPerChatbotToneUserClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SynPerChatbotToneUserClassification'>\n",
      "\n",
      "Task Name : PersianTextTone | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.PersianTextTone'>\n",
      "\n",
      "Task Name : SIDClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SIDClassification'>\n",
      "\n",
      "Task Name : DeepSentiPers | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.DeepSentiPers'>\n",
      "\n",
      "Task Name : PersianTextEmotion | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.PersianTextEmotion'>\n",
      "\n",
      "Task Name : SentimentDKSF | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.SentimentDKSF'>\n",
      "\n",
      "Task Name : NLPTwitterAnalysisClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.NLPTwitterAnalysisClassification'>\n",
      "\n",
      "Task Name : DigikalamagClassification | Value : <class 'mteb.tasks.Classification.fas.FaMTEBClassification.DigikalamagClassification'>\n",
      "\n",
      "Task Name : PersianFoodSentimentClassification | Value : <class 'mteb.tasks.Classification.fas.PersianFoodSentimentClassification.PersianFoodSentimentClassification'>\n",
      "\n",
      "Task Name : FilipinoHateSpeechClassification | Value : <class 'mteb.tasks.Classification.fil.FilipinoHateSpeechClassification.FilipinoHateSpeechClassification'>\n",
      "\n",
      "Task Name : FilipinoShopeeReviewsClassification | Value : <class 'mteb.tasks.Classification.fil.FilipinoShopeeReviewsClassification.FilipinoShopeeReviewsClassification'>\n",
      "\n",
      "Task Name : FinToxicityClassification | Value : <class 'mteb.tasks.Classification.fin.FinToxicityClassification.FinToxicityClassification'>\n",
      "\n",
      "Task Name : FrenchBookReviews | Value : <class 'mteb.tasks.Classification.fra.FrenchBookReviews.FrenchBookReviews'>\n",
      "\n",
      "Task Name : MovieReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.fra.MovieReviewSentimentClassification.MovieReviewSentimentClassification'>\n",
      "\n",
      "Task Name : GujaratiNewsClassification | Value : <class 'mteb.tasks.Classification.guj.GujaratiNewsClassification.GujaratiNewsClassification'>\n",
      "\n",
      "Task Name : HebrewSentimentAnalysis | Value : <class 'mteb.tasks.Classification.heb.HebrewSentimentAnalysis.HebrewSentimentAnalysis'>\n",
      "\n",
      "Task Name : HindiDiscourseClassification | Value : <class 'mteb.tasks.Classification.hin.HindiDiscourseClassification.HindiDiscourseClassification'>\n",
      "\n",
      "Task Name : SentimentAnalysisHindi | Value : <class 'mteb.tasks.Classification.hin.SentimentAnalysisHindi.SentimentAnalysisHindi'>\n",
      "\n",
      "Task Name : FrenkHrClassification | Value : <class 'mteb.tasks.Classification.hrv.FrenkHrClassification.FrenkHrClassification'>\n",
      "\n",
      "Task Name : IndonesianIdClickbaitClassification | Value : <class 'mteb.tasks.Classification.ind.IndonesianIdClickbaitClassification.IndonesianIdClickbaitClassification'>\n",
      "\n",
      "Task Name : IndonesianMongabayConservationClassification | Value : <class 'mteb.tasks.Classification.ind.IndonesianMongabayConservationClassification.IndonesianMongabayConservationClassification'>\n",
      "\n",
      "Task Name : ItaCaseholdClassification | Value : <class 'mteb.tasks.Classification.ita.ItaCaseholdClassification.ItaCaseholdClassification'>\n",
      "\n",
      "Task Name : Itacola | Value : <class 'mteb.tasks.Classification.ita.ItalianLinguistAcceptabilityClassification.ItalianLinguisticAcceptabilityClassification'>\n",
      "\n",
      "Task Name : JavaneseIMDBClassification | Value : <class 'mteb.tasks.Classification.jav.JavaneseIMDBClassification.JavaneseIMDBClassification'>\n",
      "\n",
      "Task Name : WRIMEClassification | Value : <class 'mteb.tasks.Classification.jpn.WRIMEClassification.WRIMEClassification'>\n",
      "\n",
      "Task Name : KannadaNewsClassification | Value : <class 'mteb.tasks.Classification.kan.KannadaNewsClassification.KannadaNewsClassification'>\n",
      "\n",
      "Task Name : KLUE-TC | Value : <class 'mteb.tasks.Classification.kor.KlueTC.KlueTC'>\n",
      "\n",
      "Task Name : KorFin | Value : <class 'mteb.tasks.Classification.kor.KorFin.KorFin'>\n",
      "\n",
      "Task Name : KorHateClassification | Value : <class 'mteb.tasks.Classification.kor.KorHateClassification.KorHateClassification'>\n",
      "\n",
      "Task Name : KorSarcasmClassification | Value : <class 'mteb.tasks.Classification.kor.KorSarcasmClassification.KorSarcasmClassification'>\n",
      "\n",
      "Task Name : KurdishSentimentClassification | Value : <class 'mteb.tasks.Classification.kur.KurdishSentimentClassification.KurdishSentimentClassification'>\n",
      "\n",
      "Task Name : MalayalamNewsClassification | Value : <class 'mteb.tasks.Classification.mal.MalayalamNewsClassification.MalayalamNewsClassification'>\n",
      "\n",
      "Task Name : MarathiNewsClassification | Value : <class 'mteb.tasks.Classification.mar.MarathiNewsClassification.MarathiNewsClassification'>\n",
      "\n",
      "Task Name : MacedonianTweetSentimentClassification | Value : <class 'mteb.tasks.Classification.mkd.MacedonianTweetSentimentClassification.MacedonianTweetSentimentClassification'>\n",
      "\n",
      "Task Name : AfriSentiClassification | Value : <class 'mteb.tasks.Classification.multilingual.AfriSentiClassification.AfriSentiClassification'>\n",
      "\n",
      "Task Name : AfriSentiLangClassification | Value : <class 'mteb.tasks.Classification.multilingual.AfriSentiLangClassification.AfriSentiLangClassification'>\n",
      "\n",
      "Task Name : AmazonCounterfactualClassification | Value : <class 'mteb.tasks.Classification.multilingual.AmazonCounterfactualClassification.AmazonCounterfactualClassification'>\n",
      "\n",
      "Task Name : AmazonReviewsClassification | Value : <class 'mteb.tasks.Classification.multilingual.AmazonReviewsClassification.AmazonReviewsClassification'>\n",
      "\n",
      "Task Name : CataloniaTweetClassification | Value : <class 'mteb.tasks.Classification.multilingual.CataloniaTweetClassification.CataloniaTweetClassification'>\n",
      "\n",
      "Task Name : CyrillicTurkicLangClassification | Value : <class 'mteb.tasks.Classification.multilingual.CyrillicTurkicLangClassification.CyrillicTurkicLangClassification'>\n",
      "\n",
      "Task Name : HinDialectClassification | Value : <class 'mteb.tasks.Classification.multilingual.HinDialectClassification.HinDialectClassification'>\n",
      "\n",
      "Task Name : IndicLangClassification | Value : <class 'mteb.tasks.Classification.multilingual.IndicLangClassification.IndicLangClassification'>\n",
      "\n",
      "Task Name : IndicNLPNewsClassification | Value : <class 'mteb.tasks.Classification.multilingual.IndicNLPNewsClassification.IndicNLPNewsClassification'>\n",
      "\n",
      "Task Name : IndicSentimentClassification | Value : <class 'mteb.tasks.Classification.multilingual.IndicSentimentClassification.IndicSentimentClassification'>\n",
      "\n",
      "Task Name : LanguageClassification | Value : <class 'mteb.tasks.Classification.multilingual.LanguageClassification.LanguageClassification'>\n",
      "\n",
      "Task Name : MasakhaNEWSClassification | Value : <class 'mteb.tasks.Classification.multilingual.MasakhaNEWSClassification.MasakhaNEWSClassification'>\n",
      "\n",
      "Task Name : MassiveIntentClassification | Value : <class 'mteb.tasks.Classification.multilingual.MassiveIntentClassification.MassiveIntentClassification'>\n",
      "\n",
      "Task Name : MassiveScenarioClassification | Value : <class 'mteb.tasks.Classification.multilingual.MassiveScenarioClassification.MassiveScenarioClassification'>\n",
      "\n",
      "Task Name : MTOPDomainClassification | Value : <class 'mteb.tasks.Classification.multilingual.MTOPDomainClassification.MTOPDomainClassification'>\n",
      "\n",
      "Task Name : MTOPIntentClassification | Value : <class 'mteb.tasks.Classification.multilingual.MTOPIntentClassification.MTOPIntentClassification'>\n",
      "\n",
      "Task Name : MultiHateClassification | Value : <class 'mteb.tasks.Classification.multilingual.MultiHateClassification.MultiHateClassification'>\n",
      "\n",
      "Task Name : MultilingualSentimentClassification | Value : <class 'mteb.tasks.Classification.multilingual.MultilingualSentimentClassification.MultilingualSentimentClassification'>\n",
      "\n",
      "Task Name : NaijaSenti | Value : <class 'mteb.tasks.Classification.multilingual.NaijaSenti.NaijaSenti'>\n",
      "\n",
      "Task Name : NordicLangClassification | Value : <class 'mteb.tasks.Classification.multilingual.NordicLangClassification.NordicLangClassification'>\n",
      "\n",
      "Task Name : NusaParagraphEmotionClassification | Value : <class 'mteb.tasks.Classification.multilingual.NusaParagraphEmotionClassification.NusaParagraphEmotionClassification'>\n",
      "\n",
      "Task Name : NusaParagraphTopicClassification | Value : <class 'mteb.tasks.Classification.multilingual.NusaParagraphTopicClassification.NusaParagraphTopicClassification'>\n",
      "\n",
      "Task Name : NusaX-senti | Value : <class 'mteb.tasks.Classification.multilingual.NusaXSenti.NusaXSentiClassification'>\n",
      "\n",
      "Task Name : ScalaClassification | Value : <class 'mteb.tasks.Classification.multilingual.ScalaClassification.ScalaClassification'>\n",
      "\n",
      "Task Name : SIB200Classification | Value : <class 'mteb.tasks.Classification.multilingual.SIB200Classification.SIB200Classification'>\n",
      "\n",
      "Task Name : SouthAfricanLangClassification | Value : <class 'mteb.tasks.Classification.multilingual.SouthAfricanLangClassification.SouthAfricanLangClassification'>\n",
      "\n",
      "Task Name : SwissJudgementClassification | Value : <class 'mteb.tasks.Classification.multilingual.SwissJudgementClassification.SwissJudgementClassification'>\n",
      "\n",
      "Task Name : TurkicClassification | Value : <class 'mteb.tasks.Classification.multilingual.TurkicClassification.TurkicClassification'>\n",
      "\n",
      "Task Name : TweetSentimentClassification | Value : <class 'mteb.tasks.Classification.multilingual.TweetSentimentClassification.TweetSentimentClassification'>\n",
      "\n",
      "Task Name : MyanmarNews | Value : <class 'mteb.tasks.Classification.mya.MyanmarNews.MyanmarNews'>\n",
      "\n",
      "Task Name : NepaliNewsClassification | Value : <class 'mteb.tasks.Classification.nep.NepaliNewsClassification.NepaliNewsClassification'>\n",
      "\n",
      "Task Name : DutchBookReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.nld.DutchBookReviewSentimentClassification.DutchBookReviewSentimentClassification'>\n",
      "\n",
      "Task Name : NoRecClassification | Value : <class 'mteb.tasks.Classification.nob.NoRecClassification.NoRecClassification'>\n",
      "\n",
      "Task Name : NorwegianParliamentClassification | Value : <class 'mteb.tasks.Classification.nob.NorwegianParliamentClassification.NorwegianParliamentClassification'>\n",
      "\n",
      "Task Name : OdiaNewsClassification | Value : <class 'mteb.tasks.Classification.ory.OdiaNewsClassification.OdiaNewsClassification'>\n",
      "\n",
      "Task Name : PunjabiNewsClassification | Value : <class 'mteb.tasks.Classification.pan.PunjabiNewsClassification.PunjabiNewsClassification'>\n",
      "\n",
      "Task Name : CBD | Value : <class 'mteb.tasks.Classification.pol.PolishClassification.CbdClassification'>\n",
      "\n",
      "Task Name : PolEmo2.0-IN | Value : <class 'mteb.tasks.Classification.pol.PolishClassification.PolEmo2InClassification'>\n",
      "\n",
      "Task Name : PolEmo2.0-OUT | Value : <class 'mteb.tasks.Classification.pol.PolishClassification.PolEmo2OutClassification'>\n",
      "\n",
      "Task Name : AllegroReviews | Value : <class 'mteb.tasks.Classification.pol.PolishClassification.AllegroReviewsClassification'>\n",
      "\n",
      "Task Name : PAC | Value : <class 'mteb.tasks.Classification.pol.PolishClassification.PacClassification'>\n",
      "\n",
      "Task Name : HateSpeechPortugueseClassification | Value : <class 'mteb.tasks.Classification.por.HateSpeechPortugueseClassification.HateSpeechPortugueseClassification'>\n",
      "\n",
      "Task Name : Moroco | Value : <class 'mteb.tasks.Classification.ron.Moroco.Moroco'>\n",
      "\n",
      "Task Name : RomanianReviewsSentiment | Value : <class 'mteb.tasks.Classification.ron.RomanianReviewsSentiment.RomanianReviewsSentiment'>\n",
      "\n",
      "Task Name : RomanianSentimentClassification | Value : <class 'mteb.tasks.Classification.ron.RomanianSentimentClassification.RomanianSentimentClassification'>\n",
      "\n",
      "Task Name : GeoreviewClassification | Value : <class 'mteb.tasks.Classification.rus.GeoreviewClassification.GeoreviewClassification'>\n",
      "\n",
      "Task Name : HeadlineClassification | Value : <class 'mteb.tasks.Classification.rus.HeadlineClassification.HeadlineClassification'>\n",
      "\n",
      "Task Name : InappropriatenessClassification | Value : <class 'mteb.tasks.Classification.rus.InappropriatenessClassification.InappropriatenessClassification'>\n",
      "\n",
      "Task Name : KinopoiskClassification | Value : <class 'mteb.tasks.Classification.rus.KinopoiskClassification.KinopoiskClassification'>\n",
      "\n",
      "Task Name : RuReviewsClassification | Value : <class 'mteb.tasks.Classification.rus.RuReviewsClassification.RuReviewsClassification'>\n",
      "\n",
      "Task Name : RuSciBenchGRNTIClassification | Value : <class 'mteb.tasks.Classification.rus.RuSciBenchGRNTIClassification.RuSciBenchGRNTIClassification'>\n",
      "\n",
      "Task Name : RuSciBenchOECDClassification | Value : <class 'mteb.tasks.Classification.rus.RuSciBenchOECDClassification.RuSciBenchOECDClassification'>\n",
      "\n",
      "Task Name : SanskritShlokasClassification | Value : <class 'mteb.tasks.Classification.san.SanskritShlokasClassification.SanskritShlokasClassification'>\n",
      "\n",
      "Task Name : SinhalaNewsClassification | Value : <class 'mteb.tasks.Classification.sin.SinhalaNewsClassification.SinhalaNewsClassification'>\n",
      "\n",
      "Task Name : SinhalaNewsSourceClassification | Value : <class 'mteb.tasks.Classification.sin.SinhalaNewsSourceClassification.SinhalaNewsSourceClassification'>\n",
      "\n",
      "Task Name : CSFDSKMovieReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.slk.CSFDSKMovieReviewSentimentClassification.CSFDSKMovieReviewSentimentClassification'>\n",
      "\n",
      "Task Name : SlovakHateSpeechClassification | Value : <class 'mteb.tasks.Classification.slk.SlovakHateSpeechClassification.SlovakHateSpeechClassification'>\n",
      "\n",
      "Task Name : FrenkSlClassification | Value : <class 'mteb.tasks.Classification.slv.FrenkSlClassification.FrenkSlClassification'>\n",
      "\n",
      "Task Name : SpanishNewsClassification | Value : <class 'mteb.tasks.Classification.spa.SpanishNewsClassification.SpanishNewsClassification'>\n",
      "\n",
      "Task Name : SpanishSentimentClassification | Value : <class 'mteb.tasks.Classification.spa.SpanishSentimentClassification.SpanishSentimentClassification'>\n",
      "\n",
      "Task Name : SiswatiNewsClassification | Value : <class 'mteb.tasks.Classification.ssw.SiswatiNewsClassification.SiswatiNewsClassification'>\n",
      "\n",
      "Task Name : SlovakMovieReviewSentimentClassification | Value : <class 'mteb.tasks.Classification.svk.SlovakMovieReviewSentimentClassification.SlovakMovieReviewSentimentClassification'>\n",
      "\n",
      "Task Name : SwahiliNewsClassification | Value : <class 'mteb.tasks.Classification.swa.SwahiliNewsClassification.SwahiliNewsClassification'>\n",
      "\n",
      "Task Name : DalajClassification | Value : <class 'mteb.tasks.Classification.swe.DalajClassification.DalajClassification'>\n",
      "\n",
      "Task Name : SwedishSentimentClassification | Value : <class 'mteb.tasks.Classification.swe.SwedishSentimentClassification.SwedishSentimentClassification'>\n",
      "\n",
      "Task Name : SweRecClassification | Value : <class 'mteb.tasks.Classification.swe.SweRecClassification.SweRecClassification'>\n",
      "\n",
      "Task Name : TamilNewsClassification | Value : <class 'mteb.tasks.Classification.tam.TamilNewsClassification.TamilNewsClassification'>\n",
      "\n",
      "Task Name : TeluguAndhraJyotiNewsClassification | Value : <class 'mteb.tasks.Classification.tel.TeluguAndhraJyotiNewsClassification.TeluguAndhraJyotiNewsClassification'>\n",
      "\n",
      "Task Name : WisesightSentimentClassification | Value : <class 'mteb.tasks.Classification.tha.WisesightSentimentClassification.WisesightSentimentClassification'>\n",
      "\n",
      "Task Name : TswanaNewsClassification | Value : <class 'mteb.tasks.Classification.tsn.TswanaNewsClassification.TswanaNewsClassification'>\n",
      "\n",
      "Task Name : TurkishMovieSentimentClassification | Value : <class 'mteb.tasks.Classification.tur.TurkishMovieSentimentClassification.TurkishMovieSentimentClassification'>\n",
      "\n",
      "Task Name : TurkishProductSentimentClassification | Value : <class 'mteb.tasks.Classification.tur.TurkishProductSentimentClassification.TurkishProductSentimentClassification'>\n",
      "\n",
      "Task Name : UkrFormalityClassification | Value : <class 'mteb.tasks.Classification.ukr.UkrFormalityClassification.UkrFormalityClassification'>\n",
      "\n",
      "Task Name : UrduRomanSentimentClassification | Value : <class 'mteb.tasks.Classification.urd.UrduRomanSentimentClassification.UrduRomanSentimentClassification'>\n",
      "\n",
      "Task Name : VieStudentFeedbackClassification | Value : <class 'mteb.tasks.Classification.vie.VieStudentFeedbackClassification.VieStudentFeedbackClassification'>\n",
      "\n",
      "Task Name : TNews | Value : <class 'mteb.tasks.Classification.zho.CMTEBClassification.TNews'>\n",
      "\n",
      "Task Name : IFlyTek | Value : <class 'mteb.tasks.Classification.zho.CMTEBClassification.IFlyTek'>\n",
      "\n",
      "Task Name : MultilingualSentiment | Value : <class 'mteb.tasks.Classification.zho.CMTEBClassification.MultilingualSentiment'>\n",
      "\n",
      "Task Name : JDReview | Value : <class 'mteb.tasks.Classification.zho.CMTEBClassification.JDReview'>\n",
      "\n",
      "Task Name : OnlineShopping | Value : <class 'mteb.tasks.Classification.zho.CMTEBClassification.OnlineShopping'>\n",
      "\n",
      "Task Name : Waimai | Value : <class 'mteb.tasks.Classification.zho.CMTEBClassification.Waimai'>\n",
      "\n",
      "Task Name : YueOpenriceReviewClassification | Value : <class 'mteb.tasks.Classification.zho.YueOpenriceReviewClassification.YueOpenriceReviewClassification'>\n",
      "\n",
      "Task Name : IsiZuluNewsClassification | Value : <class 'mteb.tasks.Classification.zul.IsiZuluNewsClassification.IsiZuluNewsClassification'>\n",
      "\n",
      "Task Name : BornholmBitextMining | Value : <class 'mteb.tasks.BitextMining.dan.BornholmskBitextMining.BornholmBitextMining'>\n",
      "\n",
      "Task Name : PubChemSMILESBitextMining | Value : <class 'mteb.tasks.BitextMining.eng.PubChemSMILESBitextMining.PubChemSMILESBitextMining'>\n",
      "\n",
      "Task Name : SAMSumFa | Value : <class 'mteb.tasks.BitextMining.fas.FaMTEBSummaryRetrieval.SAMSumFa'>\n",
      "\n",
      "Task Name : SynPerChatbotSumSRetrieval | Value : <class 'mteb.tasks.BitextMining.fas.FaMTEBSummaryRetrieval.SynPerChatbotSumSRetrieval'>\n",
      "\n",
      "Task Name : SynPerChatbotRAGSumSRetrieval | Value : <class 'mteb.tasks.BitextMining.fas.FaMTEBSummaryRetrieval.SynPerChatbotRAGSumSRetrieval'>\n",
      "\n",
      "Task Name : TbilisiCityHallBitextMining | Value : <class 'mteb.tasks.BitextMining.kat.TbilisiCityHallBitextMining.TbilisiCityHallBitextMining'>\n",
      "\n",
      "Task Name : BibleNLPBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.BibleNLPBitextMining.BibleNLPBitextMining'>\n",
      "\n",
      "Task Name : BUCC | Value : <class 'mteb.tasks.BitextMining.multilingual.BUCCBitextMining.BUCCBitextMining'>\n",
      "\n",
      "Task Name : BUCC.v2 | Value : <class 'mteb.tasks.BitextMining.multilingual.BUCCBitextMiningFast.BUCCBitextMiningFast'>\n",
      "\n",
      "Task Name : DiaBlaBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.DiaBLaBitextMining.DiaBLaBitextMining'>\n",
      "\n",
      "Task Name : FloresBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.FloresBitextMining.FloresBitextMining'>\n",
      "\n",
      "Task Name : IN22ConvBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.IN22ConvBitextMining.IN22ConvBitextMining'>\n",
      "\n",
      "Task Name : IN22GenBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.IN22GenBitextMining.IN22GenBitextMining'>\n",
      "\n",
      "Task Name : IndicGenBenchFloresBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.IndicGenBenchFloresBitextMining.IndicGenBenchFloresBitextMining'>\n",
      "\n",
      "Task Name : IWSLT2017BitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.IWSLT2017BitextMining.IWSLT2017BitextMining'>\n",
      "\n",
      "Task Name : LinceMTBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.LinceMTBitextMining.LinceMTBitextMining'>\n",
      "\n",
      "Task Name : NollySentiBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.NollySentiBitextMining.NollySentiBitextMining'>\n",
      "\n",
      "Task Name : NorwegianCourtsBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.NorwegianCourtsBitextMining.NorwegianCourtsBitextMining'>\n",
      "\n",
      "Task Name : NTREXBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.NTREXBitextMining.NTREXBitextMining'>\n",
      "\n",
      "Task Name : NusaTranslationBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.NusaTranslationBitextMining.NusaTranslationBitextMining'>\n",
      "\n",
      "Task Name : NusaXBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.NusaXBitextMining.NusaXBitextMining'>\n",
      "\n",
      "Task Name : PhincBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.PhincBitextMining.PhincBitextMining'>\n",
      "\n",
      "Task Name : RomaTalesBitextMining | Value : <class 'mteb.tasks.BitextMining.multilingual.RomaTalesBitextMining.RomaTalesBitextMining'>\n",
      "\n",
      "Task Name : Tatoeba | Value : <class 'mteb.tasks.BitextMining.multilingual.TatoebaBitextMining.TatoebaBitextMining'>\n",
      "\n",
      "Task Name : SRNCorpusBitextMining | Value : <class 'mteb.tasks.BitextMining.srn.SRNCorpusBitextMining.SRNCorpusBitextMining'>\n",
      "\n",
      "Task Name : VieMedEVBitextMining | Value : <class 'mteb.tasks.BitextMining.vie.VieMedEVBitextMining.VieMedEVBitextMining'>\n",
      "\n",
      "Task Name : BlurbsClusteringP2P | Value : <class 'mteb.tasks.Clustering.deu.BlurbsClusteringP2P.BlurbsClusteringP2P'>\n",
      "\n",
      "Task Name : BlurbsClusteringS2S | Value : <class 'mteb.tasks.Clustering.deu.BlurbsClusteringS2S.BlurbsClusteringS2S'>\n",
      "\n",
      "Task Name : TenKGnadClusteringP2P | Value : <class 'mteb.tasks.Clustering.deu.TenKGnadClusteringP2P.TenKGnadClusteringP2P'>\n",
      "\n",
      "Task Name : TenKGnadClusteringS2S | Value : <class 'mteb.tasks.Clustering.deu.TenKGnadClusteringS2S.TenKGnadClusteringS2S'>\n",
      "\n",
      "Task Name : ArxivClusteringP2P | Value : <class 'mteb.tasks.Clustering.eng.ArxivClusteringP2P.ArxivClusteringP2P'>\n",
      "\n",
      "Task Name : ArxivClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.eng.ArxivClusteringP2P.ArxivClusteringP2PFast'>\n",
      "\n",
      "Task Name : ArxivClusteringS2S | Value : <class 'mteb.tasks.Clustering.eng.ArxivClusteringS2S.ArxivClusteringS2S'>\n",
      "\n",
      "Task Name : BigPatentClustering | Value : <class 'mteb.tasks.Clustering.eng.BigPatentClustering.BigPatentClustering'>\n",
      "\n",
      "Task Name : BiorxivClusteringP2P | Value : <class 'mteb.tasks.Clustering.eng.BiorxivClusteringP2P.BiorxivClusteringP2P'>\n",
      "\n",
      "Task Name : BiorxivClusteringS2S | Value : <class 'mteb.tasks.Clustering.eng.BiorxivClusteringS2S.BiorxivClusteringS2S'>\n",
      "\n",
      "Task Name : BuiltBenchClusteringP2P | Value : <class 'mteb.tasks.Clustering.eng.BuiltBenchClusteringP2P.BuiltBenchClusteringP2P'>\n",
      "\n",
      "Task Name : BuiltBenchClusteringS2S | Value : <class 'mteb.tasks.Clustering.eng.BuiltBenchClusteringS2S.BuiltBenchClusteringS2S'>\n",
      "\n",
      "Task Name : MedrxivClusteringP2P | Value : <class 'mteb.tasks.Clustering.eng.MedrxivClusteringP2P.MedrxivClusteringP2P'>\n",
      "\n",
      "Task Name : MedrxivClusteringS2S | Value : <class 'mteb.tasks.Clustering.eng.MedrxivClusteringS2S.MedrxivClusteringS2S'>\n",
      "\n",
      "Task Name : RedditClustering | Value : <class 'mteb.tasks.Clustering.eng.RedditClustering.RedditClustering'>\n",
      "\n",
      "Task Name : RedditClusteringP2P | Value : <class 'mteb.tasks.Clustering.eng.RedditClusteringP2P.RedditClusteringP2P'>\n",
      "\n",
      "Task Name : StackExchangeClustering | Value : <class 'mteb.tasks.Clustering.eng.StackExchangeClustering.StackExchangeClustering'>\n",
      "\n",
      "Task Name : StackExchangeClusteringP2P | Value : <class 'mteb.tasks.Clustering.eng.StackExchangeClusteringP2P.StackExchangeClusteringP2P'>\n",
      "\n",
      "Task Name : TwentyNewsgroupsClustering | Value : <class 'mteb.tasks.Clustering.eng.TwentyNewsgroupsClustering.TwentyNewsgroupsClustering'>\n",
      "\n",
      "Task Name : WikiCitiesClustering | Value : <class 'mteb.tasks.Clustering.eng.WikiCitiesClustering.WikiCitiesClustering'>\n",
      "\n",
      "Task Name : WikipediaSpecialtiesInChemistryClustering | Value : <class 'mteb.tasks.Clustering.eng.WikipediaChemistrySpecialtiesClustering.WikipediaChemistrySpecialtiesClustering'>\n",
      "\n",
      "Task Name : WikipediaChemistryTopicsClustering | Value : <class 'mteb.tasks.Clustering.eng.WikipediaChemistryTopicsClustering.WikipediaChemistryTopicsClustering'>\n",
      "\n",
      "Task Name : AlloProfClusteringP2P | Value : <class 'mteb.tasks.Clustering.fra.AlloProfClusteringP2P.AlloProfClusteringP2P'>\n",
      "\n",
      "Task Name : AlloProfClusteringS2S | Value : <class 'mteb.tasks.Clustering.fra.AlloProfClusteringS2S.AlloProfClusteringS2S'>\n",
      "\n",
      "Task Name : HALClusteringS2S | Value : <class 'mteb.tasks.Clustering.fra.HALClusteringS2S.HALClusteringS2S'>\n",
      "\n",
      "Task Name : IndicReviewsClusteringP2P | Value : <class 'mteb.tasks.Clustering.multilingual.IndicReviewsClusteringP2P.IndicReviewsClusteringP2P'>\n",
      "\n",
      "Task Name : MasakhaNEWSClusteringP2P | Value : <class 'mteb.tasks.Clustering.multilingual.MasakhaNEWSClusteringP2P.MasakhaNEWSClusteringP2P'>\n",
      "\n",
      "Task Name : MasakhaNEWSClusteringS2S | Value : <class 'mteb.tasks.Clustering.multilingual.MasakhaNEWSClusteringS2S.MasakhaNEWSClusteringS2S'>\n",
      "\n",
      "Task Name : MLSUMClusteringP2P | Value : <class 'mteb.tasks.Clustering.multilingual.MLSUMClusteringP2P.MLSUMClusteringP2P'>\n",
      "\n",
      "Task Name : MLSUMClusteringS2S | Value : <class 'mteb.tasks.Clustering.multilingual.MLSUMClusteringS2S.MLSUMClusteringS2S'>\n",
      "\n",
      "Task Name : WikiClusteringP2P | Value : <class 'mteb.tasks.Clustering.multilingual.WikiClusteringP2P.WikiClusteringP2P'>\n",
      "\n",
      "Task Name : SNLClustering | Value : <class 'mteb.tasks.Clustering.nob.snl_clustering.SNLClustering'>\n",
      "\n",
      "Task Name : VGClustering | Value : <class 'mteb.tasks.Clustering.nob.vg_clustering.VGClustering'>\n",
      "\n",
      "Task Name : EightTagsClustering | Value : <class 'mteb.tasks.Clustering.pol.PolishClustering.EightTagsClustering'>\n",
      "\n",
      "Task Name : RomaniBibleClustering | Value : <class 'mteb.tasks.Clustering.rom.RomaniBibleClustering.RomaniBibleClustering'>\n",
      "\n",
      "Task Name : SpanishNewsClusteringP2P | Value : <class 'mteb.tasks.Clustering.spa.SpanishNewsClusteringP2P.SpanishNewsClusteringP2P'>\n",
      "\n",
      "Task Name : SwednClustering | Value : <class 'mteb.tasks.Clustering.swe.swedn_clustering.SwednClustering'>\n",
      "\n",
      "Task Name : CLSClusteringS2S | Value : <class 'mteb.tasks.Clustering.zho.CMTEBClustering.CLSClusteringS2S'>\n",
      "\n",
      "Task Name : CLSClusteringP2P | Value : <class 'mteb.tasks.Clustering.zho.CMTEBClustering.CLSClusteringP2P'>\n",
      "\n",
      "Task Name : ThuNewsClusteringS2S | Value : <class 'mteb.tasks.Clustering.zho.CMTEBClustering.ThuNewsClusteringS2S'>\n",
      "\n",
      "Task Name : ThuNewsClusteringP2P | Value : <class 'mteb.tasks.Clustering.zho.CMTEBClustering.ThuNewsClusteringP2P'>\n",
      "\n",
      "Task Name : BlurbsClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.deu.BlurbsClusteringP2P.BlurbsClusteringP2PFast'>\n",
      "\n",
      "Task Name : BlurbsClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.deu.BlurbsClusteringS2S.BlurbsClusteringS2SFast'>\n",
      "\n",
      "Task Name : TenKGnadClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.deu.TenKGnadClusteringP2P.TenKGnadClusteringP2PFast'>\n",
      "\n",
      "Task Name : TenKGnadClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.deu.TenKGnadClusteringS2S.TenKGnadClusteringS2SFast'>\n",
      "\n",
      "Task Name : ArXivHierarchicalClusteringP2P | Value : <class 'mteb.tasks.Clustering.eng.ArXivHierarchicalClustering.ArXivHierarchicalClusteringP2P'>\n",
      "\n",
      "Task Name : ArXivHierarchicalClusteringS2S | Value : <class 'mteb.tasks.Clustering.eng.ArXivHierarchicalClustering.ArXivHierarchicalClusteringS2S'>\n",
      "\n",
      "Task Name : BigPatentClustering.v2 | Value : <class 'mteb.tasks.Clustering.eng.BigPatentClustering.BigPatentClusteringFast'>\n",
      "\n",
      "Task Name : BiorxivClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.eng.BiorxivClusteringP2P.BiorxivClusteringP2PFast'>\n",
      "\n",
      "Task Name : BiorxivClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.eng.BiorxivClusteringS2S.BiorxivClusteringS2SFast'>\n",
      "\n",
      "Task Name : MedrxivClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.eng.MedrxivClusteringP2P.MedrxivClusteringP2PFast'>\n",
      "\n",
      "Task Name : MedrxivClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.eng.MedrxivClusteringS2S.MedrxivClusteringS2SFast'>\n",
      "\n",
      "Task Name : RedditClustering.v2 | Value : <class 'mteb.tasks.Clustering.eng.RedditClustering.RedditFastClusteringS2S'>\n",
      "\n",
      "Task Name : RedditClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.eng.RedditClusteringP2P.RedditFastClusteringP2P'>\n",
      "\n",
      "Task Name : StackExchangeClustering.v2 | Value : <class 'mteb.tasks.Clustering.eng.StackExchangeClustering.StackExchangeClusteringFast'>\n",
      "\n",
      "Task Name : StackExchangeClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.eng.StackExchangeClusteringP2P.StackExchangeClusteringP2PFast'>\n",
      "\n",
      "Task Name : TwentyNewsgroupsClustering.v2 | Value : <class 'mteb.tasks.Clustering.eng.TwentyNewsgroupsClustering.TwentyNewsgroupsClusteringFast'>\n",
      "\n",
      "Task Name : BeytooteClustering | Value : <class 'mteb.tasks.Clustering.fas.FaMTEBClustering.BeytooteClustering'>\n",
      "\n",
      "Task Name : DigikalamagClustering | Value : <class 'mteb.tasks.Clustering.fas.FaMTEBClustering.DigikalamagClustering'>\n",
      "\n",
      "Task Name : HamshahriClustring | Value : <class 'mteb.tasks.Clustering.fas.FaMTEBClustering.HamshahriClustring'>\n",
      "\n",
      "Task Name : NLPTwitterAnalysisClustering | Value : <class 'mteb.tasks.Clustering.fas.FaMTEBClustering.NLPTwitterAnalysisClustering'>\n",
      "\n",
      "Task Name : SIDClustring | Value : <class 'mteb.tasks.Clustering.fas.FaMTEBClustering.SIDClustring'>\n",
      "\n",
      "Task Name : AlloProfClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.fra.AlloProfClusteringP2P.AlloProfClusteringP2PFast'>\n",
      "\n",
      "Task Name : AlloProfClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.fra.AlloProfClusteringS2S.AlloProfClusteringS2SFast'>\n",
      "\n",
      "Task Name : HALClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.fra.HALClusteringS2S.HALClusteringS2SFast'>\n",
      "\n",
      "Task Name : LivedoorNewsClustering.v2 | Value : <class 'mteb.tasks.Clustering.jpn.LivedoorNewsClustering.LivedoorNewsClusteringv2'>\n",
      "\n",
      "Task Name : LivedoorNewsClustering | Value : <class 'mteb.tasks.Clustering.jpn.LivedoorNewsClustering.LivedoorNewsClustering'>\n",
      "\n",
      "Task Name : MewsC16JaClustering | Value : <class 'mteb.tasks.Clustering.jpn.MewsC16JaClustering.MewsC16JaClustering'>\n",
      "\n",
      "Task Name : MLSUMClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.multilingual.MLSUMClusteringP2P.MLSUMClusteringP2PFast'>\n",
      "\n",
      "Task Name : MLSUMClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.multilingual.MLSUMClusteringS2S.MLSUMClusteringS2SFast'>\n",
      "\n",
      "Task Name : SIB200ClusteringS2S | Value : <class 'mteb.tasks.Clustering.multilingual.SIB200ClusteringS2S.SIB200ClusteringFast'>\n",
      "\n",
      "Task Name : WikiClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.multilingual.WikiClusteringP2P.WikiClusteringFastP2P'>\n",
      "\n",
      "Task Name : SNLHierarchicalClusteringP2P | Value : <class 'mteb.tasks.Clustering.nob.SNLHierarchicalClustering.SNLHierarchicalClusteringP2P'>\n",
      "\n",
      "Task Name : SNLHierarchicalClusteringS2S | Value : <class 'mteb.tasks.Clustering.nob.SNLHierarchicalClustering.SNLHierarchicalClusteringS2S'>\n",
      "\n",
      "Task Name : VGHierarchicalClusteringP2P | Value : <class 'mteb.tasks.Clustering.nob.VGHierarchicalClustering.VGHierarchicalClusteringP2P'>\n",
      "\n",
      "Task Name : VGHierarchicalClusteringS2S | Value : <class 'mteb.tasks.Clustering.nob.VGHierarchicalClustering.VGHierarchicalClusteringS2S'>\n",
      "\n",
      "Task Name : EightTagsClustering.v2 | Value : <class 'mteb.tasks.Clustering.pol.PolishClustering.EightTagsClusteringFast'>\n",
      "\n",
      "Task Name : PlscClusteringS2S | Value : <class 'mteb.tasks.Clustering.pol.PolishClustering.PlscClusteringS2S'>\n",
      "\n",
      "Task Name : PlscClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.pol.PolishClustering.PlscClusteringS2SFast'>\n",
      "\n",
      "Task Name : PlscClusteringP2P | Value : <class 'mteb.tasks.Clustering.pol.PolishClustering.PlscClusteringP2P'>\n",
      "\n",
      "Task Name : PlscClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.pol.PolishClustering.PlscClusteringP2PFast'>\n",
      "\n",
      "Task Name : GeoreviewClusteringP2P | Value : <class 'mteb.tasks.Clustering.rus.GeoreviewClusteringP2P.GeoreviewClusteringP2P'>\n",
      "\n",
      "Task Name : RuSciBenchGRNTIClusteringP2P | Value : <class 'mteb.tasks.Clustering.rus.RuSciBenchGRNTIClusteringP2P.RuSciBenchGRNTIClusteringP2P'>\n",
      "\n",
      "Task Name : RuSciBenchOECDClusteringP2P | Value : <class 'mteb.tasks.Clustering.rus.RuSciBenchOECDClusteringP2P.RuSciBenchOECDClusteringP2P'>\n",
      "\n",
      "Task Name : SwednClusteringP2P | Value : <class 'mteb.tasks.Clustering.swe.SwednClustering.SwednClusteringP2P'>\n",
      "\n",
      "Task Name : SwednClusteringS2S | Value : <class 'mteb.tasks.Clustering.swe.SwednClustering.SwednClusteringFastS2S'>\n",
      "\n",
      "Task Name : CLSClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.zho.CMTEBClustering.CLSClusteringFastS2S'>\n",
      "\n",
      "Task Name : CLSClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.zho.CMTEBClustering.CLSClusteringFastP2P'>\n",
      "\n",
      "Task Name : ThuNewsClusteringS2S.v2 | Value : <class 'mteb.tasks.Clustering.zho.CMTEBClustering.ThuNewsClusteringFastS2S'>\n",
      "\n",
      "Task Name : ThuNewsClusteringP2P.v2 | Value : <class 'mteb.tasks.Clustering.zho.CMTEBClustering.ThuNewsClusteringFastP2P'>\n",
      "\n",
      "Task Name : Core17InstructionRetrieval | Value : <class 'mteb.tasks.InstructionRetrieval.eng.Core17InstructionRetrieval.Core17InstructionRetrieval'>\n",
      "\n",
      "Task Name : News21InstructionRetrieval | Value : <class 'mteb.tasks.InstructionRetrieval.eng.News21InstructionRetrieval.News21InstructionRetrieval'>\n",
      "\n",
      "Task Name : Robust04InstructionRetrieval | Value : <class 'mteb.tasks.InstructionRetrieval.eng.Robust04InstructionRetrieval.Robust04InstructionRetrieval'>\n",
      "\n",
      "Task Name : mFollowIRCrossLingualInstructionRetrieval | Value : <class 'mteb.tasks.InstructionRetrieval.multilingual.mFollowIR.mFollowIRCrossLingual'>\n",
      "\n",
      "Task Name : mFollowIRInstructionRetrieval | Value : <class 'mteb.tasks.InstructionRetrieval.multilingual.mFollowIR.mFollowIR'>\n",
      "\n",
      "Task Name : KorHateSpeechMLClassification | Value : <class 'mteb.tasks.MultiLabelClassification.kor.KorHateSpeechMLClassification.KorHateSpeechMLClassification'>\n",
      "\n",
      "Task Name : MalteseNewsClassification | Value : <class 'mteb.tasks.MultiLabelClassification.mlt.MalteseNewsClassification.MalteseNewsClassification'>\n",
      "\n",
      "Task Name : MultiEURLEXMultilabelClassification | Value : <class 'mteb.tasks.MultiLabelClassification.multilingual.MultiEURLEXMultilabelClassification.MultiEURLEXMultilabelClassification'>\n",
      "\n",
      "Task Name : BrazilianToxicTweetsClassification | Value : <class 'mteb.tasks.MultiLabelClassification.por.BrazilianToxicTweetsClassification.BrazilianToxicTweetsClassification'>\n",
      "\n",
      "Task Name : CEDRClassification | Value : <class 'mteb.tasks.MultiLabelClassification.rus.CEDRClassification.CEDRClassification'>\n",
      "\n",
      "Task Name : SensitiveTopicsClassification | Value : <class 'mteb.tasks.MultiLabelClassification.rus.SensitiveTopicsClassification.SensitiveTopicsClassification'>\n",
      "\n",
      "Task Name : ArEntail | Value : <class 'mteb.tasks.PairClassification.ara.ArEntail.ArEntail'>\n",
      "\n",
      "Task Name : CTKFactsNLI | Value : <class 'mteb.tasks.PairClassification.ces.CTKFactsNLI.CTKFactsNLI'>\n",
      "\n",
      "Task Name : FalseFriendsGermanEnglish | Value : <class 'mteb.tasks.PairClassification.deu.FalseFriendsDeEnPC.FalseFriendsDeEnPC'>\n",
      "\n",
      "Task Name : LegalBenchPC | Value : <class 'mteb.tasks.PairClassification.eng.LegalBenchPC.LegalBenchPC'>\n",
      "\n",
      "Task Name : PubChemAISentenceParaphrasePC | Value : <class 'mteb.tasks.PairClassification.eng.PubChemAISentenceParaphrasePC.PubChemAISentenceParaphrasePC'>\n",
      "\n",
      "Task Name : PubChemSMILESPC | Value : <class 'mteb.tasks.PairClassification.eng.PubChemSMILESPC.PubChemSMILESPC'>\n",
      "\n",
      "Task Name : PubChemSynonymPC | Value : <class 'mteb.tasks.PairClassification.eng.PubChemSynonymPC.PubChemSynonymPC'>\n",
      "\n",
      "Task Name : PubChemWikiParagraphsPC | Value : <class 'mteb.tasks.PairClassification.eng.PubChemWikiParagraphsPC.PubChemWikiParagraphsPC'>\n",
      "\n",
      "Task Name : SprintDuplicateQuestions | Value : <class 'mteb.tasks.PairClassification.eng.SprintDuplicateQuestionsPC.SprintDuplicateQuestionsPC'>\n",
      "\n",
      "Task Name : TwitterSemEval2015 | Value : <class 'mteb.tasks.PairClassification.eng.TwitterSemEval2015PC.TwitterSemEval2015PC'>\n",
      "\n",
      "Task Name : TwitterURLCorpus | Value : <class 'mteb.tasks.PairClassification.eng.TwitterURLCorpusPC.TwitterURLCorpusPC'>\n",
      "\n",
      "Task Name : CExaPPC | Value : <class 'mteb.tasks.PairClassification.fas.FaMTEBPairClassification.CExaPPC'>\n",
      "\n",
      "Task Name : SynPerChatbotRAGFAQPC | Value : <class 'mteb.tasks.PairClassification.fas.FaMTEBPairClassification.SynPerChatbotRAGFAQPC'>\n",
      "\n",
      "Task Name : FarsiParaphraseDetection | Value : <class 'mteb.tasks.PairClassification.fas.FaMTEBPairClassification.FarsiParaphraseDetection'>\n",
      "\n",
      "Task Name : SynPerTextKeywordsPC | Value : <class 'mteb.tasks.PairClassification.fas.FaMTEBPairClassification.SynPerTextKeywordsPC'>\n",
      "\n",
      "Task Name : SynPerQAPC | Value : <class 'mteb.tasks.PairClassification.fas.FaMTEBPairClassification.SynPerQAPC'>\n",
      "\n",
      "Task Name : ParsinluEntail | Value : <class 'mteb.tasks.PairClassification.fas.FaMTEBPairClassification.ParsinluEntail'>\n",
      "\n",
      "Task Name : ParsinluQueryParaphPC | Value : <class 'mteb.tasks.PairClassification.fas.FaMTEBPairClassification.ParsinluQueryParaphPC'>\n",
      "\n",
      "Task Name : FarsTail | Value : <class 'mteb.tasks.PairClassification.fas.FarsTail.FarsTail'>\n",
      "\n",
      "Task Name : ArmenianParaphrasePC | Value : <class 'mteb.tasks.PairClassification.hye.ArmenianParaphrasePC.ArmenianParaphrasePC'>\n",
      "\n",
      "Task Name : indonli | Value : <class 'mteb.tasks.PairClassification.ind.IndoNLI.IndoNLI'>\n",
      "\n",
      "Task Name : KLUE-NLI | Value : <class 'mteb.tasks.PairClassification.kor.KlueNLI.KlueNLI'>\n",
      "\n",
      "Task Name : OpusparcusPC | Value : <class 'mteb.tasks.PairClassification.multilingual.OpusparcusPC.OpusparcusPC'>\n",
      "\n",
      "Task Name : PawsXPairClassification | Value : <class 'mteb.tasks.PairClassification.multilingual.PawsXPairClassification.PawsXPairClassification'>\n",
      "\n",
      "Task Name : PubChemWikiPairClassification | Value : <class 'mteb.tasks.PairClassification.multilingual.PubChemWikiPairClassification.PubChemWikiPairClassification'>\n",
      "\n",
      "Task Name : RTE3 | Value : <class 'mteb.tasks.PairClassification.multilingual.RTE3.RTE3'>\n",
      "\n",
      "Task Name : XNLI | Value : <class 'mteb.tasks.PairClassification.multilingual.XNLI.XNLI'>\n",
      "\n",
      "Task Name : XNLIV2 | Value : <class 'mteb.tasks.PairClassification.multilingual.XNLI.XNLIV2'>\n",
      "\n",
      "Task Name : XStance | Value : <class 'mteb.tasks.PairClassification.multilingual.XStance.XStance'>\n",
      "\n",
      "Task Name : SICK-E-PL | Value : <class 'mteb.tasks.PairClassification.pol.PolishPC.SickePLPC'>\n",
      "\n",
      "Task Name : PpcPC | Value : <class 'mteb.tasks.PairClassification.pol.PolishPC.PpcPC'>\n",
      "\n",
      "Task Name : CDSC-E | Value : <class 'mteb.tasks.PairClassification.pol.PolishPC.CdscePC'>\n",
      "\n",
      "Task Name : PSC | Value : <class 'mteb.tasks.PairClassification.pol.PolishPC.PscPC'>\n",
      "\n",
      "Task Name : Assin2RTE | Value : <class 'mteb.tasks.PairClassification.por.Assin2RTE.Assin2RTE'>\n",
      "\n",
      "Task Name : SICK-BR-PC | Value : <class 'mteb.tasks.PairClassification.por.SickBrPC.SickBrPC'>\n",
      "\n",
      "Task Name : TERRa | Value : <class 'mteb.tasks.PairClassification.rus.TERRa.TERRa'>\n",
      "\n",
      "Task Name : Ocnli | Value : <class 'mteb.tasks.PairClassification.zho.CMTEBPairClassification.Ocnli'>\n",
      "\n",
      "Task Name : Cmnli | Value : <class 'mteb.tasks.PairClassification.zho.CMTEBPairClassification.Cmnli'>\n",
      "\n",
      "Task Name : NamaaMrTydiReranking | Value : <class 'mteb.tasks.Reranking.ara.NamaaMrTydiReranking.NamaaMrTydiReranking'>\n",
      "\n",
      "Task Name : AskUbuntuDupQuestions | Value : <class 'mteb.tasks.Reranking.eng.AskUbuntuDupQuestions.AskUbuntuDupQuestions'>\n",
      "\n",
      "Task Name : BuiltBenchReranking | Value : <class 'mteb.tasks.Reranking.eng.BuiltBenchReranking.BuiltBenchReranking'>\n",
      "\n",
      "Task Name : MindSmallReranking | Value : <class 'mteb.tasks.Reranking.eng.MindSmallReranking.MindSmallReranking'>\n",
      "\n",
      "Task Name : SciDocsRR | Value : <class 'mteb.tasks.Reranking.eng.SciDocsReranking.SciDocsReranking'>\n",
      "\n",
      "Task Name : StackOverflowDupQuestions | Value : <class 'mteb.tasks.Reranking.eng.StackOverflowDupQuestions.StackOverflowDupQuestions'>\n",
      "\n",
      "Task Name : WebLINXCandidatesReranking | Value : <class 'mteb.tasks.Reranking.eng.WebLINXCandidatesReranking.WebLINXCandidatesReranking'>\n",
      "\n",
      "Task Name : AlloprofReranking | Value : <class 'mteb.tasks.Reranking.fra.AlloprofReranking.AlloprofReranking'>\n",
      "\n",
      "Task Name : SyntecReranking | Value : <class 'mteb.tasks.Reranking.fra.SyntecReranking.SyntecReranking'>\n",
      "\n",
      "Task Name : VoyageMMarcoReranking | Value : <class 'mteb.tasks.Reranking.jpn.MMarcoReranking.VoyageMMarcoReranking'>\n",
      "\n",
      "Task Name : ESCIReranking | Value : <class 'mteb.tasks.Reranking.multilingual.ESCIReranking.ESCIReranking'>\n",
      "\n",
      "Task Name : MIRACLReranking | Value : <class 'mteb.tasks.Reranking.multilingual.MIRACLReranking.MIRACLReranking'>\n",
      "\n",
      "Task Name : WikipediaRerankingMultilingual | Value : <class 'mteb.tasks.Reranking.multilingual.WikipediaRerankingMultilingual.WikipediaRerankingMultilingual'>\n",
      "\n",
      "Task Name : RuBQReranking | Value : <class 'mteb.tasks.Reranking.rus.RuBQReranking.RuBQReranking'>\n",
      "\n",
      "Task Name : T2Reranking | Value : <class 'mteb.tasks.Reranking.zho.CMTEBReranking.T2Reranking'>\n",
      "\n",
      "Task Name : MMarcoReranking | Value : <class 'mteb.tasks.Reranking.zho.CMTEBReranking.MMarcoReranking'>\n",
      "\n",
      "Task Name : CMedQAv1-reranking | Value : <class 'mteb.tasks.Reranking.zho.CMTEBReranking.CMedQAv1'>\n",
      "\n",
      "Task Name : CMedQAv2-reranking | Value : <class 'mteb.tasks.Reranking.zho.CMTEBReranking.CMedQAv2'>\n",
      "\n",
      "Task Name : CPUSpeedTask | Value : <class 'mteb.tasks.SpeedTask.CPUSpeedTask.CPUSpeedTask'>\n",
      "\n",
      "Task Name : GPUSpeedTask | Value : <class 'mteb.tasks.SpeedTask.GPUSpeedTask.GPUSpeedTask'>\n",
      "\n",
      "Task Name : GermanSTSBenchmark | Value : <class 'mteb.tasks.STS.deu.GermanSTSBenchmarkSTS.GermanSTSBenchmarkSTS'>\n",
      "\n",
      "Task Name : BIOSSES | Value : <class 'mteb.tasks.STS.eng.BiossesSTS.BiossesSTS'>\n",
      "\n",
      "Task Name : SICK-R | Value : <class 'mteb.tasks.STS.eng.SickrSTS.SickrSTS'>\n",
      "\n",
      "Task Name : STS12 | Value : <class 'mteb.tasks.STS.eng.STS12STS.STS12STS'>\n",
      "\n",
      "Task Name : STS13 | Value : <class 'mteb.tasks.STS.eng.STS13STS.STS13STS'>\n",
      "\n",
      "Task Name : STS14 | Value : <class 'mteb.tasks.STS.eng.STS14STS.STS14STS'>\n",
      "\n",
      "Task Name : STS15 | Value : <class 'mteb.tasks.STS.eng.STS15STS.STS15STS'>\n",
      "\n",
      "Task Name : STS16 | Value : <class 'mteb.tasks.STS.eng.STS16STS.STS16STS'>\n",
      "\n",
      "Task Name : STSBenchmark | Value : <class 'mteb.tasks.STS.eng.STSBenchmarkSTS.STSBenchmarkSTS'>\n",
      "\n",
      "Task Name : FaroeseSTS | Value : <class 'mteb.tasks.STS.fao.FaroeseSTS.FaroeseSTS'>\n",
      "\n",
      "Task Name : Farsick | Value : <class 'mteb.tasks.STS.fas.FaMTEBSTS.Farsick'>\n",
      "\n",
      "Task Name : SynPerSTS | Value : <class 'mteb.tasks.STS.fas.FaMTEBSTS.SynPerSTS'>\n",
      "\n",
      "Task Name : Query2Query | Value : <class 'mteb.tasks.STS.fas.FaMTEBSTS.Query2Query'>\n",
      "\n",
      "Task Name : FinParaSTS | Value : <class 'mteb.tasks.STS.fin.FinParaSTS.FinParaSTS'>\n",
      "\n",
      "Task Name : SICKFr | Value : <class 'mteb.tasks.STS.fra.SickFrSTS.SickFrSTS'>\n",
      "\n",
      "Task Name : JSICK | Value : <class 'mteb.tasks.STS.jpn.JSICK.JSICK'>\n",
      "\n",
      "Task Name : JSTS | Value : <class 'mteb.tasks.STS.jpn.JSTS.JSTS'>\n",
      "\n",
      "Task Name : KLUE-STS | Value : <class 'mteb.tasks.STS.kor.KlueSTS.KlueSTS'>\n",
      "\n",
      "Task Name : KorSTS | Value : <class 'mteb.tasks.STS.kor.KorSTS.KorSTS'>\n",
      "\n",
      "Task Name : IndicCrosslingualSTS | Value : <class 'mteb.tasks.STS.multilingual.IndicCrosslingualSTS.IndicCrosslingualSTS'>\n",
      "\n",
      "Task Name : SemRel24STS | Value : <class 'mteb.tasks.STS.multilingual.SemRel24STS.SemRel24STS'>\n",
      "\n",
      "Task Name : STS17 | Value : <class 'mteb.tasks.STS.multilingual.STS17CrosslingualSTS.STS17Crosslingual'>\n",
      "\n",
      "Task Name : STS22.v2 | Value : <class 'mteb.tasks.STS.multilingual.STS22CrosslingualSTS.STS22CrosslingualSTSv2'>\n",
      "\n",
      "Task Name : STS22 | Value : <class 'mteb.tasks.STS.multilingual.STS22CrosslingualSTS.STS22CrosslingualSTS'>\n",
      "\n",
      "Task Name : STSBenchmarkMultilingualSTS | Value : <class 'mteb.tasks.STS.multilingual.STSBenchmarkMultilingualSTS.STSBenchmarkMultilingualSTS'>\n",
      "\n",
      "Task Name : SICK-R-PL | Value : <class 'mteb.tasks.STS.pol.PolishSTS.SickrPLSTS'>\n",
      "\n",
      "Task Name : CDSC-R | Value : <class 'mteb.tasks.STS.pol.PolishSTS.CdscrSTS'>\n",
      "\n",
      "Task Name : Assin2STS | Value : <class 'mteb.tasks.STS.por.Assin2STS.Assin2STS'>\n",
      "\n",
      "Task Name : SICK-BR-STS | Value : <class 'mteb.tasks.STS.por.SickBrSTS.SickBrSTS'>\n",
      "\n",
      "Task Name : RonSTS | Value : <class 'mteb.tasks.STS.ron.RonSTS.RonSTS'>\n",
      "\n",
      "Task Name : RUParaPhraserSTS | Value : <class 'mteb.tasks.STS.rus.RUParaPhraserSTS.RUParaPhraserSTS'>\n",
      "\n",
      "Task Name : RuSTSBenchmarkSTS | Value : <class 'mteb.tasks.STS.rus.RuSTSBenchmarkSTS.RuSTSBenchmarkSTS'>\n",
      "\n",
      "Task Name : STSES | Value : <class 'mteb.tasks.STS.spa.STSES.STSES'>\n",
      "\n",
      "Task Name : ATEC | Value : <class 'mteb.tasks.STS.zho.CMTEBSTS.ATEC'>\n",
      "\n",
      "Task Name : BQ | Value : <class 'mteb.tasks.STS.zho.CMTEBSTS.BQ'>\n",
      "\n",
      "Task Name : LCQMC | Value : <class 'mteb.tasks.STS.zho.CMTEBSTS.LCQMC'>\n",
      "\n",
      "Task Name : PAWSX | Value : <class 'mteb.tasks.STS.zho.CMTEBSTS.PAWSX'>\n",
      "\n",
      "Task Name : STSB | Value : <class 'mteb.tasks.STS.zho.CMTEBSTS.STSB'>\n",
      "\n",
      "Task Name : AFQMC | Value : <class 'mteb.tasks.STS.zho.CMTEBSTS.AFQMC'>\n",
      "\n",
      "Task Name : QBQTC | Value : <class 'mteb.tasks.STS.zho.CMTEBSTS.QBQTC'>\n",
      "\n",
      "Task Name : SummEval | Value : <class 'mteb.tasks.Summarization.eng.SummEvalSummarization.SummEvalSummarization'>\n",
      "\n",
      "Task Name : SummEvalSummarization.v2 | Value : <class 'mteb.tasks.Summarization.eng.SummEvalSummarization.SummEvalSummarizationv2'>\n",
      "\n",
      "Task Name : SummEvalFr | Value : <class 'mteb.tasks.Summarization.fra.SummEvalFrSummarization.SummEvalFrSummarization'>\n",
      "\n",
      "Task Name : SummEvalFrSummarization.v2 | Value : <class 'mteb.tasks.Summarization.fra.SummEvalFrSummarization.SummEvalFrSummarizationv2'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in TASKS_REGISTRY.items():\n",
    "    print(f\"Task Name : {key} | Value : {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61531859-bbca-4c2b-98e1-9d6a033fa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3faa37-def1-4c79-bf11-50e2f3a7bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = defaultdict(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2fefed-7a28-4c8d-b6aa-a002c4fd5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb0e64-f9c2-4846-b2e4-93ff4ed69cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b955391-76f2-486d-bc63-3ccc575d0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[1, 2, 3], [4, 5], [6, 7, 8, 9], [10], [11, 12, 13], [14, 15], [16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097fd26-0243-4538-9b9a-8aea240f78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254d2f8-d609-4afb-ac69-b4223971a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "version(\"mteb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87cf9d-865a-4559-ae11-ec4ab3701cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = \"/path/to/your/project:\" + os.environ.get(\"PYTHONPATH\", \"\")\n",
    "print(\"PYTHONPATH:\", os.environ[\"PYTHONPATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837af693-438c-491a-b7fc-fc498abf02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb import get_model, get_model_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d904a428-d7be-4e5b-b090-430a98b04563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/miniconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23dbf96d-c38b-4067-a0de-74d6fd926ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aamita/miniconda3/envs/retrieval/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9267530-32fa-42ea-ae2f-6cbb01d75fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_retrieval",
   "language": "python",
   "name": "image_retrieval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
